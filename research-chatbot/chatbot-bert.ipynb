{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ChatBot using Transfer Learning"
      ],
      "metadata": {
        "id": "ajHMgD6WSM5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "9yC25Z6iSrW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg-7zhwAS6vn",
        "outputId": "d183226c-b662-4dd7-d148-1538ab115838"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import preprocessing\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from transformers import AdamW # optimizer from hugging face transformers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "from preprocess_data import raw_to_json, unzip_entities, tags_patterns_mix, remove_fallback"
      ],
      "metadata": {
        "id": "cjLfr3ruSuPn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ],
      "metadata": {
        "id": "jxxySK_nS2ZS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not torch.cuda.is_available():\n",
        "  raise Exception(\"GPU not availalbe. CPU training will be too slow.\")\n",
        "\n",
        "print(\"device name\", torch.cuda.get_device_name(0))\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLnZAOdrTGQB",
        "outputId": "e2d8a4c3-2a2e-4b3a-b304-9f6867f68c34"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device name Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Settings"
      ],
      "metadata": {
        "id": "rCI69_NWSvj_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "CwrM5tOPTuH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('data/Training - Training.csv')\n",
        "df_test = pd.read_csv('data/Training - Test.csv')"
      ],
      "metadata": {
        "id": "HDFJeSGDSa98"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare training data\n",
        "parent_tags = ['navigate', 'find', 'action']\n",
        "intents = raw_to_json(df_train)\n",
        "data = unzip_entities(intents, parent_tags)\n",
        "df_train = tags_patterns_mix(remove_fallback(data))"
      ],
      "metadata": {
        "id": "aDyGe9wtgmYO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare test data\n",
        "df_test = df_test.drop(df_test[df_test['Tag'] == 'fallback'].index)\n",
        "df_test.reset_index(inplace=True, drop=True)"
      ],
      "metadata": {
        "id": "VnIGVwtVgpay"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Z-R5gp-EgQjf",
        "outputId": "b7757601-37a2-4b3d-dfde-365f7f5f3d25"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e1c16c03-728e-441e-b79a-801e2e2246b9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tag</th>\n",
              "      <th>pattern</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>greeting</td>\n",
              "      <td>Hi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>greeting</td>\n",
              "      <td>Hey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>greeting</td>\n",
              "      <td>Hello</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>greeting</td>\n",
              "      <td>Good morning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>greeting</td>\n",
              "      <td>Good evening</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1c16c03-728e-441e-b79a-801e2e2246b9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e1c16c03-728e-441e-b79a-801e2e2246b9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e1c16c03-728e-441e-b79a-801e2e2246b9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        tag       pattern\n",
              "0  greeting            Hi\n",
              "1  greeting           Hey\n",
              "2  greeting         Hello\n",
              "3  greeting  Good morning\n",
              "4  greeting  Good evening"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7Ew8HFdngESf",
        "outputId": "b226c15b-c4fc-4b74-eaa3-7cb67258dc6f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4414fd05-bf01-4bd7-94b0-20c96e51ba7b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Tag</th>\n",
              "      <th>Tag_parent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Where can I unfollow another person?</td>\n",
              "      <td>find_follow</td>\n",
              "      <td>find</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How to get to the homepage?</td>\n",
              "      <td>find_homepage</td>\n",
              "      <td>find</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Where do I find my profile?</td>\n",
              "      <td>find_profile</td>\n",
              "      <td>find</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Where can I view my feed?</td>\n",
              "      <td>find_personal_feed</td>\n",
              "      <td>find</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Where can I access the public feed?</td>\n",
              "      <td>find_public_feed</td>\n",
              "      <td>find</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4414fd05-bf01-4bd7-94b0-20c96e51ba7b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4414fd05-bf01-4bd7-94b0-20c96e51ba7b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4414fd05-bf01-4bd7-94b0-20c96e51ba7b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                               Sentence                 Tag Tag_parent\n",
              "0  Where can I unfollow another person?         find_follow       find\n",
              "1           How to get to the homepage?       find_homepage       find\n",
              "2           Where do I find my profile?        find_profile       find\n",
              "3             Where can I view my feed?  find_personal_feed       find\n",
              "4   Where can I access the public feed?    find_public_feed       find"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape, df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7xNTelChyfw",
        "outputId": "ac1b82c2-5d30-4fe3-95d8-58426699eea8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1137, 2), (30, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lbl_enc = preprocessing.LabelEncoder()\n",
        "lbl_enc.fit(df_train['tag'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikCzw0qde9q4",
        "outputId": "b85811b5-a019-4398-b270-1b05150d8edf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['label'] = lbl_enc.transform(df_train['tag'])\n",
        "df_test['label'] = lbl_enc.transform(df_test['Tag'])"
      ],
      "metadata": {
        "id": "UkAD24SAfPOd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['label'].value_counts(normalize = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wvjdl5fCfuuN",
        "outputId": "cfcc7a65-4ef6-448d-d7dd-3df6f1db3ea3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8     0.087951\n",
              "14    0.070361\n",
              "13    0.070361\n",
              "22    0.061566\n",
              "11    0.061566\n",
              "12    0.061566\n",
              "9     0.061566\n",
              "10    0.061566\n",
              "17    0.052770\n",
              "25    0.049252\n",
              "6     0.047493\n",
              "23    0.043096\n",
              "24    0.043096\n",
              "28    0.036939\n",
              "16    0.035180\n",
              "15    0.035180\n",
              "26    0.024626\n",
              "27    0.024626\n",
              "5     0.015831\n",
              "19    0.008795\n",
              "29    0.007036\n",
              "0     0.007036\n",
              "18    0.006157\n",
              "21    0.006157\n",
              "1     0.006157\n",
              "20    0.004398\n",
              "2     0.003518\n",
              "4     0.002639\n",
              "3     0.002639\n",
              "7     0.000880\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df_train['pattern'].to_numpy()\n",
        "y_train = df_train['label'].to_numpy()\n",
        "X_test = df_test['Sentence'].to_numpy()\n",
        "y_test = df_test['label'].to_numpy()"
      ],
      "metadata": {
        "id": "Bleh1JJPiKZv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import BERT Model & Tokenizer"
      ],
      "metadata": {
        "id": "y3ECZLzqT5PG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert = AutoModel.from_pretrained('bert-base-uncased') # load pretrained BERT model\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased') # load BERT tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9bkRRGGT-uk",
        "outputId": "c2f549c3-1c03-48c6-c15b-da7ac33f73bc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample data\n",
        "text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n",
        "\n",
        "# encode text\n",
        "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)\n",
        "\n",
        "# output\n",
        "print(sent_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsAB1NEJUJZF",
        "outputId": "c506409d-6422-4dc6-d0dc-7a7feb55b795"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 14924, 4818, 102, 0], [101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in X_train]\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Ju2x6XG-URoK",
        "outputId": "1cf4c0bf-a63c-4053-e966-a387b70d6a4c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4cec3fa350>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len = 15"
      ],
      "metadata": {
        "id": "gWJd4c3IjZlz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    X_train.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    padding='max_length',\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    X_test.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    padding='max_length',\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "metadata": {
        "id": "bGWOBSwrkOai"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(y_train.tolist())\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(y_test.tolist())"
      ],
      "metadata": {
        "id": "UmisMvp6k9OB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define a batch size\n",
        "batch_size = 1\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(test_seq, test_mask, test_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "BefXvwhZlWdK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "iTm7MeQylnYC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture"
      ],
      "metadata": {
        "id": "FfK_wvUllreZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      self.dropout = nn.Dropout(0.1) # dropout layer\n",
        "      self.relu = nn.ReLU() # relu activation function\n",
        "      self.fc1 = nn.Linear(768,512) # dense layer 1\n",
        "      self.fc2 = nn.Linear(512,len(np.unique(y_train))) # dense layer 2 (Output layer)\n",
        "      self.softmax = nn.LogSoftmax(dim=1) #softmax activation function\n",
        "\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "      x = self.relu(x)\n",
        "      x = self.dropout(x)\n",
        "      x = self.fc2(x) # output layer\n",
        "      x = self.softmax(x) # apply softmax activation\n",
        "      return x"
      ],
      "metadata": {
        "id": "JpE_Kwl6lpEs"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "4Ewpo0ezlt_s"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)"
      ],
      "metadata": {
        "id": "Rw8ghFTdmRsq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compute the class weights\n",
        "class_wts = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "\n",
        "print(class_wts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDNiLFcQmaGm",
        "outputId": "fb799c34-b5d5-4cae-b84d-9635117d7f46"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 4.7375      5.41428571  9.475      12.63333333 12.63333333  2.10555556\n",
            "  0.70185185 37.9         0.379       0.54142857  0.54142857  0.54142857\n",
            "  0.54142857  0.47375     0.47375     0.9475      0.9475      0.63166667\n",
            "  5.41428571  3.79        7.58        5.41428571  0.54142857  0.77346939\n",
            "  0.77346939  0.67678571  1.35357143  1.35357143  0.90238095  4.7375    ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 100"
      ],
      "metadata": {
        "id": "2aWUORWtmhUP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finetuning"
      ],
      "metadata": {
        "id": "LYmNgzCXm3SA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        " \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "tL1XckC_m0KC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "AEdz1Cbem6TW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hXZ-Ybrm9jl",
        "outputId": "13df9f97-56b5-42b5-ae91-fe9b3e3b4a37"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 3.169\n",
            "Validation Loss: 4.103\n",
            "\n",
            " Epoch 2 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.981\n",
            "Validation Loss: 4.059\n",
            "\n",
            " Epoch 3 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.892\n",
            "Validation Loss: 3.608\n",
            "\n",
            " Epoch 4 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.787\n",
            "Validation Loss: 3.665\n",
            "\n",
            " Epoch 5 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.737\n",
            "Validation Loss: 3.674\n",
            "\n",
            " Epoch 6 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.670\n",
            "Validation Loss: 4.497\n",
            "\n",
            " Epoch 7 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.604\n",
            "Validation Loss: 3.629\n",
            "\n",
            " Epoch 8 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.563\n",
            "Validation Loss: 3.929\n",
            "\n",
            " Epoch 9 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.519\n",
            "Validation Loss: 3.238\n",
            "\n",
            " Epoch 10 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.483\n",
            "Validation Loss: 3.447\n",
            "\n",
            " Epoch 11 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.485\n",
            "Validation Loss: 3.584\n",
            "\n",
            " Epoch 12 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.431\n",
            "Validation Loss: 3.560\n",
            "\n",
            " Epoch 13 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.389\n",
            "Validation Loss: 3.236\n",
            "\n",
            " Epoch 14 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.390\n",
            "Validation Loss: 3.521\n",
            "\n",
            " Epoch 15 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.354\n",
            "Validation Loss: 4.679\n",
            "\n",
            " Epoch 16 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.353\n",
            "Validation Loss: 3.517\n",
            "\n",
            " Epoch 17 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.320\n",
            "Validation Loss: 3.880\n",
            "\n",
            " Epoch 18 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.267\n",
            "Validation Loss: 3.443\n",
            "\n",
            " Epoch 19 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.258\n",
            "Validation Loss: 3.348\n",
            "\n",
            " Epoch 20 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.218\n",
            "Validation Loss: 3.319\n",
            "\n",
            " Epoch 21 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.231\n",
            "Validation Loss: 3.293\n",
            "\n",
            " Epoch 22 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.226\n",
            "Validation Loss: 3.378\n",
            "\n",
            " Epoch 23 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.179\n",
            "Validation Loss: 3.816\n",
            "\n",
            " Epoch 24 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.169\n",
            "Validation Loss: 3.835\n",
            "\n",
            " Epoch 25 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.131\n",
            "Validation Loss: 3.852\n",
            "\n",
            " Epoch 26 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.150\n",
            "Validation Loss: 3.031\n",
            "\n",
            " Epoch 27 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.120\n",
            "Validation Loss: 3.265\n",
            "\n",
            " Epoch 28 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.099\n",
            "Validation Loss: 2.977\n",
            "\n",
            " Epoch 29 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.078\n",
            "Validation Loss: 3.758\n",
            "\n",
            " Epoch 30 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.052\n",
            "Validation Loss: 3.875\n",
            "\n",
            " Epoch 31 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.101\n",
            "Validation Loss: 2.614\n",
            "\n",
            " Epoch 32 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.035\n",
            "Validation Loss: 3.210\n",
            "\n",
            " Epoch 33 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.025\n",
            "Validation Loss: 3.921\n",
            "\n",
            " Epoch 34 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.051\n",
            "Validation Loss: 3.350\n",
            "\n",
            " Epoch 35 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.006\n",
            "Validation Loss: 4.088\n",
            "\n",
            " Epoch 36 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.037\n",
            "Validation Loss: 3.849\n",
            "\n",
            " Epoch 37 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.045\n",
            "Validation Loss: 3.185\n",
            "\n",
            " Epoch 38 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.002\n",
            "Validation Loss: 3.165\n",
            "\n",
            " Epoch 39 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.000\n",
            "Validation Loss: 2.589\n",
            "\n",
            " Epoch 40 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 2.015\n",
            "Validation Loss: 2.822\n",
            "\n",
            " Epoch 41 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.963\n",
            "Validation Loss: 2.959\n",
            "\n",
            " Epoch 42 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.976\n",
            "Validation Loss: 3.519\n",
            "\n",
            " Epoch 43 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.978\n",
            "Validation Loss: 4.610\n",
            "\n",
            " Epoch 44 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.966\n",
            "Validation Loss: 3.404\n",
            "\n",
            " Epoch 45 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.981\n",
            "Validation Loss: 3.778\n",
            "\n",
            " Epoch 46 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.951\n",
            "Validation Loss: 3.445\n",
            "\n",
            " Epoch 47 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.892\n",
            "Validation Loss: 4.672\n",
            "\n",
            " Epoch 48 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.961\n",
            "Validation Loss: 2.997\n",
            "\n",
            " Epoch 49 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.909\n",
            "Validation Loss: 5.046\n",
            "\n",
            " Epoch 50 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.978\n",
            "Validation Loss: 3.717\n",
            "\n",
            " Epoch 51 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.961\n",
            "Validation Loss: 3.572\n",
            "\n",
            " Epoch 52 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.962\n",
            "Validation Loss: 3.744\n",
            "\n",
            " Epoch 53 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.889\n",
            "Validation Loss: 4.461\n",
            "\n",
            " Epoch 54 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.944\n",
            "Validation Loss: 4.283\n",
            "\n",
            " Epoch 55 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.911\n",
            "Validation Loss: 4.393\n",
            "\n",
            " Epoch 56 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.997\n",
            "Validation Loss: 3.140\n",
            "\n",
            " Epoch 57 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.922\n",
            "Validation Loss: 4.010\n",
            "\n",
            " Epoch 58 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.931\n",
            "Validation Loss: 3.488\n",
            "\n",
            " Epoch 59 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.937\n",
            "Validation Loss: 4.058\n",
            "\n",
            " Epoch 60 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.900\n",
            "Validation Loss: 4.011\n",
            "\n",
            " Epoch 61 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.927\n",
            "Validation Loss: 2.661\n",
            "\n",
            " Epoch 62 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.948\n",
            "Validation Loss: 5.014\n",
            "\n",
            " Epoch 63 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.904\n",
            "Validation Loss: 3.607\n",
            "\n",
            " Epoch 64 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.835\n",
            "Validation Loss: 3.483\n",
            "\n",
            " Epoch 65 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.933\n",
            "Validation Loss: 4.050\n",
            "\n",
            " Epoch 66 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.977\n",
            "Validation Loss: 4.365\n",
            "\n",
            " Epoch 67 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.946\n",
            "Validation Loss: 3.870\n",
            "\n",
            " Epoch 68 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.903\n",
            "Validation Loss: 4.274\n",
            "\n",
            " Epoch 69 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.895\n",
            "Validation Loss: 4.289\n",
            "\n",
            " Epoch 70 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.924\n",
            "Validation Loss: 3.497\n",
            "\n",
            " Epoch 71 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.918\n",
            "Validation Loss: 4.149\n",
            "\n",
            " Epoch 72 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.927\n",
            "Validation Loss: 4.078\n",
            "\n",
            " Epoch 73 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.902\n",
            "Validation Loss: 4.287\n",
            "\n",
            " Epoch 74 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.941\n",
            "Validation Loss: 4.845\n",
            "\n",
            " Epoch 75 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.903\n",
            "Validation Loss: 4.250\n",
            "\n",
            " Epoch 76 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.849\n",
            "Validation Loss: 3.738\n",
            "\n",
            " Epoch 77 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.993\n",
            "Validation Loss: 4.238\n",
            "\n",
            " Epoch 78 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.912\n",
            "Validation Loss: 5.274\n",
            "\n",
            " Epoch 79 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.899\n",
            "Validation Loss: 3.271\n",
            "\n",
            " Epoch 80 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.906\n",
            "Validation Loss: 3.750\n",
            "\n",
            " Epoch 81 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.949\n",
            "Validation Loss: 3.689\n",
            "\n",
            " Epoch 82 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.860\n",
            "Validation Loss: 3.831\n",
            "\n",
            " Epoch 83 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.948\n",
            "Validation Loss: 5.098\n",
            "\n",
            " Epoch 84 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.889\n",
            "Validation Loss: 3.329\n",
            "\n",
            " Epoch 85 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.936\n",
            "Validation Loss: 3.930\n",
            "\n",
            " Epoch 86 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.894\n",
            "Validation Loss: 4.269\n",
            "\n",
            " Epoch 87 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.906\n",
            "Validation Loss: 3.284\n",
            "\n",
            " Epoch 88 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.914\n",
            "Validation Loss: 3.580\n",
            "\n",
            " Epoch 89 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.940\n",
            "Validation Loss: 5.377\n",
            "\n",
            " Epoch 90 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.850\n",
            "Validation Loss: 4.472\n",
            "\n",
            " Epoch 91 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.944\n",
            "Validation Loss: 5.113\n",
            "\n",
            " Epoch 92 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.869\n",
            "Validation Loss: 4.261\n",
            "\n",
            " Epoch 93 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.923\n",
            "Validation Loss: 4.795\n",
            "\n",
            " Epoch 94 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.926\n",
            "Validation Loss: 3.406\n",
            "\n",
            " Epoch 95 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.891\n",
            "Validation Loss: 4.063\n",
            "\n",
            " Epoch 96 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.908\n",
            "Validation Loss: 4.075\n",
            "\n",
            " Epoch 97 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.835\n",
            "Validation Loss: 3.906\n",
            "\n",
            " Epoch 98 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.938\n",
            "Validation Loss: 4.205\n",
            "\n",
            " Epoch 99 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.847\n",
            "Validation Loss: 4.032\n",
            "\n",
            " Epoch 100 / 100\n",
            "  Batch    50  of  1,137.\n",
            "  Batch   100  of  1,137.\n",
            "  Batch   150  of  1,137.\n",
            "  Batch   200  of  1,137.\n",
            "  Batch   250  of  1,137.\n",
            "  Batch   300  of  1,137.\n",
            "  Batch   350  of  1,137.\n",
            "  Batch   400  of  1,137.\n",
            "  Batch   450  of  1,137.\n",
            "  Batch   500  of  1,137.\n",
            "  Batch   550  of  1,137.\n",
            "  Batch   600  of  1,137.\n",
            "  Batch   650  of  1,137.\n",
            "  Batch   700  of  1,137.\n",
            "  Batch   750  of  1,137.\n",
            "  Batch   800  of  1,137.\n",
            "  Batch   850  of  1,137.\n",
            "  Batch   900  of  1,137.\n",
            "  Batch   950  of  1,137.\n",
            "  Batch 1,000  of  1,137.\n",
            "  Batch 1,050  of  1,137.\n",
            "  Batch 1,100  of  1,137.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.999\n",
            "Validation Loss: 3.587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "DSj7CQIk4cDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(10,8))\n",
        "fig.suptitle('Loss per Epoch', fontsize=20)\n",
        "plt.xlabel('Epoch', fontsize=18)\n",
        "plt.ylabel('Loss', fontsize=18)\n",
        "plt.plot(train_losses, label='Train')\n",
        "plt.plot(valid_losses, label='Validation')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "pINtrzRToo73",
        "outputId": "25d63dc2-3b32-4a17-f618-74a358a18577"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4c7390ec10>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAIhCAYAAAAVei3TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOyde5wkZX3un3e6Z3ruu+yNXVhgF0RAI4SbNxRZzYlRFKLBCyYGYhKP5qImRz3q8YIak5MjUePRo0GJF9Tg3YDBqKAQ0BjY5bYK6LKwLrsLuzuzO9eemb6954+33urq6reuXV1VM/18P5/5dE93dXV1T03VU8/vJqSUIIQQQggh+aIv6w0ghBBCCCHtUKQRQgghhOQQijRCCCGEkBxCkUYIIYQQkkMo0gghhBBCcghFGiGEEEJIDqFII4QQAiHEVUIIKYS4KOttIYQoKNIIWeFYJ142ROwy+nsO+Lko6+0khCwfillvACGErDDe7/PcnrQ2ghCy/KFII4SQBJFSXpX1NhBCVgYMdxJCbIQQJSHEO4QQO4UQZSHEjBDidiHEKz2Wv0QIcYsQ4nEhxJIQ4oAQ4jYhxJ+5ljtZCHGNEOJhIcSCEOKI9R6fFkKsDbltUghxqxDiOCHEdUKIQ9a6dgghXuPzuhcKIW4SQkxY27hbCPFhIcRqw7J7rJ9xIcRHrPtVIcRVYbYxCs4cMCHEFUKIe6zPc0gI8c9CiI0erztVCPFFIcR+IUTF+s6/KIQ41WP5ghDiDUKInwghpq33eFgI8Vmf11wmhLjT2geOCCGuF0Icn+TnJ4QEQyeNEAIAEEIMAPg+gOcBeAjAJwEMA7gMwFeFEL8ppXyXY/nXA/gnAE8AuBHABIANAM4E8EcA/p+13CYAdwEYB3ATgG8CGASwFcBrAXwCwGTIzTwGwE8BTAH4HIDVAF4J4MtCiOOllB92fab3AbgKwBEA3wVwyNq+twJ4sRDiWVLKGdd7DAD4EYA1AH4AYAbAoyG3Lw5/BeC3AXwVwL8DeA7U93eREOIZUsrDjs9zPoCbAYwBuAHAAwBOB/AHAC4VQvyWlPIux/IDUJ/7vwF4DMBXrM+zBcDLANwBYJdre/4MwCXW+m8D8AwArwJwlrUPLCX54QkhPkgp+cMf/qzgHwBS/asHLvdOa9mbABQdj2+AyqWSAJ7teHwHgCUAGwzrWue4/5fWa99sWG4EwFCUzwHgawD6HI9vhRJhFQAnOx7fZi3/UwCrXeu60nruo67H9ee8GcBInO8ZShSaft7hWv4qa/kKgLNdz33Ueu5ax2MCwIPW47/vWv5V1uMPub6bv7UevwFAyfWaEoD1hu2ZAfA017JfsZ57Zdb7M3/400s/mW8Af/jDn+7+RBBpuwA0AJxueO6PrfX8s+OxHQDmARwTsF4t0l6fwOeoAdhqeE4LjPc5Hvu29dhTPdZ3D4BDrse0SDsr7vfs8zPlsc3XGta1CsotXNDiCsAF1vI/9Xj/263nL7R+L1jrKAM4LsT26+35G8NzWvBenfX+zB/+9NIPc9IIIRBCjAF4EoADUsqHDIv8yLo92/HYl6HCoQ8IIT4qhPhdIcR6w2tvADAH4JNCiG8KIV4vhHiqEELE2NS9UkpT6PFWw/Y9C0AVwCus/K+WH6iw5npDTtwigPtjbBsAQEopPH7acuAsbjOsYxrAvVBh4TOsh8+xbn/kXt71uP4OTocSe/dLKQ9E+AjbDY89Zt0eE2E9hJAOYU4aIQRQJ3MAeNzjef24LTSklB8RQkxA5TC9CcBbAEghxG0A3ial3G4t92shxNOhnJrfAfByaxWPCSGullJ+PMJ2HvR4/AnX5wCAtVDHuPcFrHMUrTlxh6SUafaVC/uZov6N9O3+iNszZXisZt0WIq6LENIBdNIIIQAwbd0aKwoBbHItBwCQUn5RSvlMKEF0MYBrAVwI4PtOV01K+aCU8lXWcucBeAfU8ecfhRB/HGE7j/V4XG+3c/umARz1cbb0z69d60q78W/YzxT1b6TFFqsyCVmmUKQRQiClnAWwG8DxHm0Ztlm3d3u8fkpKeZOU8k8BfB6qMvJCw3I1KeUOKeXfA7jcevh3I2zqiUKILYbHL7Ju73E89jMAxwghnhph/VnwPPcDQohVAH4TKvT6oPWw/mwXeazH/Td6CEqonSmEOC6RLSWEpApFGiFE889QFYQfFkLYYS0hxDoA73Esox/f5pFXtsG6LVvLnWuJDjfHOpcLSQHA3wsh7GOXEGIrVLi1BuBLjmU/at1+xiRShBAjQohnRnjvbvFaIcTZrseuggpv/otstrz4CYBfAniOEOIy58LW788F8CuothqQUtah2qAMAfi0EKLkes2ARw4hISQnMCeNkB5BCPF5n6f/DMDVAF4E4FIA9wkhboIqDHgFlPD6P1LKOxyv+TaAOSHEz6CqIgWUUDgfqvLzZmu51wL470KIO6DcuqMATgHwUqgWHh+L8DHuh+rbtUMI8QM0+6StBvB2KeVuvaCU8hYhxDsA/B2AXdbneRQqB+0kKAfrDqg8ucQIaHz7HSnlva7HvgfgJ0KIr0HllT3H+tkDFRYGoMpzhRBXAPghVN+6f4Vyy06DciNnAfyhlLLhWPf7ob6vlwL4lRDiu9ZyJ0D1ZnsblPNJCMkjWZeX8oc//OnuD4JbQ0hYfcSgqgnfBeDnUO0fZqGEzOWG9b4BSqg9AuWGHYEKyb0dwJhjuWcA+BSA+6xlFgA8DNWM9jcifo5bARwH5ZgdggoH3g3gNT6vew5Ub7UDUD3JDkNVTn4EwHmuZfcA2NPF7/lKx/JXWY9dBNW37V7ruzlsfTebPN7nNADXQQm6qnX7JQCneSxfBPAXAO6EqrKdh2q3cg2AJ5m2x7COLdZzn896f+YPf3rpR0iZdo4sIYRERwghAdwmpbwo621JAstxex+AbVLKW7PdGkJIHmFOGiGEEEJIDqFII4QQQgjJIRRphBBCCCE5hDlphBBCCCE5hE4aIYQQQkgOoUgjhBBCCMkhFGmEEEIIITmEIo0QQgghJIdQpBFCCCGE5BCKNEIIIYSQHEKRRgghhBCSQyjSCCGEEEJyCEUaIYQQQkgOoUgjhBBCCMkhFGmEEEIIITmEIo0QQgghJIdQpBFCCCGE5BCKNEIIIYSQHEKRRgghhBCSQyjSCCGEEEJyCEUaIYQQQkgOoUgjhBBCCMkhFGmEEEIIITmEIo0QQgghJIdQpBFCCCGE5BCKNEIIIYSQHEKRRgghhBCSQyjSCCGEEEJyCEUaIYQQQkgOoUgjhBBCCMkhFGmEEEIIITmEIo0QQgghJIdQpBFCCCGE5BCKNEIIIYSQHEKRRgghhBCSQyjSCCGEEEJyCEUaIYQQQkgOoUgjhBBCCMkhFGmEEEIIITmEIo0QQgghJIdQpBFCCCGE5JBi1huQNOvWrZNbtmzJejMIIYQQQgLZsWPHhJRyvem5FSfStmzZgu3bt2e9GYQQQgghgQghfu31HMOdhBBCCCE5JFMnTQixB8AsgDqAmpTyPNfzFwH4VwCPWg99S0r5gTS3kRBCCCEkC/IQ7twmpZzwef52KeVLUtsaQgghhJAckAeR1nWq1Sr27duHxcXFrDdlxTA4OIjNmzejv78/600hhBBCViRZizQJ4AdCCAngn6SU1xiWeZYQ4j4ABwC8VUr5C/cCQojXA3g9AJx44oltK9i3bx/GxsawZcsWCCES/QC9iJQSk5OT2LdvH7Zu3Zr15hBCCCErkqwLB54jpTwHwIsA/LkQ4kLX83cDOElKeRaA/wvgO6aVSCmvkVKeJ6U8b/369irWxcVFrF27lgItIYQQWLt2LZ1JQgghpItkKtKklPut20MAvg3g6a7nZ6SUc9b9mwD0CyHWxXkvCrRk4fdJCCGEdJfMRJoQYkQIMabvA/htAD93LbNRWGpACPF0qO2dTHtbCSGEEELSJsuctGMBfNvSYEUAX5FS/rsQ4g0AIKX8NIDLALxRCFEDsADg1VJKmdUGx2VychIveMELAABPPPEECoUCdFj2zjvvxMDAgOdrt2/fji9+8Yv4+Mc/nsq2EkIIISQfiGWoeXw577zzpHviwIMPPogzzjgjoy1q5aqrrsLo6Cje+ta32o/VajUUi1nXcEQnT98rIYQQshwRQuxw94nVLD9l0CHvv/EXeODATKLrfMpx43jfS58a6TVXXnklBgcHcc899+CCCy7Aq1/9arz5zW/G4uIihoaG8LnPfQ6nnXYabr31Vlx99dX47ne/i6uuugp79+7FI488gr179+Itb3kL3vSmNyX6WQghhBCSD3pOpOWJffv24ac//SkKhQJmZmZw++23o1gs4uabb8a73vUufPOb32x7zUMPPYQf//jHmJ2dxWmnnYY3vvGN7FVGCCGErEB6TqRFdby6ySte8QoUCgUAwPT0NK644grs2rULQghUq1Xjay6++GKUSiWUSiVs2LABBw8exObNm9PcbEIIIYSkQNZ90nqakZER+/573vMebNu2DT//+c9x4403evYgK5VK9v1CoYBardb17SSEEEJI+lCk5YTp6Wkcf/zxAIDPf/7z2W4MIYQQQjKHIi0nvP3tb8c73/lOnH322XTHCCGEEMIWHCQ+/F4JIYSQzvBrwUEnjRBCCCHROPxL4O9OBKb2Zr0lKxqKNEIIIYRE48gjwNI0MLk76y1Z0VCkEUIIISQatSV1W5nLdjtWOBRphBBCCIlG3erluUSR1k0o0gghhBASjTqdtDSgSCOEEEJINOoVdbs0m+12rHAo0lJg27Zt+P73v9/y2Mc+9jG88Y1vNC5/0UUXQbcRefGLX4ypqam2Za666ipcffXVvu/7ne98Bw888ID9+3vf+17cfPPNUTefEEIIaaVmiTQ6aV2FIi0FLr/8clx//fUtj11//fW4/PLLA1970003YfXq1bHe1y3SPvCBD+C3fuu3Yq2LEEIIsbGdNIq0btJzA9bxvXcAT+xMdp0bnwa86H97Pn3ZZZfh3e9+NyqVCgYGBrBnzx4cOHAA//Iv/4K//uu/xsLCAi677DK8//3vb3vtli1bsH37dqxbtw4f+tCH8IUvfAEbNmzACSecgHPPPRcA8JnPfAbXXHMNKpUKnvSkJ+G6667DvffeixtuuAG33XYb/uZv/gbf/OY38cEPfhAveclLcNlll+GWW27BW9/6VtRqNZx//vn41Kc+hVKphC1btuCKK67AjTfeiGq1iq9//es4/fTTk/2+CCGELG+Yk5YKdNJSYM2aNXj605+O733vewCUi/bKV74SH/rQh7B9+3bcf//9uO2223D//fd7rmPHjh24/vrrce+99+Kmm27CXXfdZT/38pe/HHfddRfuu+8+nHHGGbj22mvx7Gc/G5dccgk+/OEP495778Upp5xiL7+4uIgrr7wSX/3qV7Fz507UajV86lOfsp9ft24d7r77brzxjW8MDKkSQgjpQezqTuakdZPec9J8HK9uokOel156Ka6//npce+21+NrXvoZrrrkGtVoNjz/+OB544AGceeaZxtfffvvteNnLXobh4WEAwCWXXGI/9/Of/xzvfve7MTU1hbm5ObzwhS/03ZZf/vKX2Lp1K5785CcDAK644gp88pOfxFve8hYASvQBwLnnnotvfetbHX92QgghKwz2SUsFOmkpcemll+KWW27B3XffjXK5jDVr1uDqq6/GLbfcgvvvvx8XX3wxFhcXY637yiuvxCc+8Qns3LkT73vf+2KvR1MqlQAAhUKBw94JISQOT+wEdq3gQi3mpKUCRVpKjI6OYtu2bXjd616Hyy+/HDMzMxgZGcGqVatw8OBBOxTqxYUXXojvfOc7WFhYwOzsLG688Ub7udnZWWzatAnVahVf/vKX7cfHxsYwO9tuRZ922mnYs2cPHn74YQDAddddh+c973kJfVJCCCG442PATW/Neiu6R53VnWlAkZYil19+Oe677z5cfvnlOOuss3D22Wfj9NNPx2te8xpccMEFvq8955xz8KpXvQpnnXUWXvSiF+H888+3n/vgBz+IZzzjGbjgggtakvxf/epX48Mf/jDOPvts7N7dnK82ODiIz33uc3jFK16Bpz3taejr68Mb3vCG5D8wIYT0KkuzTSGzEtHhTjppXUVIKbPehkQ577zzpO4xpnnwwQdxxhlnZLRFKxd+r4QQ4sHnXwIcfgh428NZb0l3+NZ/B+6/Hhg6Bvife7LemmWNEGKHlPI803N00gghhJCkqcytbCetTictDSjSCCGEkKSplJttKlYi+rM1qs3QJ0mcnhFpKy2smzX8PgkhxIdqeWU7aU5hRjeta/SESBscHMTk5CSFRUJIKTE5OYnBwcGsN4UQQvJJZQ5o1ICVet5xClBWeHaNnmhmu3nzZuzbtw+HDx/OelNWDIODg9i8eXPWm0EIIfmkUla39SpQHMh2W7oBRVoq9IRI6+/vx9atW7PeDEIIIb1AvdZMrK9XVq5IEwVA1hnu7CI9Ee4khBBCUqM637y/UvPSahXVfgMAKpzf2S0o0gghhJAk0aFOYOVWeNYrwPBadZ9OWtegSCOEEEKSpOoUaSvUSasvAcNr1H3mpHUNijRCCCEkSZyiZaWKtFoFGLJEGp20rkGRRgghhCRJz4Q7mZPWbSjSCCGEkCTphcKBegUYGAP6+umkdRGKNEIIISRJKg6R1ljBTlpxACiNMieti1CkEUIIIUmy0sOdUqqxUIUB5abRSesaFGmEEEJIkqz0cGejDkAChVI4J23H54Gpx9LYshUHRRohhBCSJJUVLtL0NIVCPzAwCiz5FA4szgA3vhm47/p0tm2FQZFGCCGEJEla4c5GA7j+94FHbu3ee5jQwrMYwklbOKJul6a7v10rEIo0QgghJEnSCndWy8BD3wX2/qx772GiZn0m20nzE2lH1S3z1mJBkUYIIYQkSUu4s4tOWm3Rul3q3nuY0MKzUAJKY/5OWlk7aeylFgeKNEIIISRJ0gp36vFTaee9OcOdoZ00irQ4UKQRQgghSVKdB0qr1P2uhjsXu/8eJuqOcGdpVE0ckNK8LEVaR1CkEUII0DzhEdIplXlgaLW6300BVVuwblMOd+r3K1hOmmwA1QXzslqkcXRULCjSCCFkcjfwt8cBhx7MekvISqBSdoi0boY7tZOWcsNc20kbUDlpgHdeGp20jqBII4SQ6X2ArANTe7PeErISqM4Dgyk4aXZOWkaFA8UB5aQB3iKMIq0jKNIIIUQ7EV4hG0KiUJkHho5R91didacd7rRmdwLeThqrOzsiU5EmhNgjhNgphLhXCLHd8LwQQnxcCPGwEOJ+IcQ5WWwnIWSFo4dg15iXhkMPArtuznorljeVMjA4DkB02UmzLipSD3da71dwOmkB4c56JX0xuQIoZr0BALZJKSc8nnsRgFOtn2cA+JR1SwghyaFPpHTSgJ98HNhzB/BXO7PekuVLZR7oH1HVj6mItLTDnU4nLWROGqCEXLHU3W1bYeQ93HkpgC9Kxc8ArBZCbMp6owghKwztDPBKX7mJzo75JBpSqu9vYESJmEate+9lV3em3YLD+n/RfdIAn5y0I0D/sLXMTPe3bYWRtUiTAH4ghNghhHi94fnjATzm+H2f9VgLQojXCyG2CyG2Hz58uEubSghZsdgijU4aGlWK1U6oLamWFAPDKThpGfVJqzkGrPvlpDUayklbfaL6nXlpkclapD1HSnkOVFjzz4UQF8ZZiZTyGinleVLK89avX5/sFhJCVj52uJM5aajXmJvXCXokVL/lpKXRJy2r6s5CyT8nrTKrBCtFWmwyFWlSyv3W7SEA3wbwdNci+wGc4Ph9s/UYIYQkhz7p0ElTTlqjpsQaiY4OFetwZ1f7pGUV7nT0SRvwcdJ0Zefqk9QtRVpkMhNpQogRIcSYvg/gtwH83LXYDQD+0KryfCaAaSnl4ylvKiFkpWO34KCDZOdQ0U2Lh57buZLDnc4+aYUiUBwyCzBdNLDa8lr8BrETI1lWdx4L4NtCCL0dX5FS/rsQ4g0AIKX8NICbALwYwMMAygD+KKNtJYSsZBrMSbPRDlptqZlvRMKTSbgzq5w0q1KzNGoWYLZI0+FOFg5EJTORJqV8BMBZhsc/7bgvAfx5mttFCOlB7HAnE+YpWDvEGe7s609pLFRG1Z2FfnU7MGrOSbNFGsOdccm6cIAQQrKHEweasB1JZ7SFO7sp0qz3Sj0nbUm5hCoSFuykrdoMQFCkxYAijRBCbCeNeVicvtAhWqykEu7UTlraY6Eq6rNpBsb8nbShY4DSOEVaDCjSCCGETloTnZPGIop4aHdrYCQFJy2jnLS6S6R5OWnlI0qcFfrVZAKv0VHEE4o0Qgip0z2yoZPWGRWnSOuyk6ZFmmyk2zJFhzs1Az7hzqHV6n5plIUDMaBII4QQNrNtwukLnaHFShoizfk3SjPkWa+q9huakk/hwNAx1jJjDHfGgCKNEELopDVpOFpwkOhUy4AoKIHW9XCnY39NM+RZcztpYx5O2hFgaI26T5EWC4o0QghhiK8JBWtnVMrKRRMivcIBIN0Kz3ql2SMNaOakNRqty9FJ6xiKNEIIscOdDPHZgpWh33hU5pRIA9JpwaHFUqrhzkqzRxrQHA2le8Rp3CKNEwciQ5FGCCF0j5rUORaqI6ploH9Y3S/0N0VvV95rERhcpe53Uwy6qVeAostJA1rz0hoNJdKGrXDnAJ20OFCkEUIInbQmDTaz7YhKWTWyBbob7pRSFQ4Mjqvf0/x7mfqkAa1O2dKMqjp1hzvdIVHiC0UaIYRoF0LW03Uk8kgvVnc2GsDtH1F9vTqlMtcM/xUGurc/1StKBNlOWtrhTld1J9DqlDkb2QJKpEG2h0SJLxRphBDiPJH2spsmpRKqQG85aRO/BG55P/DgjZ2vyx3u7JaTpvfTQasPWarhzqXWcKcWpU4nbcESvC0iDQx5RoQijRBCnCfSXhInbpwn+l7KSZs/rG7Lk52vK61wp/77ZBHurFdbCwdMOWm2k+ZoweFehgRCkUYIIc7k7l4K87lxfg+9VN05P6FuF5IId863hjtlA2jUO1+vG9tJ0+HOtPukOZ00Q07awpS6pZPWERRphBBS71Fx4qZXnTTtoCWRk1adbw13At0RUFmKtHo1OCet7BXu5GioKFCkEUKIszlnTztpjvmPvRT21U5a0uHOPi3SupAvVnOJtFTDnUutY6GMOWmmwgH4O2mNhsqLJDYUaYQQUq80TyJ00hS9JFbLCYm0Rl19b85wJ9Adkab30yz6pLW14BgBINpz0krjQKGofg8j0r7+h8ANf5n45i5nKNIIIaRea55EekmcuGnJzaOTFplqWd2mEe6suas7M2zBIYQSpu7qzqHVzd9LVoGD39SBJ34OHN2T6KYudyjSCCGkXsmmSi5vMCets/VULJHmrO4E0slJSzvc6RRpgMpLc/dJ05WdQNNd9MtJm5/o7RY4BijSCCGkXmle6ffyScKZk9ZLYV/dgmNxqjkWKw7aJVrJ4c5GXVWsOvukAQYnzTG3E1A5bIWSd7izugBUZnv7IskARRohhNSrTZHWSw6Sm1510uYnAGGdDnXCexwyCXemPHFAiyhnnzTActIcIq18pFWkAc3RUCZ0yLmX0w0MUKQRQkij2gx39rSTZom0wkDviLRGQ+VPHbNV/d5JXlqm4c6UWnDoz1II4aQNr2ldxlekWW4mnbQWKNIIIb2NlK3hzl4RJyZ0qG9gtHe+h4WjKny3/jTr9w7y0trCnV1swaFFmi54SatPmi3S3E7aWNNJazRU6NjopHkUDthOWo/sdyGhSCOE9DY6D8tuwUEnDaWx3nE0dPuNdU+2fu/ASfMKdza60SfNEjPFIeVqpRXu1CLNmJNmuWRL00r4Rgp3Wk5aL+VChoAijRDS2+iTju6a3ivixETdIdJ6RazOJyjS7HDniLrtdrizMAD09Vnh6ZScNDsnzSXSnDlp7rmd9jJj3tWddriTIs0JRRohpLfRwqQ4qE48vZy4rB2fgdHeEavaSdPhzo5Emg53ukVal8Kd/UPqfrGLg9zd6M/iDnc6c9Lc0wY0YZy0RrU7s06XKRRphJDeRp90+opA/2Bvh1vqjtBvbbE3RvRoJ238eKB/pLNeaWlXdxYtkZZquNN6H3e4U+8z9RpQjiPSJpr36abZUKQRQnobOxF6QJ306KRZoV+Z7tDurNDO2fBaVY3YiUhLNdy5qC4qACUGU6vudFQAO7Hnd842nTRTdafXxAHtpAG9faHkgiKNJIuUqrKHkOWCs+1EzztpjnAn0BuOxvwEUFqlQobDazoPdxYHgb6C+r2b4c7aQtOxK5bSE9R2Tpph4gCg8tK8wp0DlttmEpROkdYL+11IKNJIsvziW8DVp6Z3VUeIH9UFYHK3/zLOHJued9Jcla69kJdWngBG1qr7w2s7r+7UwgnobrizuqAEIWCFO9Ny0jxEmnYPKw6RNri6dRm9X5nctPmJ5jop0mwo0kiyTO5WBz2/+WyEpMX2zwGffq7/qB9n36diiU4a0HTSeqHCc34CGF6n7ncq0irl5ncHAH3d7JO22CwcKPSnXzhQdIs0S4Atzalec6VVQKHYuowWae7zg5TKSVu1Wf1OkWZDkUaSRSfO6ltCsmT+EFCd9z/oO3PS+od6+wTRkpOG3nDS5ieAEUukDa3pvJntgNNJ63K4UztpxVJ6f6ugcKfOSRtyuWiAQ6S5nLTFabXvaZHWyxdKLijSSLLoK+9euAIn+Ufvh34ug3bZCv3qpNfLIs3ZJw3oje+iPKEcNEDdLk7HF1VphzttJy3NFhw+Y6GAZk6aOx8NcIg0V4WnruxcdaK67YX9LiQUaSRZ6KSRPKFFmp/L4HbSevkqXuekDfSISJNShTdH1qvfdTVi3CHrlflmbhbQ/Wa2mYo0w4B1QLmJpuHqgI9Is4oGGO5sgyKNJAudNJInbCcthEjr005aD++7veakLU4pYTriyEkD4ueltYm0Luak1RZd4c6URVrbWChdFDBvHq4OeOekUaR5QpFGksUWaXTSSA7QgsvvBObs+9TzTlqP5aTN6x5pWqRZwiJurzR3uLOvAIhCSk5aWjlpDufZid2CYzZGuNMSaUNoLeQAACAASURBVKtPsN6jh/8HXVCkkWSxw5097EaQ+Ozf0VkzUTdhnLSGswVHj4+F0vl5vVLdqUdCOVtwAMk5aUD3QpGZhztdIq04qATp0oxyKP1EmrsFhz31gYUDbijSSLJUKNJITKQEPncxcOc1ya2zGsZJc08cWOHukR+NKgDRFBor/bvQ4mA4qXBn2UOkJRzubDTUhUfRMbsztXCnx1goIZSbNnMAkI324eqAGrsFYXbSBlf3Tpg9AhRpJFm0k1aZz3Y7yPKjtqhcrIWp5NYZKifN4aT1D/b2BUa92qxyBVa+q2g7aY4WHEA8kSalavfiDHcCqldYI2GRpkWMPRYqxXCnPeu2v/25gTFg6jF13+Sk9fWZ53fOH1bFG1r4UaTZUKSRZGHhAIlLN/IZI1V3WhMHZL07id7LgUatWUAB9J6T1j8Yf8h6vaK+vzTCnXq/tge5l9LbZ2tLah/pM8iH0igw7SPSABVKbyscmFAiTYdvKdJsKNJIsrBwgMRFu69JCvxamD5prtmdSW/DcqJeVc5Przga5UklGvTfHVAhzzgNbfX+2ybS+pMXUHq/tqs7B9IT1PVKez6aZmAUmNmv7puqOwEfJ22dtV7BnDQHFGkkWVg4QOKi950kQ2yhnDRH+MZ2kHr0JNGoqu9BOxor/WQ572hkq4k7ZF3vv23hzm44aTrc6SgcaFRVrlq3qVfaR0JpSqMqHw3wdtJKY+0TB3S4Uwg2lHZBkUaSheFOEpduOGn6ZObrpDnCnbY46dH9V+ek9RUB0bfyT5Zlx0goTdz5nZ5OWhdEmttJ085W0rlvxvde8nfSNL4izeGk1WvKudQNhYullb/fRYAijSRHo9E8eDDcSaLSDYFvu3MhJw70vJNm5aT1iqMxf7iZj6aJ66SlGe5056TZ4ekUQp71avtIKI2uzgRUtabXMk6Rpr9rLZZ7fX6uC4o0khzOMFWvOhEkPkmPFKvXms6Cb5801+xOoHdPEjonDegRkTbp4aTFGAuVarhTizSXk5ZG8UB9qX0klEY7aaVVzf3IjVuk6Ua2LU7aCi9YiQBFGkkOpzCjk0aiYoc7ExIGzouGoD5pok91h7cLB1a4OPFC56QBK1+kSdk6XF0zvBZYijFk3XbSRlsf70afNP13KTpy0oB02nDUK+090jR66sCQh4sGhBBpPd4Gx0XmIk0IURBC3COE+K7huSuFEIeFEPdaP3+SxTaSkDiFGUUaiUrSTprzQB80u1Of5PRJb6X3B/OiXmu6JCvd0ViaVX/7Nict5mgoW6S5nLS+YhfDnY7ZnUA6f69aJdhJ86rsBJRIq8wqkQw026A4RdpK3u8i4uFHpsqbATwIYNzj+a9KKf8ixe0hcaky3Ek6IOnK4GpYJ63WFGl00pSoAKw5piv4/7jsEgca59SBsWPDr88v3OluOdEptkhzO2lphDsrwTlpXkUDehnZUN/XwIjDSbPEcnGwdy+SDGTqpAkhNgO4GMBns9wOkhB00kgnJD1SLJKTpt2jXnfSqr3jpLmHq2viTh1INdypqzszCncGVXcGiTSgKVznD6sLA11o0E8nzUnW4c6PAXg7AL/mLr8nhLhfCPENIcQJKW1X9jx0E/Bvb816K6KhT7KDq1f2FTjpDkn3SWvJSQsQaX0OYQL0sJNWc3wXK7zKzj1cXaOdtKgNbb3CnYX+LvZJc4c7U5jfGdQnDTDP7dQMGETa8LrmBAPmpLWQmUgTQrwEwCEp5Q6fxW4EsEVKeSaAHwL4gse6Xi+E2C6E2H748OEubG0G/Op7wD3XZb0V0dD/WCPr6KSR6OiTXKOWjPPQ4qQFTByww509Ppampbpzhferco+E0sQdsl4tAxDNCmFNV6o7XaFV7X4m/T4makve4c5ITpo1GkqPhNIwJ62FLJ20CwBcIoTYA+B6AM8XQnzJuYCUclJKqf9anwVwrmlFUsprpJTnSSnPW79+vWmR5cfSrDpALqcZgvrAMbyWV0IkOkmHy53r8DvoN5whvh5vwdFL1Z3u4eqa4Q7CnQOjqseck65Vd4rmxYUWTamEO6vehQNhc9KA5tQBPRJKw5y0FjITaVLKd0opN0sptwB4NYAfSSn/wLmMEGKT49dLoAoMegNtBSedcNpNtDCjSCNxSLrwxBmyDJo44HbSenX/dZ6A+wdXdth3fkKFdN3NZ4slJbbiVHe6Q51Al8KdC2pf1YJQ77+phDuXvFtwDK5St+62Jk5MOWlOJ405aS3kobqzBSHEBwBsl1LeAOBNQohLANQAHAFwZZbblipOkeZXzpwnbCdtjbovZftVJSFe6HAnkJBIC5uT5mrgCiTjIP30E2o9Fy6j3NJGrVndudLDTmVDI1vN8JroIq1abq/sBJRIS3pcU22xNayqc8TSCHc60wPcrHsycMkngDNe4v36NpFmCHeu5IuDiORCpEkpbwVwq3X/vY7H3wngndlsVcYsWvH6ypz/cnnC6aTJhjrA9w/6v4YQTUu4MwGRpkMmA2Ph+6TpcUhJvP8vvg1MPgw8569Uo9zlQFt15wo+WZqGq2vizO/U4U433Qh3VhdaBWGa4U6/2Z1CAOe81v/1TpFWmQeq84Zw5wre7yKSdXUn8WJZhjsdOWnO3wkJQyVhkabXMbQ6oE+ayxlISpwsTqmfJ3Z2vq60aMlJW+HVne5cKCexRVqa4U7HBbAW1mlVd3qJtDA4CwfcjWwBJdLqS81mtz0ORVpeWa4ira/YzEvo1bweEo9quekIJFI4YO1/g6sDnDRHA1cgOXGyOK1u99ze+brSom3iwAoWaeXJ9spOzVCMIeue4U6rujNJ0VFbbPZIA5o5YqmEO31acIShWFLfSWXOLNL6e7x4xwVFWh5pNJrlyctKpFkWvD5QUaSRKFTLTRc2iQO0LdLGg2d3Op2BJBLmpWyKtEf/o7N1pYlz4kBxUH03Db82lsuY+YkAJy1O4cBI++Na9DZq0dbnR7XcLHIBHOHOtFpwdCDSgOb8TvfcToAV1i4o0vJIdR6AddW1rESadeCwRRrDnSQClXKzsWhSLTgKpWb4xAu3SCsOdd4CoLpgDW4vAL/+6fJppeOu7gRW5smyMq/+xn45aZXZaOFDT5HWhaT+6qI53NltkdaoA7Lu3SctLG0izZmT1uMNpV1QpOURpzBbboUD/UNsY0DiUZ1vhp8SKRxYVPtiseR/sm3UWvs+JeGkaRdty3PU//CBeztbX1q0TBxYwSJt3qNHmkZX1EeZOqBnUbrphkirLZjDnd2uxtWfwatPWlgG/ERajzeUdkGRlkecIm3ZOWnDdNJIPCrl5sE6KSetf1idwMLO7gSSyUlbnFK3Z7xU3T56m/eyjUb00Fq3cE8cAFZmG46yx7QBTZyGtpV57xYcgMr3S4o2Jy2lFhx6/V590sJiO2kTQP9Iq7i19zuKNIAiLZ/o9hvAMhNpdNJITBqN1vBTEqEOfSIrBAwKN+akdbjvaidtzcnAsb/hn5d22/8GPn52PnK/3NWdwMrs/q6Hq494TKiJOhqq0fB20vq6EIp0t+DoK6jQerdFmnakk8xJc7uZvT6azQVFWh5ZWqYirUInjcSk5uixByRX3dk/rCrRfCcOuMKdSfRp0iJtcDWw5bnAY/9lForVReCuzyrnLWsxJGVr6LcXnDT3cHWNLdJCOpx2T740w52uHpTFgIuRJKh3Q6S5hDJz0lqgSMsjyzYnTYu0oebvhIRB90gbXK0cgUT6pJXViSyqk5aESFuwwp1Dq4GtF6r17burfbkHvtN0a7I+Kenqw17KSfMMd0Z00vS0DN9wZ4LFI9XF1upOoDuD3N3otIEkw51tIo1OmhOKtDyinbThtcvLSbPDnWzBQSJStU5yA5bIT7pwwNdJc4T4AOv9k3LSVgEnPRsQfeaQ552fad7P+qJGiwidk6Zznjr9LuYngb87EXjk1s7WkyTlCSVqdGNVN0M6Jy2kk6ZFWpZOWioiTe8jHRYOlEa9w53MSWuBIi2PaGE2fhywtJyctAU6aSQeWpTp/SeJ0J92dgsDIZw0d7iz05w0y0kbXKXctE1ntYu0A/cA+7cDx5+nfs/6pKTnSybtpB3cCSxN52vywrzVyNZrtnBxQFUghnXS9LEuDZFWryrX0+3aBVUxJ4H+P+q4Bce4+h8zhTuZk9YCRVoe0SJt7Lhl5qRZfdL0wZ1OGgmLDnf2J+ik6cKBYkkJEK/E/IZrLFRSTlr/SFP8bb0Q2Le9dYj8XZ9Vn/e811nbm/H/i64+LLhFWod5TpO71e3cwc7WkyTlCe98NM1whKkDdrjTp5ltUuFO+4LG7aT1d392p+2kJZCTBqiea8xJ84UiLY8szap/9sFVqqHickGHO/v61MmHThoJS0u4M6F9Rzu7fk5Go2Ely7tz0hY6G+OzONUcjwYokdaoAnt/pn5fOArs/AZw5iuBsWOb25sltpPmmDgAdO4q2iLtcGfrSZL5w975aJrhteH7pFUc+6+bpJ007TC1hTsDwvpJYOekJSTSAOakBUCRlkcWp9VOrJMrlwNSts6uS8oNIb2B7aSNqJNPIjlpVt6OPdfQ4DI0XHlYgHqNbHTmfCxMqTCn5oRnKvGjQ573fFmdhM7/k/y0unDnGyVV3Xkkh06a30goTZQh62HCnY2knDSH6+ykOND9cGeS1Z0az5y0FVhVHAOKtDyyNKvmDerkyuVAbRGAbOYT9A9TpJHw2Ce54eT2HbeTZjqBmU46SYxDWpxuddJKoyr3bM/tyr3bfq0Sbhuf5kjQz4uTpsdCJdTv0HbSDnW2niTxG66uSSzcaV0AJBbutPbLtnDnQPfDnXaftASqOzVtTlpCDu4KgSItjyzNNp20emV5XFFUXX2C+oda828I8aOacE6a7ewGOGmmHJskEubd4U5AhTwP3KPabhx5BHj6n6rH81IN3Y2ctHoNOPqoup8XJ626qFobBeakRRiynmq409pPiu4WHKXuz4jV/0NJjIXSeIq0ZXDeSwGKtDxii7Rx6/dlUOFpn2SHmrdZn3TI8iHpwoF6VYUs+4eaV/2mg37dlYcFJOMgLU6rnm9Otj5XbdNNb1MnJj0yKi/9yNpy0hJohTC9V+X8jW9WrlSSo5HiEjQSSjO8Rom5MGIhzRYcXk5aMaCKOQmSHAulcQ+57+tT3xnPHwAo0vLJ0owSaAOj6vflUDzgbKGgb1k4QMLS1ietw33H6cwVfU6SpnBnIk7adLuTtvnpSjCWJ4Bzrmie6PLSsqYtJy2B72HyEXV70rMAyKZACsuRR4H/+idgz0/ib4OboOHqmihTB6qOnEo3iVd3euSkpdEnzQ53dtonzRJpQ2ta80E1xSE6aRaGb4dkztKsEml6R14OeWkmJ805g5QQP7STVrRmv3bqKjkr4HydNFNOWodOWqOh9v0hl5PWPwic+Axgzx3AuVca3i9rJ801caCvoO53JNIeVrcnPgvY+XUV8hzb6LMNDRUS/uVN6ufQA9brnw287nvxt8PJ9D51O7bJf7khx5D18YBlK/NqHzIJjtSqO9NoZptwTprX7NRiiTlpFhRpecQOd1pO2rIId2onzVE4MJuTHBSSf3RlcFLtW0xOmkmkNVx5WEDnDtLSDADZ7qQBwLb/BUz8Clh9guP98lbd6ap07cTROLJb5R9tfJr6Pah44LrfBR69TY0GO+nZwAv/Fnjwu80JDkmwf7sSn8c+1X+5KKOhKvPmUCfQhXCn61iriTO7c+oxlT+p/z5BJFXdqaNEXiKtv8P9bgVBkZY3Gg1DTtoycNLcs+sY7iRR0I2QgWRy0px5OwW/wgFD+KbTZszOaQNuTnym+nFS6E9uXmknuKs7AfX9dbJdk7uBtScDoxvU734iTUrVR+6pLwcu/geVEwaoSQV77oi/DW4eu8uqqh3yXy6KSKuWzaFOwBHuTCgfT/89jE5axJDqD98DHHwA+Is7wy1v56R1KNL6+pRQ8wo5J9WGZwXAnLS8UZmDugpfrjlpLBwgMag4TnLFIXUyaNTjr8+ZI2knwEdtwRHzSt6e27nafzmNEMlMOegU01zGTp20yYeBNacAI1qk+bjr8xNKSJ/4zKZAA9TFalKpE/UacOBuYPP5wctqkRamoW1l3lzZCTRFb9LhTmNOWsS/1cTDqrFy6PdOaCwUYL5g0XS6360g6KTlDe2a6RYczsfyjH1S1C042CeNRKDqOMk5c8J0yD/y+hw5kna4ya8Fh1OYdBh+dA5XD0txMHvn2Z2TBlghtJjisVYBph8DznyV+tsOjPk7aTNWrtj48a2PD46rEHKjoRyYTjj0gPqeQ4k0SyjO5zXc6a7ujDi7U0rVHiXKZI2kxkIBwB980/u5JObnrhDopOWNFpG2nHLSTC042CeNhEQ3ngWSaYFhJ1cP+XcwN5107OayMcXJghXudBcO+NE/nH0LDmNOWgdFHEf3qJYja09Rv49u8HfSpver21UukVYaByCTOZ7su0vdnhBCpBX6lRs6H6IJb6hwZ0LVnc592/0+UYTg/ISK3FTnvefauqkvqRYtnYrlIJiTZkORljeWLFu/tKoZ7lxWTpqjcKBR635zRbIyqJQdjZB1c9cOnCWjk+YT7uzL2EnrNPcrCUw5aZ04abqyc40WaceqmZlezFgibXxz6+ODVm5uEiHPfdtVsvrqk8ItP7oh3KSE8iQwfIz5OSHUd5qYk1ZW63NXkhZK0cKdR/e0rjMM9UoyLloQxcHsL1pyAkVa3rBF2pgqge8fWSYizdW7Jy+9n8jyoDrvEPgJjEmyCwfCOmmuZHnnOqISS6TlIIfTPXEAsNqhxHQ09MzO0E7aPiU03MnkdgFVEiLtThXqFCLc8iMb/IWlZu6gEqFeJNkeo7poLnooDFgzZ0MWKOhJEED46TC1FEVa1jmaOYEiLW84w536dlkUDpQBCEODTuYVkBBUyq2VwUBnOSktTpqu7jScJBt+Y6E6qO4Ufa2jb4IoDmWfg+OeOACo/+e4/8OTu4GhY5q5XUEibWY/MH5cu4BKykkrH1Hu3ubzwr9mdH2wk1arqOR7XRxhotCfYLhzob2yE/Bv2mziiEOkhQ0lrxQn7eAD0XLxMoQiLW+0ibRlMmRd5xTpA2wSISvSO1QXWue+6sc6WZ9el1+fNN+JAx1Ud5bGo+Xt9OfAOUi6unPyYWDtk5q/j25Q343X+qb3A6s2tz+elJO2f4e6DVM0oAnjpOnnR/1EWtJOmkGk+bWaMeEMd4Z10uqVzkdChaGTMHsQE7uATz0L2PmN7qw/YSjS8oa+WtRXj6Wx5VM44LTg6aSRKFTn2520TgS+cwi1b580Q7K8EJ31aVqYilY0AOSjGtqYk9aBo3HkkWY+GtAMB3o5UzP72ys7gaZI67Sh7b67lMN53DnhXzO6XolDPwGtCwuCRFojwbFQ7vYbQFNch63wPPqo+j6ACOHOpc5HQoUhiakjXhz8ubp9+IfdWX/CUKTlDe2a6aKB0tjycdKcfYK0K5L1iYcsDyoOkd9pM1n7tVb4XbtkYfuk6W2Ie5Iwze0MIg8tB0w5aXG/h0pZia61IUVaow7MHGiv7ASaF6ydOmn77gI2PDVaWxcdwvRz0/Tn8c1JKyZb3WkMd/qE9U0cebQpoishjYB6JZkeaUEUS91zliesgpZHbl0WIU+KtLyxNKsEWl9B/T4wFv4fKEvcV3csHCBhadSVy9VW3dnBQbq6oPZBIVTYsa8/wElzibROEvnjiLRcOWmunLQ4Iu2INVjdKdL0CCBTXtrcQUDW/Z20Ti5WGw1g345o+WhA0x3za8OhRZrXiCMg4XDngkfhQASRVikDc08AG3/D+j1KTloKTppu/dINETXxK3U7dxA4/FDy608YirS8sTTdzEcDLCdtGQwqdx849P0KRRoJoG2kWAIC370/ejX6rBuECdChkzYVftqAJg8tOIyVrjEnIejKTlO40yR47B5phpy0gRE1NquTwoGJX6lja5R8NMAxKcHPSbNEZ2BOWlLhTo/CgUKEyQZTv1a3x8YQaWnlpEF2Z2D85C5g7anq/iO3Jb/+hKFIyxtLs80rR8AqHFgOTtqCy0lj4QAJiRYnpokDcakttu6PXiNz/MKdaTppeegLleTEgUlX+w3A4aQZRJrXtAFAuaGdXqzqJraRRZrVDsTPSZs/rI7ZfrNAozaa9cO9b2v8Ws240ZWdUUVaWi049HeZ9P+ElCrceco2YM3JKuSZcyjS8oYerq5ZLjlplXkWDpB46PL/fnd1Z4fNbJ1uQ7EUvroT6Kzj+cJUzHBnOdscGdtVLDQfKw6qMGTU4eCTu5Vz5jyWFQdUSw5TuNNr2oBmMMT8zvuuBz5xvmq14WbfXcrddFabhiHMYPi5g/4uGtCFcKdfdWeI99GVnXa4M0pOWhotOKzPknRe2uwTqqXV2lOBky8C9tyR+4brFGl5wy3SBkZVrkjeR2S0hTvppJGQVBw9zQBHC4wEctI0XifJhiFZHog/Dqm2pAoAIld3dtj2IwkaVeWiOfuUxe0Zd2R3a6hTM3qsWaTN7Fci3StMXBoPdtIO3KPCmj94T/tz+7arfLSo44z6h1ResG/hwGH/HmlAsuHO2mL7SCggWrjz6KNqqs348QBEhHDnUkrhzi45aZO71O26JymRVpkF9t+d7HskDEVa3licaVYzAckkzaaBZ+EAnTQSgBbyunBAiKazFHudppw0Dyetr9jeQDVujpjdQieiSCvmoNCmXjWI1ZjicXI3sPbk9sdHN5jzu6b3KRfNaxJAKYSTtnBU3d77JWD3j5uPL82qwepRQ532Ngc0tA3lpCXYzNbd7kgTNdx5zEnq+x4YjSDSDPtIN4jyWaIwoUXak4EtzwUgch/ypEjLG23hTj2/M+fFA545aRRpJAD3SDGgs5wwwOCklbxnd5rCN3GdtEVruHrkwoEuOQdRaNRa89EAx8kywnYtzqgcLlNo0c9JM+WjaQbHVeK/HwtHgfWnq/f97luaDu3+HQBk9MpOTVBD2/lDKYc7vZrZRpg4cHQPsGaruj8wHD7cWVtKpwWH/f+Q8PljYpc6zowdpyZhHPebFGkrkm6GJNoKByzBlvfiAbdI6yuof2aGO0kQ+mQ64BL5HRUOLLSGhIoD3rM7Tc5AbCctxtxOIB/Oc73aPrTb3q4IIs1U2akZ8RhYPr3fOx8NsMKdAdGEhaPA2Cbgpf+oRMitf6se10UDx58buOlG/Jy06qL6mweJtL6E+qRJ2b5va8KKtEZdVXces0X9PjAS0UlLMSct6XPt5C5VzKLD3lufp+a55vj8SpEWlUMPAf/3XGD3j5Jfd6OhYuTunDQg3+FOKc0WfB6GRpP8YztpI83HOt13QjtpHieduE7agnbSlqFI0zlpTuI4aabKTs3oBlUo4jwp1irKXRs3tN/QhCkcWDiqChO2PAc490rgPz+p8o32bQfWnaaei8PIBu/qTu2whcpJS8BJ06LF5KTZf6uA95k5oLblGO2kRRFpS80xa90kiYbWJiZ2qVCn5uSLlIO89z+TfZ8EoUiLyvAadQD+yquAh/4t2XXrQeolQ05anhva1iuqAqxNpA2HH9xLuk+9qi4E8obdJ81VHdyRSHO1KfB00irtwgSIP1hchzujFg50K1E6CvVaMjlpWqStMeWkGXqlzT4OQIZw0mb8q1+1SAOA//YBJZxu+EvlpMXNRwOUsFw4anbCwkwbAJITaabUAPs9dOFAwN9KV3ba4c4oOWlpVXfq/4cEnbTqIjC1t9kjDQBOfKa6gMtxyJMiLSqjG4ArbgQ2ngl89bXA/V9Pbt3u4erO+3l20rwOHHTS8sXHzwF+9v+y3op27D5pbietwxYcTrehUPKeOGAMdw7FO0HEDnd2yTmIQqNqbuoLRMsNOrJbuWKm5HZTS4sZq/2GX05aaUw5Hl7fT6PRKtIGVwEX/4Oa01iejJ+PBjT7u5ny0uy5nT7TBoDkCge0iDc2sw3ZguOo1SOtJdwZNict5RYcSeakHdkNQALrHCKtf0gJNYq0FcbwGuAPvwOc9GzgW38K7Ph8Mus1irRlEO7UB06jk0aRlguqi8D03nwejKquiQNA8uHO4oA5DNTwCndaszSj9i2LXTiQg0Ib3+rOiOFOU6gTcIg0R/GA37QBTdD8zsosIButIc0zXgI85VJ1v1MnDTDnpdnTBtJy0jyOtUD4cOeRR5UY1+HlgZHwk2HSctL6IzhpS7PArpuBH74PuPHN3mLYruw8tfXxky9SYt6vgjdDisGLECOlMeD3v67ctBvfrOziZ/15Z+u0y/dNhQPLQaSZnDQWDuQCfXJ74v5st8NEpQyIvtb+S/3DygGJgym52tNJ85hF2D+oTvr1arQcnMVp9V6mnCE/4vYjSxJTdWec/m2TDwO/8XLzc6Yh637TBjQly5lcnAHGNrY/r9tvuPPOXvpx4IxLgGOfGrzdXvgNWdftRPzmdgLJ9UnTx1rfsVAhwp2rT2wWiYQNdzYa6qImtbFQ8L5omTkA3HmNaka7/26VbgMBQAJPeyWw5YL21+geae6q45MvAm55P/DofwBPuyyZ7U8QOmmd0D8EvPor6mrt++/qPEdtyZCTppOp85yTVjVU5wEMd+YJHYabOwjMGlogZInusefskdXJvqNdn7CzO00izc6JibgNcaYNAMkWDkgJfPkVwJ2fifY6U3Vn1ATu8hHlJpoqOwFgeK0S5E6RNr1PfWc6amAiyEnzEmlDq9WJ16v/WhhGfcZZzR1UrmmQcCn0NwfYd4K9b5ty0iKEO3WoEwgf7rSnc6Q0YB3wvjj42aeAOz4KQADPeQvw2u8A/+MhNePVq6hvYpe6EHCmVQDAprPU/vfIj82vyxiKtE4pDgC/d6068HTauVgfgJzhzr4+1fF6WThppnAnnbRcsOjoMZU3N60y337SKXYg0kzOrt/sTlP4xs4Ri5jIvzgdvWgASFakVeaAXT8AbnorL1deyAAAIABJREFUcNe14V/nW90Z0knzq+wEVGue4XXt4U6/yk6geeG66NErzUukJYHtpBlEWpgeaUByszvtfdvHSQsT7tSVnUD46k5bpKXopHldJJUn1T7zJz8EXvBeNYtzbKPKPfQSWxO7zL37+grA1guB3bdmO5bNA4q0JCj0Kxt/9onO1mPKSQOsIet5FmksHMg9OlcKAB6/L7vtMFFd8HBhYwp804nM10nzyEkDojtpcYart7xfAtWd8xPqdngd8G9/Ddzz5XCvM+akRaw6nbOOgePHeS8zemx7uNOvshNwOGkex8FuirTSqDq2mSYlzB0KzkcD1D7WqHVeXW0XDhhy0oQIzn1bOGo5nS6R1qgGizuvObfdIKiqeGHK/Lc+5fnKLHHPb5VSheGd7TecnHyR2g+PPBJ3i7sGRVpSjG20Ssk7wHbSxlsfz/uQdffsRc0ACwdyg3Yg+oo5FGnl1h5pgCXSYgqWSE6aoaIRiD8OaXEqetEAkOysW32CeslHgJO3ATf8BbDzG8Gva9QM1Z0R+6TZAnGt9zKjrr5j0wHTBgDHeLyI4c6kGFlvdtLmDgXnowFN8dtpyLPqcay138ejH6BGt99oCXdaYeagkKdebxp90gpFtS967XcLR82O9SnPByCBR29rfXzuoNp33EUDmpO3qdtH/yP2JneLzEWaEKIghLhHCPFdw3MlIcRXhRAPCyH+SwixJf0tDMnYcck5aQOu3IyB0eWRk9bmpA2H779DuosWacefm89wZ5uTNqxcrDjOQ82QXK1nd7rDGZ7hzpjhx9hOWgmAiC9MnZQtoTS+WeXMnvgs4FuvBx680f91SVR36mKP4XXeyzidtEoZWDgS7KTp6IJXQ1tbpMUQyGEY9ZiUEMVJAzoPeVYN+ZZOvPoBao7o9hsuJw0IPlbr9aYR7gSslIeIIu24c1SRiTsvbcKjaECz5mT1uXR7khyRuUgD8GYAD3o898cAjkopnwTgowD+PrWtikoiTtqsyj/rc/1Z8u6keeakMdyZG7RI2/JcdTXtlduTBcZpFR2E/4xOWgmAVG6Rk8BwZ8T3j1s4IITVm83n/6XRAB64IVi42kJpjRK/r/kqcPw5wNf/CHjkNu/X+eWkhRWP5Ul1UelX3Tq6XjkbUqoqPSBETpqucvcSaVPKje1W5aFpfmelrFp/BPVIAxwirUMnzXQB4n6fUE7aSc3Hwoo0ve1pFA4A1oWVn0gzuKaFIrD1ue35Zbqy0yvcKYQ6h890eA7vApmKNCHEZgAXA/isxyKXAviCdf8bAF4gRCdlOl1kbJO6IuykQ/LSTGv7Dc2yEWkGN6S+pGbFkWxZnFYn4BOfqX5/Yme22+PEGO7soG+Y6aJBh2jc/58Nn2a2Ud9fyviFA0DwUPnH/gv42muBPbf7r0eHHEcsN6s0Bvz+N9Sx5V6f/DTTxAEhrJ5xEcKdfqFOQDlP9YoKDev2G0FOWl9BXcD6OWndCnUC5vmddiPbME6abo/RqZPm0ycNCCHSHlXhWdPowUCRZv3vpNGCA7AuWgz7nZT+f+9Tnq96QuoiFkA5acUh/7D62KbOjZYukLWT9jEAbwfgdWl4PIDHAEBKWQMwDaDtCCCEeL0QYrsQYvvhw4bkzjTQvXs6CXkuzrQXDQCWSFuO4c4czCMkCh2G23SW+j1PeWmVsrlwAIjXN8xUOODVnsCrT1ocJ60yr/o1xXHSgOA8vAUr1yzoRFKeUCdrZ9rE0Gp1cvbLeTNNHACaoeIwlEOKNEAl4k+HmDagGRz3z0nrpkgb2aBcwrrDiZ0LObcTSM5JCxJpQX8rd2Un4HDSQuakpVE4AHg7adUFJRj9RBrQGvLUlZ3uKJWTsY2dpyx1gcxEmhDiJQAOSSl3dLouKeU1UsrzpJTnrV8fwnruBmOb1G0nf+SlWR+RFjBcOEu8GizmoYs6UWiRNroBGN0IPJ6jvDTdJ81JJ/tOzeDsejlpQeHOKO8fd9qAJqiiVbvpQZ3Ry5MqJ8wddCgO+p/A/XrGhRXL5cmmg+eFc+pAmJFQmtK4fwuObuWjAdY2y9YGy/a0gSgirUMnzW8slH4fPyF49NetRQNAhJy0tEXaoPmiJahIZM1WJUSdIm1yl3fRgGb8ODppLi4AcIkQYg+A6wE8XwjxJdcy+wGcAABCiCKAVQBitiHvMraT1sEf2Uuk6cKBHPZwAaDG+hSH2q9SbCeNvdIyx5nQvunMfBUPVAwizRZJMfYd00WD7aS5RZrPxAEgWvpC3LmdmqJHeEejRZqp872T+UlgxOBmBYVTTRMHgGhO2vykf9EA0HSe5g6qRrbD68JNaBgc92/B0VUnTc/vdAhkO9wZQqRphzIJJ6046N2c16uKGVAia2Zfa/sNwNEwPSjcmYFIM/0/hKnkPeX5Ki2gXlVC7+ivg0Xa2EZ1ns1ZalFmIk1K+U4p5WYp5RYArwbwIynlH7gWuwHAFdb9y6xl8qlUEnHSZtrbbwDN4cJJ9FDqBu45iRqGO/ODU6RtPBM4/Mv8/F2qpurODvYdU/jda66hp5MWI9y6oJ20uOHOABEVVqR5hRz7A3LLTBMHgPA5aVKq9zYJRCfOWZgz+4Pz0TSlDMOdpvmd+n6oFhxJVXcueLto+n28BPXUXjXqrNNwZ1o5aV77nXasfUXaNvV59t1l9T6TwNogkWb19stZ8UDWOWltCCE+IIS4xPr1WgBrhRAPA/hrAO/IbssCGF6jrkK74aTZlU05zUurLpjHlCTZ+4l0httJk3Xg0APZbhOghEGjlnDhgG5T4HTS9EnSEO40uUdxJg5oJy1u2C2oGlqfRANFmoebFeTUmao7AUs8hvgeqmW1/qCctKFj1PvMHwo3bUBT8igcCEokTwLT/M65Q8DQmnDVjklWd5qOtZqiT7jT1CMNiFDdmeJYKMD7oiKMk7bluc0RUXZlp0f7DU0S0bAukIsB61LKWwHcat1/r+PxRQCvyGarIiKEVR3SaU6ah5MGqKvIMOXeaWNqoQBQpOUJt5MGqOKB48/NbpuA5okhUSfNlJPm5aR5FQ7EcNKSCHf6tUYJm5M2P2kWSsWSv9gyVXcC4Z0056QDP4Ro9h2b2a9aJoTBq3CgWlZ/x25XdwIuJ+1guMpOIMHqzkX/0HCh5B2u0z3A3OHO3PZJC8hJ88v9HFqtRkTt/nHzfz/QSUsgGtYFcuekLWs66ZXWqKsrZa+cNCC/DW1NY30AFg7kicWZpng4Zotq+JiH4oHAyuAYAr+2oHKAnILD00nzaGYbp7lsIoUDYcKdE97L1KvA0rQ5ed+rpYHGs7ozoOBAU3a1/vBjdIMa07M0E65oALAKBwwirdvTBvR7F0qunLTD4S+akywcMI2Ecr6P13inI4+q17qFZaFffbZqzpy0TnLSAJWXduBuYN92FcosjfovbztpB6JvaxehSEuSTkp49QHYq0+acxknjbq6WsgSU3UewMKBvFBbUsJFizQh8lM8UOlC+5bqQvuJzDQovFEHIM0nHbs/WAwnzeSGhyGoBYczJ80rNdduZOtROBCYk+blpIX4HuZ93tvN6LHNi4RVIcOdg+NKZLsFox6D1U2RZrt/znBnFCfNEmlJjIXyar8BWOFOD5F2dI+6QDMVHYQZsp6XnLSFoypcPjDS/pyTk7epHLxdPwgOdQJKxJXG6aStaDoJd3oNVweaVwCmnLQHbwCu+13gkNfQhhSoeIU7WTjQdepV4I6P+X/H2n1whuE2ngkc/EVr36cs0ALeNBYKiD9xwL0/mvqkBTkDQeFBNwtTquGqKfk+DEFiSB8jGtWma+fGb3amnwiU0jsnLWx1p59AdDO6oflZQztp1v7rdtPScNKA9vmdc4fD9UgDHOHOTkXaor9IK5S8qztn9gGrTzA/NzAaIdyZUnWnX07a0DHeFa6a489Voks2vCcNuBnb1JyCkRMo0pJkbKMKNcSZV+kr0sZbl3GixVlQnko3YeFAdjx2J3Dz+/zdVFOu1KYz1QFQJ9VmRTfCndWF9rwdU5+0oJYCQeFBN51MGwDUdxCmcABodXScaKFkCjkWS94iUE8F8Zq+EOZ7iBLudIqbsNWdgx5D1tMSaaOO0VBLcyo8GKb9BpBguDOourPfO9xZPuItoAdGQlR36rFQabbgMAjOsEUihSKw9UJ1PygfTZPDhrYUaUnSSeKhLdIMoRKdk2ZKmtWDY72urNPAs3CATlrX0Seosk+ekkmkOYsHssQuHHCFLoodtuBwiz6jk2a5iF4nnSjjkID4w9U1YVpw6Hw3rwrPso+TVhxSlbQm91SH4bwmDoRxFOcnlBMXJtxrhwlF87gZhNf8ztSctHVNcRylRxqQoJNmuABxUix5C8FAkZazsVBeff2iVPLq6QNhwp1A58V/XYAiLUk6KeHVBx6/6k7TlY4WaQtZijSvPml00rqOFmB+yeSLhv5d656sDoJZFw/YTppr/+nrs5KZ4xQOGEJCtpPmEBv6ZGYSJnqbok4ciFs0oN9P1r1P5EtzwJqT1f15D+dc52eZKiz9htb7Dc8OK1Z1f7Yw45W1uBnbGD4RXR8bMwt3Wk5ao9GMXEQWaQn0SfNrwVHwEGnVReX8eX1HoURaBk6arLdfVEQRaWe+Enj+u4EtF4Zbftya39nwmlSZPhRpSdKRk6ZFmqm6cwSAaA93NhqqQgrI2EnzOHAU+lWvGjpp3UP/3cs+gzhMTlqhCGx4SvbFA3a7DEMScFAivd862woHDBMEgsKdaTtpxYAQ79JsU6R5hTvnJwAI80nMbx5pwzoRGnPSwlZ3HgkX6gSaTlrYfDTAP9xZKPnnaiXB6AYlGhaOOhrZph3uXAwOd5reQ8999XTSQuakiYIadp8GdrGP6/yxMB1epJXGgAvf1rxIC2Jsk3KV9feVAyjSkmRci7Q4TppPTpoQ5iHrM/ubO3CmTppHdacQ1hWa4aQz8zjwj2cBhx7q/vblnam9wJ474r1WC7CoIg1Qw9afuD/bcWNefdIAK0crbk6au3DAcJIMcgaiisSFqc7DnYD5PRsN5aQfcxIA4R/uHFrtPTkAMF802d+FVwuOheD9ZD7EcHWNdqDC5qMB/k5amETyTnGOhrLndkas7ux24YAOd7r/VnZRxxrz60LlpHm0q+kW+nO6LxC6OadVGy05Kh6gSEuS0rg6scRx0uwKPI98jtJYu5M28SvH6zMSafWquvLwsuC9hkYfuEeVhO/f3tXNWxbc8CbgG38c77VanPuGO71E2pnqualfx3vvJPAqHACCc7Q812kQacYWHD4hPv2aqC04Oi0cAMz/L9V5AFKFU4fX+oQ7fWZnep30AEdOmkd1JxDsApUnIjhplkgLO20AaO6/Jiet26FOoHU01PxhACK8KE0s3BnQgsPLsSsHOWkhW3CEdaSSQO93zmNAvQpUZrv3985hQ1uKtCQRIn5D26VZAMIc9gEsO9ol0nSos7QqOyfNK6dI45XXM7VX3eZsTlrqHN0DPPLj+I2KwzppfcV2IbTxLHWbZfGAdllNPY+Cqh29MJ3IYrXgGAo/WLxeU/+fHYU7fcKR2kUvjVlVhh6i3M/Nstfv56R5VHcCwX+LssekAxMDo8BF7wTOenW45YFmlKHNSZtKR6Q5R0PNHVSCNGy7lSSctEZdiemgZraAQaRZx4chPycthEhL00krGi4qFkLM7eyEHI6GokhLmrjVIXpuZ5/Hn8TopO1S7t26U7Nz0uycIi+R5hGy0iItZ92dbQ4+AHz/fwHXXAQc7aLTdM+X1G21HC/saOekBThpg6vaw0HHPkXlmGRZPFCdb58OoOkfiuZkaUyFA4UiIPpcOWlB4c4ITp52dzoqHPCZ0OFMhxhZ591ypzzp7WYV/cKpfjlpBhfSTb2q9rOgkVAaIYCL3qHc3LAU+tV3lAcnLUqPNCAZkWYfawOqO4H2NhxBPewGRtUxSLdiMVGrpDcSCjDnpHW7SCSHIi0XsztXFGMbVSgvKl5zOzWl0factMldwNonqRBLOaNER79wFeDjpFnCJ0e2MspHgJ3fAO79MvD4vc3HH7/XygVKmHoNuOfL6r5sqAN41HCCXd0Z4KSZHJ7+ITXHL8teadUFb/fYqwQ/cJ1ls9vgbvQZykkLmZNmqqCNSr9PzljFKdI2APt3mNdRngQ2n++/ft/qTp9cNr/vwu7PFtJJi0tpzCzSjj+7u+8LKAHeV2zmpIWt7ASsZHvRWbhT7xe+TpoOqxryuAD/nDRA/e+Y8qIB7zm33cIUnrdFWpdy0gr9KvcwRyKNTlrSaCctqiuyNO39zwF4O2nrnqwOHrl20nxEWtYJmlICe/8L+OafAP9wGvC9tynB9Dt/D/yp1SDWNC8wCXbfopzEE5+lfo/jGmn7vzrvLWj8qg6H1zYPfFlQmTcXDQAdFA54JFcXXXMNk3TSOh2uDvgPddf/+wOjVud7Q+GAlP4hR3v9JifNLycthEjzm3SQJKb5nWk5aX196rufO6yEWhSRBqj9rBORVgs41gLmsD6g9ovSuLfICjNkvb6UXo80wJyTlka7lbFNuUrDoZOWNGMb1YllaSbaAVuHO70YGGvNW6rMq+rOdU9SojCznDR94PBx0kyhGTvcmdE/Q6UM7Pw6cNdngCd2qgPYuX8EnPNaYOPT1DL6gGCa9JAEO76gDvpPfRmw9z/Vdxn1JL84rcJ4sqEOxKY5iH4ibegYtR9lhVdlMBC9TxmgwjX1JfOJrM1J8xEmQLQWHHauTId90gBzOLIlJ229OhZUyq0Cd3FahS09w52Gk57GbuwbU6TZ4bSQ4c64DI63OmnVBSVe0hBpQHM01FxckdZBuPPII9Y2+HzHnuHOI94uGhBOpNVSdtKMOWkpibQcOWkUaUnjrA6JKtL88lncNr8uGlh7qjqoL06rK+lul6G78Zq9qDGdaBem1PaWxtXBzmuwc7fYvwO47mVqGzY8Bbj4I8CZr2rOSNUM+Ay275TZJ4Bf/Tvw7L9oivM4ob3FKWD1iaoAwU+k6fYwbgZXq/y7rKj4ibTh6H3StJAwOmkll5MWFO60nLQw/1dJOGl+Cfp2TtqooxXEYWDAEYYPyjvqD+Ok+YU7fXLSooyE6gS3k9btRHI3oxuAyd3qO4ySkwZ49zALy4M3KuGy1acxq1e4szzpXTQAhHTSsspJc+yviyn8veOmLHUJhjuTJm7i4dKsd/sNwMpJm22GUfWkgXVPVlfvst49x8ePSlB1pyFkpV20zecDkM2eQ2nx4HfVwejKm4A3/hQ4/4/bBRqg8nNMicpJcO9X1N/snCvCORUmahX13a45Rf3uVfEX5KRlGe6sln0E/mD0cKefs1sY8MhJ8wl3QoY7sdo5aR04aX7Vl9pFL407qgxdf2875BhQOBB14oBfrpz93hk5aWlNG9CMbGg6WmF7pGk6CXc2Guq4depvmSuh7ffwCHcu+IyEAiKItCz6pDn214WjAITqaNAtxo9TF0Cd9rRLCIq0pInbZ2VxJjgnTTaaB8qJXQCE6kCuTwxZ5KUFFg6YRJqVj3biM9Vt2vH/2ceB0Y3AlguCHZLSePIiTUrg7i8CJz0HWHtK/PFZ2r1Za82l8yoeCRJpldnsDki+4c4YLTj0d2jqyl4sufqk+YT4AP8cLjeJOGl+1Z3WPjgw2tpU1UlQ8r5fODVUTpqfk6ZbPHRZLLU5aSmLtNH1AKTjfgQKA819Lir77gTmngDOuNR/OXv8mSEnzTfcaV2kBom0LPqkuUXa4CrvLghJMLYRmZgHHlCkJY2+uorjpPlWd7pCb5O7VJirf7CZB5NFXlpg4YAh3KmdtBOeoW7TbsMxc8A7/OfGVLDRKXvuAI4+Cpzzh+p3v07zftgizXLSTG04akvKmfETac51pU2l7O0M6BYcUYpwqj7hTreTERTujPJ3WZxW7Uz8XI4g/ByrpVkloIqlpjhw53r6DVcHvMfsAAnkpE2ofSls37C4DK7K3knTRHbSOgh3PnCD2n+f/MKA99CtPtzhzrBOmk+/xtpSyuFOQ/g/jSIRe+pAPvLSKNKSpjSqxFYUJ61RV9V5QYUDQPOfSFd2AsvDSXOeaKf2qu9ow1PU71k4aWMZirS7v6Ds+qdcon73q+rzQ/+9V5+oBIIp3LkY0L/LFvgZhTyr8/6FA7JhPrHt+QnwyG2G9fmE391OWuDszgh/l4Up9V12khPq59wtzaljixCtOWlOAsOdYSYOxGzBMT/R/VAnoP4fq+WmqEzdSXOItMg5aTHDnVKqfLSTt/mnxACOcKfDGa8tqfNGp4UDaecOm/rzpSnSclI8QJHWDcY2RmstYQ9XD+OkzTQHq687VT2WdycNaD3AH/21EhbDa5U7kLaTNvuEyjsIw6Ch5L8TykfUVfGZr2x+N2E7uruxk2jXqAOwaepAUBhOH/AyE2mGEU4av4HjN78P+Pd3tj/uVzjQ5qSFaMEBhHfSOgl1AiqEUyiZP6+z+rt/SF20uUVaeVIJXq8cv0JRiTDf2Z1+zWwDqju73X4DaB4j9TEzdSfNEsii4C96TBSK8dIKDtwDTO9tXtT5YYc7HcJGp0H4Fg6ECXem3YLDkKNJkUYSYWxjNCfNb7i6Rie2L80pUVMtN3ORMnXSglpwGPJspvYqkdbXl35PmqU5dYDXBR5BJO2k7fy6OtjpUCfgnyvkhxblg6vUCdIU7sy7SAsKdwLeY8WO7mkPhdo5aWGcNB/3yLmOME7a4lRnRQOa/kHzflCZa72IGzX0SgsjlLzaivhNHPCb+el8725XdgJNJ8kp0vqKTZHRbbSTNrLOalAbgbhO2oM3KFF42ovDvQfQ+j4LAXM7gXDhzrQLBwr97VNC0hBptnlAkbZyiToaKpRIc+Sk2ZWdeXDSyurq3+uA1e9yQ6S0RJrVOmA85Z40+r3GQjpppfFkRdquHwDrT28dh+NX1eeHFmBDq1WoyVQ4sBQg0gYz3HekDAh3eiTSVxdVUm91vj0vyzcnreSRk+YV7tR9xVJy0gDvBr5LM61CZGS9ISetA5HmO3HAp7+axm9maJJoobroEGlDx6TXekiHOKP2SAO8RdrCUeD+r6sIiRspgQf+Fdj63HDOnUmk2a1ZfF5fHFSCKLBPWooiTYj2qSNpiLS+vuhGSxehSOsGesh62IRnLQL88g2cOWnO9huAOniLQnY5aX4dsN0n2oWjqppw9Ynq97QbB+owdOjCgYSrOxeOtoda/ar6/HCOIhpZ65GTlmMnrbakcs78euwB7d/L9L7mfd0OQeOXI1kciDi7M0J158JUMiLNS0QtzbVexI2sN7fgCBJK/UPJV3c2Gtk6aWmFOgEldERf9Hw0wCocMIQ7d34D+NafAD/9ePtzB3+h9vEzQoQ6AXMeVzmEkyaEOo/kqQUHYP0/WJ+l0VDHs26NhHISNWWpiyQi0oQQRSHE7wkh/lQIETKOtIIZO04d9MLO01yMmJM2uUuJNl1dJITacbNy0rycEKB5otP//Lr9hhZp48epcGec4eJxiOykWeFO01VuHBZn2v/OYfpQGdc1rdyh/qH44U79eBYizRZUEcOd03ub948+6lqnzxBq98SBRhWA8HaBw/avW5wGjuxuOtud4NV2ZGm2tZef7nzvpDwRLJSKgx7VnT45aYV+dRHo9T0sTqmef1k6aWnRVwDGjzc3jQ7Cy0nTx6RbPgD8+j9bn3vwBgACOP0l4d8DMDtpfjlpgAp5BoU708xJA1r316UZdVGXxt87ajSsi0QWaUKI/yOEuMvxuwBwM4CvAfgnADuFEKckt4nLkKgNbe3CgZA5aRO71Dgop8Wf1fxOv8RvoOmS6BPPUUuk6YHlY5tU2KobDWNN6KujKDlpsMJySbA00+6YRunH5cTp3gyvUyesRr11GS3SvC4ACkVVaZppZXBA0YlXM2QAOOISaXbhgJeT5gp3Fvq9Q2VhCzr23KFOHidf5L9cGLzmhVZcTtroBnURWHf03SofCa6wLHrkvPnlpOnXee2ftlOTRnVnxk4aAPz+N4Dnvyf667zGQs0dVAJq9YnAN17X6pA+cIOa7TsWst2Hb05aGJEW5KSlWN0JqP8H7aSlWSSSo9FQcZy03wFwu+P3lwK4EMCHAbzGeuwdHW7X8iZqQ9swOWn9w8pmX5q1Kjuf3Pp8Zk7aQoCT5mrUqk+wq05Qtzr0l1bxwOwT6kBvmjBgYtB15d4pehyWE7+qPt91TTWt/+G1Sii494Ew/buGVmXjpOlpFUGFA25xMPWY+kzjx3uHO03NbE2zO/3CN8WQDucjt6r9fPPT/ZcLQ3HII9w520x5AKwqQ9l0SaqLwW0WAOukFzEnDbCKLrxEmh4JlYKTZoc7rWPmwlT6Im3D6dEb2QLe4c7Zg8DqE4BXfkH9Pb/1euXcT+wCDj8YrqrTfg+P6s6B0WAXzE+kSZn+WCig9eIgTZE2vkldCCz5OIspEUeknQBgl+P3lwJ4VEr5Dinl9QA+DeAFSWzcsiW2k+YT7hRCHaTnDgLTj6mZnU4yc9KCctJcbsTUXuX+aHFhC9qU4v+zB8L3SAPamwh3Qq2iDjimKkCvqj4/nMnqOszlbsOhl/FLrM5qNJR2JwMLB1zidfoxJdDWnWoId0ac3ennDIxtUqHY/du9lwGUSDvpgmS6sZuaPzca7U6au1eaPW0gTLgzYk6avV0e+2dQf7YkscOdlkOchZMWF69w59xBNQFl01nA7/wdsPsW4I6PqIIBADjjpeHfQwsxpxgMmjag8ctJ8wuHdxOn85u2kwbkYupAHJE2AMA522IbVLhT8wiACGfBFYgt0qI4aSK4W3lpDHj8XnV/3ZNan8vUSYtQODD162ZlJ9BM4E/LSZt5PHzRAOAIryQg0rQYNxWIFIeiV3cuONo+6IOwOy8tTNXh0DHZ7Du2k+Yh0rycrKm9ynk4Zmt7uNOv2rhtdmeAk9Y/qGYlPnSTd07i9H5g4lfJhDr1e7o/rz0OZ64nAAAgAElEQVS305WTBjTz0oKmDWjc1XIav4kDQICTFjDYPUn+P3vnHd5Wefb/z6PhGY94ZMdkTyAJIQkkUAKllLIpu+xSKKu0pZP+Snlp37cLWqCDAg2FAgVKoexRRgkEyF5k7x0n8d7b5/fHoyPJsrYlnWP7/lyXL9nW0dFj+Ujne773cmfo/1lLrf7/tdb1HpHmCOGk1R/2hTOP/zocfRF8+H+wfAEMnxlb/pvDqV3mjgAnLZr/TbicNHN/luSkWSHSPOdwGxQPxCPS9gEnAiilpgJjAP/W34MA6z1CK3Gl6xyDqJ00z0ioiHMkB8CRTfr7wHCnVU5auD5X0D2vyOyRZpJyJ600+qIB8BNpCRibFC4/LJxTEW5//jlpENpJC0dGvkVOWrQ99gJz0vbpY6hgtM638ReYbU3BiwZAvy87232Cq6MttHNkMulcPTMxlJu2y/PRN2Z++P1ESzCx7hVpATlpAPUeJy1aN8s/x8efcBMHIEJOmhnuTIGTBr75neb/vbeItGBjoTo7tBvqXwR27kN6JnNdKUyJMKsz6PMEVDE3VkQuGoDw4c72CO1qkoXbKpHmOUfYoHggHpH2PHCtUuoN4A2gFnjL7/4ZwI4ErK13E0t1SEtd5HEfoD+kO9vxDlb3x3TSUlUlaRJLCw6zR9rAUX73Z2qRkAonrbPDM23AonBnOCfNndmznDTzBBnYliFqJ82O4c4gTX472rSgz/M4adA15NkeJkcycK5hNInQE87QQm7T68Hv37lQu1rmiLOeEizcaR57gX3SwC/c6UkOjxjuDOHYdrRpgRbqQjGcSGuo0GHhcJ8DiSTD0xYn1dMGekqwcGdDuc4l9Z8Dmp4Dlz4Fo0+BYy6N/XlcAQUKTVE6ae7s0J9BkXoKJosuTprZcihFLTgg9dNwghCPSPsV8CTaTTOAawzDqAZQSuUB5wEfJGqBvRazV1ow6g7B1v/AR7+F56+ETW+Ez0czMQVD/sjuH4gZ+boMPlwJdTKIGO70c9IayvWtv5MGunggFVcsDeX6NbIqJy1cq5VwJ8FgGIZHgPkVDkAPwp1VqRf4kcKdwaoraw/ok1p+ie9CxT/k2dYUvGgAuveQiqbvU0aebiS6+Y3ur49haJE2+hRd/JEIgjmqZvKy/3GTkafXHmu4M1TuY2cEV9EVwoEznzsVoU4Tr5NmirQUnLQTQbDqTjPnKXBY++CpcO1rsV1Qep8nPUi4M1onzW7hznTf8dpcrYVkInI/I5GRqy+KbOCkhfC2Q2MYRgtwg+crkDp0PlqMlkAfJGeoLzRp0tYMz17qC5Gg9Gin8V+CYy+LvE/zSjqwaAC6Th0IVyWaaCL1SfPmFTX6KjsDRVrO0NRcsZjPEY9IS0R1Z1gnLSu2cGdLnRYrpgBzpevCksDefNGKNFPgp/TYMZ20EOFyp9sza9Lv46R6n77NH+lzZKsCRFpEJ83jCnS2R5cIPekcePNOKNsMgyb7fl+2WZ9kx8yPvI9ocQdxuryFRX5Omjlo3XROG8p19XcklyHkxIEIr4U7I/SFSmNFaio7TdJzeqmT5vaFlU1MkRZtS6Consev1UxHm36tos5Ja9AXH4GOaqTGz8nCldm1BUcq/9fhjJYUErNIi4DbMIwEJO/0AXKG6DdgZ4dO5jQMePN7WqDNv0tffQ85OraTonklHZiPBgHzO0f2ePlRE8lJU8rXoLN6t/6df+EA6KvFwxuStkQvZkjVqnBnOCfNnRF982PoOhLKJKsgznCnKfCrUizSPGIklJMG3Zu7+rdwSR+gO7/7t+EIO7A9mJMWjUg7W793N73RVaTtXKhvx8yPvI9ocWXqdZmfGxA8Jw10aNMcDWXmHUVy9MJVd4bKRzMfV18W/L6Gcl/4NRVk5On/ea8TaUHCnaZTE8+YqVC4/J7HO1w9itcoLVtfuARrWmu+Z1Iu0tJ9Fy0pF2kpnisdgnia2X5FKfU/Ab+7VSlVCzQopZ5VSqW4TteG5AzR7oR50lz2GKx5Br7wQ5j/YzjqxNhPiOaVdGBlJ3Q90aaKzg5tg4dz0sA3j9DrpAWIyJxhOmzj35gzGXidtBgKBxxO7WAmNCctiGiKNdzpPxLKJLuoa+FAe6t+3SO5K1aNhjLDnZEmVvg7SzX7AOWreCsYA5W7ffe3N4cWaWaPJ/MEFu2Ym5whMGIWbA7IS9vxIRSM7X4894Rg0yeC5aSBFqjenLQopg2A5/Vs7h667WgLL1gjVXemqmgAgoQ7e5FIMzq7NpwOFe7s0fP4hTtjqbw1j69gxQNW5aS5A520FIa2bdLQNp5Eih8Ak8wflFKTgYeAg8B7wGXAbQlZXW/Gv2px18fwzl0w8SztosWLKeqChTutGJQdqWO8iddJ26uv9gPFae5Q/eGV7J40taW6PD3Wq1YzvNJTvE5aEHEeLGE87L7McU/+TlrAaKhwotAfr0hLcXVwW0Podhkmga9L9V4tmswr/YLRAeHOMIUsZi6L10mL0ILDn0lnQ+laX7i1o01PGhgzP7rHR0uwOa7eZtcBDmx2cdfCgWj6lHndxADB1dkeISctM3ROWqqGq5t0KRxQemJGb8BsFOzvptUf1utPZNGFf9PcaKcNgK9KP1hemrnmVOSD+eNK7zr3OeXhzkOpz9UNIB6RNhnwr0e/DGgCZhuG8RXgn8C1CVhb78YUafuWwQvX6tyzCx/tWYKxebINFu7M9A93pohILRRMzMrFqj2+cVD+eMudk3zVUleqr1jDiYJgJGrIekutfq2CORaxirSmIE5aVpGutDOJNLfTJMMCFxY87VsiHDuugKrXwBYuA0frYgLztQtXOOB10vxEWrgQnz9mQ9HNb+rb/Su0yBwzP7rHR4t3XmgwkRbgpA3wiDTD8AilKE7EoUaQdbSFnjYAXcNO/rQ26t+nunCgpc4T4s1PXNFGsgk2ssm/R1qicKX7BHVMTpop0mzkpLkydSi+syP1Ii13mP6ssKLy3Y94ju6BgH/iy+nAfw3DMM9iC4HRPVxX78dMBP3PT/QBdvmz0bXZCMe0K+CSJ4PnVFnqpEUj0pq6n2BNvA1tk1w8UFcaX4KuOWS9pwQbCWUSazPbYDlp2YVdw53BQqLBsCrc2dYYumjAJJiTlucXXjQrPM2ZsOEKB7xOWozhToDCsVA8WVd5gicfTenKz0QSrO1IS51eZ2CeUHax/huaa2IId5rh1EAnLc7qzlT3SAPP56ihQ9+9JdQJfiLNr3ig7nBiQ53gCXcG5KT1NNzp7ZNmQXUn6IsKK5w0sDzkGY9IKweOAlBK5QCz6DrL0w3EaFX0QQYMApQWaBf/LXgeWaxkF8HUC4Pfl56jQ3mWOGlRhDtbG/WHajCRlionrbbUNys0FhIl0oINVzeJdSxUMAGWVaiFnvkhG62TZqlIiyZU7nldOju0a+Z/DBUE9EoLVzgQzEmLZczNpLNhz6fardy5EIbNSPxJI9hQ+db67vlooHPSQLsxTVXRnYi9TlrABUGk1yLUzM+GKFt/JBLzQqdqTy8TaZ7XN9BJS7hI82uaa160RdvMFsKHO1M+YN1zvDZW6jWkunAALC8eiEekLQZuVkpdDDyIrhB92+/+cYD12XZW43TDMRfDWffp0TLJRil9Mrark1a1W3/IB1Z2gv6Ad7hT4KTFOLfTJCM3MS04mmtDO2nuLC0e/JOKw+6rhm75OIFTB6IVae5MLWBSPbEimnCnf5PfukM6d8o/Ud9saGtWeIYrHPBelZstOGLISQOYfI7OnVz3L9i/PPGhTvALdwY4acHyGM0h3+Xb9LpiykkLcMU628OHfrMH6ZNk4EB7r1OTysIBz2tRvbeXibSAcKdhJEek+Yc7m6o8jYZDpAD4EzbcaWGfNPBVwaa6cAB6pZN2j+dxLwDXA08ZhrERQCmlgAuBTxO2wt7MRQtg9o2pe77MFI+GitpJy4Ta/fr7YCLN4Uh+JU1roxYt8TSHTIWTFuzkHI6mai34/PNxTDfDdDeiFWlKeSZW2DHc6Tdr0tt+w89JyyrQQtVsaBvOnYtn4oA/Q6frUOtHv9GV22PmR//YaAlaOBCif53Z9sLsxxhtdWfg/iGykzblfEDB2ue7/t6ycCfaDeyVIs1Txd5ar4/XROekBTpp0eQqQoTqTgv7pIHv3CDhzsh4BNlk4HxgvmEY1/vdnQ88gHbYhFSTEeOQ9c5O+Pu5eupBPH3Koi4c8Ls/WLgTtHhK5pvB3Hcs7TdMzETlnhLWSQuSixR2XzWQGSC+zBOl6W5EK9LAmtFQrQ1ROGlZPietxmxk63cMKQUFo3S4s6NNO0KuSE5anOFOpXTIs6lSi+qRc6J/bLQEbcFRG0KkecKdZR6RFlXhQIiLgUg5aXnDYcwpsPa5rsPmLQl3+h3PvUqkBYQ768z2GwlsZAvdc9KiFmlhwp1W9kkDPycthf9vV7o+rnubSAMwDKPSMIzXDcP4OOD3VYZhPGQYxtrELE+IiVidtAMrdHuQLW/DX+bBizdARQxjV80rrkhOWloUIi1nSHJj/16RFk/hQC601kUfigxF2Jy0ILlI4Wiu7i6+AkdDNdfoPMW0CG4VeERaqltwhEnyNzH7egFUe4oDzB5pJgNH6zBcJGc3MNwUS+GAyaSz9W3JidGFkGLFfD38c8ZC5aRlFQIKjmz2/BxNuDOESIs0cQBg2te0m7n3M9/vGst1mDSaC4FE4f8e6lUiLeD4q09CI1vwhDv9nLRo8tEgfLjTvOALrDBONuZ72exxmer/96VPw9xvpfY5A4i7dlkpNVYpdadS6k+erzuVUmMTuTghRmJ10ja8oj847lgNJ30XtrwFf5oFr97mu8oLRzQd48F34skuDr1tzrDkXrF4pw3EWTgAPZ+LGs5JC9UaIeS+aro3qe0W7qzVJ89QQ7P9ifXYSQRtDVE2QjbDnfuCH0MFo7V4MP8/ocRTUCctRpFWMlc3tp12RWyPixZXiGa2wZw0p0u7JOVb9c9RDdEOV90ZoR3J5HO0WFzznO93jRX6eaM5xhJFei8VaaZTaYYOkzESCjzhTr8WHNG6nOFEWsU2vZ9Uv95WOmkAo+b5KsgtIi6RppT6BbAZuB+41fN1P7BFKfXzxC1PiIlYnLTOTtj4Cow7XfcuO/0e+PZamPNN+PwFeOfHkfcRS+EABM9HM8kdqk+yiUjQD0Y8cztNEjEaqqNNuyOhHIdgYa5wNAVx0jLy9InWv3AgWofDknBnNH3SMrqGO/OCdPcvGKPDnOXb9M8hZ3cGThyIoU+adx8u+Mb7MC2KWbvxECxnLFROGmjRas6DjCYvLN7qTtAn8SkX6M8Nc1pEQ0VqiwagFztpocKdSWzB0VQZvUhzOPXxEexitHxb8Cbqyca8aKm1yEmzAfGMhfo68P+ApcAFwHjP1wXoys//p5S6LoFrFKLFdEOi6ZB8YIVuZzDlAt/vBgyCM38F48/oPhw+GLEUDkDoUCckvw1Hbal2AeLpVWc+picCsjlC9/9QCd0h91fdvdJJqa5TB5prov97MwemvrqzrTE6J62zXYuIUH32zArPIxs9j4l24kAc4c5k4w7iqIZy0sBXPJCWE13lXUgnLcLEAZPpV+iTuNkvrrE8tcPVQR8TytPlKdpQnh3oFu48rF/zRAsPl2fAeke7/gyINicNPEPWg6RclG+FIgtFWt0h/fpF+rzog8TjpN2GFmjzDcN4zTCMHZ6v14BTgWWAtUHc/kpmvq46iyYst+FlfcU18Svd7zNH7fgnCAcj1sKBcCIt2Q1t422/AYlx0kwBFDHcGa1ICxLuBO1q+BcOxOKktdb7clmSjWFokRYpX84/V69mf/A5mWavNLP4JVThgH+fNMOIvQVHKnAFiPXODh0WjiTSoj0Rh8xJizBxwKRkrn4fr3lW/xxLOC1RKOV7PXqTsxLYzNZsv5HoULEzrWun/Fj+P2nZ3cOdTVV6skWwSTfJxivSSvX/OpVhdZsQ71io5w3D6DYN2/O75z3bCKkm2qkDnZ06H23c6cGdloIx+kO8LoJgamvU4aJIYRLzRBtsJJRJsnvS1B2Kr/0G+IRVT0Sad45mmGa2EF11Z7jB6VkFXVtwRC3SUjxWLGoX1vO6VO0J3WcvZ5gWYJGcNPMk2d6qnSOITpikEqdLv6fM18e84ApWOAC+pPNoW2DEW91p4nDofLydC6HmgGccVYrDneB7H/UqkeZ5fTv9RFqi22+Afi8YndBwRP8cy2uUlt39Ir98u761QqSZ7/+W2uCfd/2AeERaKxCuxCPHs01YlFIZSqllSqm1SqkNSql7g2xznVKqTCm1xvP1jTjW23+I9kS7f7kWYFMvCH6/mSgZ2LgykGjCVRClk+YJdybLSastTYCTloBwZ7hmthBddWewkVAm2UUB4c4YnDRIXV6aN58xkpPmeV3M5PhgOWkOBwwc5QvRhxJpDocWIh0t1s0ijAZ3lk9EtXhOmBGdtCjdkpB90qKo7jSZdjlgaDetuTq1PdJMzDYcvUqkBYQ7kzESCnxhffOCt6dOmvneszLcCb3rf51A4hFpy4FvKqW6HV1KqUHATehwaCRagNMMw5gGTAfOVEqdEGS7fxqGMd3ztSCO9fYfonXSzFDnhDOD31/gKdKNJNKq90ZXLVk8SX8YDT4m9DbuTL3+ZDhpnZ2euZ09ddJ6INIiOWmxNLMNN5MzqyigcCDKq8/MKI+dROHt4RYhZ84UFWVb9G2wcCfokKdX+IVx58xu7HYWaf7FEqGGq5t4RVqUQsmZBqggEwdiKKIoGKNbkCx7zPPcKQ53gu+4SWXrj57iDFLdmQyRZh7TZkVkzDlpQUSawx2+8CtZiEgjHq//F8AHwCal1OOAJ8bAVPQEghzgykg7MQzDAExf1e35iiLjXQhJNE6aWdU5/kuhT5C5w7WIi9QzrWwLDJ4aeV3DpsP3t0beLndYcnqlNVbok1A87TcgQTlpkZy0GAoHvAInWLizULthbc06lynak1hGip00bxPUCOLC66R5RFowJw26lsmHc3edaR6RZnZQT/EswmhwZ/rC3mboKdRx4w13RimUlPIMS4+jutOfaVfA63fo760Qaem52k2zW7g6HP5OWkebdryTKtLicdIGQH1Z19+Vb4PCsda81iLS4po48DHwVaAO+B7wuOfrTs/vLjQMY1HoPfhQSjmVUmuAI8B7hmEEc+AuUkp9rpR6USkV9BNaKXWTUmqFUmpFWVlZsE36B9E4afuX6TfvlBChTvCFj8I5ae0turigeFJcSw1KskZD9aT9BnjygVSCctISUN3ZFMZJM0NPVbvDP18gXictRSLNO04owgnE/JAu26qP71AXFmaFp/9jgu4v3RPu9Ii0aPKwUo3/vFLzuAmVkxZruBM8o7bizEkzmXqB73W2ItyZPxIGhkmfsCP+LTjqPfliychJM6t8zQveWCpgg+WkVWyzJtQJXSuWRaRFj2EYrwOjgTnA5Z6v2cAYYIRSamOYh/vvp8MwjOnACGC2UurogE1eB0YZhnEs8B7w9xD7ecwwjOMNwzi+uLg4nj+pbxCNk+at6gwR6jQpGOObhxiMiu06ObV4YuzrDEWyRkP1pJEtaNGanpOYFhyhcotiqe40/7/BctLM0EalxwWNNSctVYUDsTppFdvD5zQW+Im0cOFOp9mewObhzmhz0vJG6jClv0iNZf8mseSkgT6uJp2jv7eicOD0/4GrX0398/YE/+pOs5FtssOdrszIvQj9CQx3drTpi3UrigbA5/xCvxVpcfuXhmF0ovPTlvv/XilVBMR05jYMo1op9SFwJrDe7/cVfpstAH4b73r7BWk5oByhnbTOTtj4qg51hvrQNykcqyu4DCN42bOZI5TIN2/OMP3h1dGeWGu9JyOhTHo6ZL2lVguOUCdCp1v/76Kp7oyUkwY+FzTqcGceoCxw0iKJNI/g6myLINL8w50RctI67B7u9JuyECknLWcwfGtV6DBwMIKJtFhy0kzmfksfiwUxCMREkZYd3bgzO9HFSUvS3E7oGu6MNRQdKNKqdutKaKtEGviO12AXpf2AuMdC9RSlVLFSKt/zfSbwJfQUA/9t/ONT5wFRdFjtxzgc+mQbyg3Zt1S/cadeGHlfBaO1qxPK2SrfCqjE2uA5Q7qWjieKulJA9eyqNT2nh9WdNaHzikALYf+Tc6R9QeicNPDlE0Yr0hxOHUpMWU5aha7sjLYRMoQXaXkjtciF8OFOZ7r9nTR3RhCRFubYGXiUfu9Hvf/MINWdMeakgc41veqlyP9DQeOfk+YdCZVkJy0rRvcpbYD+3DfnFJuVnVZMGzDp506aZSINGAp8qJT6HO3GvWcYxhtKqZ8rpc7zbHOHpz3HWuAO4DqL1tp7CDeDccPL+oCf8OXI+4nUhqNssz45JPID2tuGI8Ehz9qDOsG6J65Jem7PqzsjVTIGS+gORlO1FhvBZlSazlSs4U5I7WioaDvV+x9f4dwiV5oevO7OCt/w0uVp9NlpcyfNdLpaPSItVE5aPAQ6aZ0dgGHP/Ly+hHd2Z7tvJFR2goergy+Pq/5wfE4a+Nw0c9Ra0bjErC0ezL+nnzpplpXGGIbxOTAjyO9/5vf9XcBdqVxXryfU/M7OTtj0mm5gGynUCV1F2qiTut9fthWKEpiPBn4NbQ8CMxO335603zBJz+lZvla44eom/lV9YfdVE/oDy/xQNvMJYxZpKcxJiyaXKVonDXReVkuEaRteJ83GIi2wBYcz3df7KlH792/B4X0telGlZG/E4dAh5Y5WfTGUWZDY/6uJ6aQZHbGPzfIXaRm5WqQNGGJtqxPzM0CcNKFPEMpJK9usxcqks6PbT95IfeUXzEnraNeJ3MUJzlMwnZLStYndb21p/EUDJonISYumJ1hUzWyDDFc3cbp1a4Ka/frnWD5cM/JT7KRFI9L8kp5D9UgzOWpu5Gpj00mzfbjTr3AgVD5aj/bv59h22rjSta/hTPOFO5NRNGA+h0nMTprnWPM6aRbN7PTH66T1T5EW1aWTUurOGPY5L861CIkgMx9q9nX//f5l+nbknOj243DqNhzBeqVV79EnukS23wAd/prwFVi+AOZ9J3Enp7pSKIny7w5FRm7PqzsjJXcHS+gOuq8ITWqzC6GlRudoxRImyxyoGxSngoYKGDQl8nbONP13GJ2RX7/5P9ZfYfeXDu2Vfu6RHUVali/sHW64ery4MqHdL+/Tzq5iX8Ph9lV3JiMfDbq6c7E0sgU/J61eF42Vb4Wjv5q4tcWDq387adH62/fHuF9pSmsVoZy0/cu19e1fBReJUG04vJWdCQ53Anzh+7Dgi7DibzDvjp7vr60Zmip15WhPSM9NkZMWZU5adphWM1mF2gHNyIttIHHmwNS04DAM7aRFc5WvlP6QVo7EfEi70nzNRMGe7pEro+vszrREi7T0gJw0zxzTWKs7hdhxuvXxV3cYjjoxSc/h11usJzlpDeX688DKyk7wOGnKNwqsnxHtu/LUpK5CSBxmTlpg64z9K2DErNhO2gVjYPcn3fdldn9PdLgTYMTxMGY+fPZHmH1jzwsTzOrUeIerm6Tn6A7+nR3aZYyVaHPSWqOc3RkuBGHmesWaR2IWDnR2xlYtGCutDVokRNsE1Z2pCz9iOXZD4QwcC2VDkWYWDhhGcpy0wNxHcdJSh9MTbq8/lJpwZ8w5aR7nva1RN7EF68Od7kx9XkvmZ5KNiUqkGYbxUbIXIiSIjHx9Zdza4AsXNlXrnLSjL45tX4VjtTCpP9LVmi/bmtxk0i/8AJ48G1Y/o4VaT/D2SOupSDPnd9bFXmXU0abDV5FeL1emb+5mOMLlpIHv6jlmkZavw4qtdclNFG6MspGtiTsrctFAtLjSPU6azXPSQAu1ljrf6KdEEVhFLDlpqcPp1g5VR2vyRFqiwp21B/T3VjtpaQOsaZhsE/qnNO3LBJs6cHCVvh1xfGz7MptUVgbkpZVtTuykgUCOmgcjT4BPHtSVeD2h1jMSKhGFAxBfG45IcztNgo3rCcQwostJg/icNEh+hacpRKN10k75Acy5OTHPbc7uNEN8dnSPzByctqbkOWldqjtt/Fr0NZxpvqKenjTXDvscCQp3lm/Tx2LuiMStLR5O/Qlc+Ii1a7AQEWl9jWDzO/ctBxQMPy62fQXrlWYY+s2bTJGmlHbTavfD58/3bF8Jc9J6MGS9xWw+G4WTFiknraVOu13h3LyehDsh+RWeDR6RFu3V8XHXwNgEZVx0c9JsKEz857i21ie2Rxro1yBodafkpCUdZ5qvsCvRDqn/c5jE6qS5/UXaVigcZ32YsXBs7AZDH0JEWl8jmJO2f7muxIz1pJ1Xoj+4/UVa7UEdDku2BT7uizB0OnzygO9KPx6qdmvx09PwXU9EmumkRVM4EKmZbXMUgi/ecKdX4CdZpEU7XD0ZuAJz0uwY7kyyk+bK1D20zFw0yUlLHU637z2cjJFQEBDujNdJq9cX41bnowki0vocgU6aYWiRFs+ViNMF+Ud1FWllnsldiW6/EYhSutKzcqeelBAP9UdgzXN6wkJPk85NwRNPGw7zQzkRzWy9czvDhTuLIm8TjJQ5aTHmpCUSZ+DsThuKNHMMTmu9TuBOeLjTs3/TTZOctNThf7wlzUlL9926YxiuDvoiRjmhsVK3WrI6H00QkdbnCHTSKnbo70fOjm9/BWO69kozZ7klM9xpMvFsKJ4Mi+7XFYexsvDX+oT8xZ9F3jYSPclJa4nSSTM7zRthOtiY4jsaJy2SKAzEFGnJbsPRWK5PVokWH9Fgugxms047hvjME6spZhPupJmFCZ68NG9Omg1fi76G6Va6MpJXnGM+R1Zh7BenSunw+qHPdVqFOGmWIyKtrxHopO1frm9HzIpvf2avNFM4lG3RzxGuT1eicDi0m1a2GVb9PbbHlm+DlU/CzOt1TkNPSUS4MxonDcMXigu6L48rFzYnrQfVnRf9E2wAACAASURBVJCanLSsosS01IgV02Vo9YyPsqOTZjpdDZ6Gs0kTaeKkpRxTQA0YnLzjXyl9XMeaj2aSlg0HPVNfxEmzHBFpfY30XED53JD9y/Tv4m08WzhW56CZV/XlW7WLlqoT7NQLYfjx8MZ34IVroO5QdI/74F4tek75UWLW4W3B0RMnLYJo8s9FCkVzFE7awFFw6k9hynlRL9H7/K6M1OSkWZGPBr4RM+aMTzvmYZnHQUOZvk104YD3OPOE1iUnLXWYFwXJar/h/zw9EWlmsVMiLnCFHiEira/hcGhHxN9JG35c/BU6gRWeyW6/EYjDCde/DafdDVvegT/NguWPhw9/7l0Km16Hed+GAQly/NKyAdVDJy2CI+Ly648Vcl9m4UAYJ00p3bYinrYjqRiyHu1w9WTg9At3Kmd8jYmTjdmCo9500mIMW0fcf8Bx5p04ICIt6ZjHX7JGQvk/T6xFAyZm8UDeSN/3gmWISOuLZHimDrQ2wOEN8Yc6wU+k7dBhqsaK5IyDCocrTYc9b10Mw6bDm3fCE2fqvy0Qw4D37tZXqifelrg1KBX/aKiWWp1nFMmpMHORwg1Zb6pGj0hJ8InbxJw6kEyiHa6eDEwnrbXOvs6RGe70irREt+AIEGleJ01y0pKOf7gzmZScoHtNxoPp3Eo+mi0QkdYXMZ20g6t18mdPRFp+iXYcKnf6jYNKsUgzKRwL17wGFzyic84eOQle/7bvZAaw+U3YtxTm35X4q8B4h6w310QnqrxVdxGctIzc5PUuCjX7NZGYOWlWYDoZLfX2zEcDv8KBJOWkSXWndXjDnUlqv2FyxXNwQpwNoM3PTclHswUi0voippPW06IB0Fd++SVapJntN6x88yoF06+Ab62E2d/Uo6P+MAMW/U67XO/fo9c34+rEP3d6Tvw5aZEqO8EX5grXKy3SSKiekuwh6+0t2sWyOiettcG+TprpdNUnKSfNe5yZ1Z2Sk5YyvE5aktpvJAKvSBMnzQ6ISOuLmE7avuVQMDb+BFKTgjEekbZVX+XnjUzMOntCVgF85ddw61IYfQp88HP4/RSo2A6n/09yQjfpOfHnpEXlpEVTOBBhJFRPSXa408oeadC1utP2TppHpCW8utPzGnirO82cNAl3Jh1vTlqSnbSeYIq0QhFpdkBEWl/E30nriYtmUjAGKjxOWtF468eE+FM0Dq54Fq59Q69twpkw8azkPFdPctKicdICq+6C0ZRsJy0/uSLNO23Aqpw0M9xZZ9/wntMNyuF7rZIxuxOkutMKHL3BSTNz0iTcaQfk0qkvkpnvuwpPxMyzgjG6JPvASi2C7Mjok+HG/yb3OdJzoGpX7I9rro3OfQzsXxV0XzVamCaLzHxduNDe4nNcEomdnLRkOpI9QSnPHNcGfUwkWjxJnzTr8IY7beykDTkGhhxrb7evH2EjS0RIGP4nn0Q4aWavnJZa64oG7EC4cGf5ttD3Re2kmdWdFuekQfKKBxo9w9WtdtJaG+wb7gSf25XofDT/fXebOCAiLemkZWsxnIpm4PEy40q4eZE1zaaFbohI64uYneNdmTB4as/3Z7bhgP4t0jJChDvbW+Gx+fDx/cEfF3VOWkDVXdB9pSAnDZIX8vQ6aRYVDphOWnuzvVtOmEIqGaOzTIe0W3WnjV+PvsKsb8BVL9n72BNshRwpfRHzJD78uMRcHeeX6BwZozP1PdLsRHquDgV2tHV9Xcs26fDZ4fXdH9PRpsNK0bhf3qq7EDlp7a36+ZMp0rxjxZIk0hrLdUsXq0KN/iHc3uCkJbpHGnQ/ziQnLXUMGGTvfDTBdoiT1hcxnbRE5KOBPrHljdBX2gWjE7PP3kio+Z2lnjl3ZVu7PybauZ3gl9AdopltNHM7e0qyh6w3lGsXzariE39hZmeRZuaNJaNpscOh/3bvxAHJSRMEuyIirS+SNxJQMPoLidtn0UQontS/r7YjibSavTrXyR9zBl5UfdIiNLP1zu3sxeHOxgrr8tEgwEmz8bGczJw00Meat7pTctIEwa5IuLMvUjgWvrsB8oYnbp9n/w46WhO3v95IqCHrB9f4wsHl2/ToKpPmKIerg8fhSA9d3emd25mKwoEk5qRZlY8GXd0zOztHycxJAy3S/Ks7lVMSxQXBhoiT1ldJpEADGHiUdKAO5qR1tOtctDHz9c/lASHPlhjCnaBPzqEKB8yKy2SGO9NzAZXcnDTbOGl2DncmMScNdJGK/8QBcdEEwZaISBOEaPE6aX4irXyrzu2Z+lXtRpRt6foYr5OWAJHmDXcm0UlzOHwTK5JBQ7l1PdLAV90J9hYmZqVv0pw0v+Oss93erqIg9GNEpAlCtJhCy3/IupmPNnK2LqooDxBpsTpprozQ1Z2Nlfo22eHCZI2G6mjTQtNKJ83p0qFpsLeTZvbMS0uWSEvvWt0pLSEEwZaISBOEaPGGO/1F2hp9Qi0cp4srAis8Y80jc2eFdtIaKwCV/PYVmQOh/jAYRmL3myqRGQnTTbOzk+ZKspPm79h2tomTJgg2RUSaIERLsJy00rV6jIrDCcUT9CB6s+8U+LXgiPJk684IL9Iy8pLvehSMgd2L4C9zYfUz4WeJxoLVcztNzKkDdhZpyeyTBh7H1m/igJ1fC0Hox4hIi5GdZfXc8sxKNh+qjbyx0LdwZ+m8M9NJ6+yE0s9hqKeas2iidiWqdvse01KrHxftSdCVGTrc2VSZGhfq/D/DBX/RYcFXb4MHj4aFv4GGip7t1+q5nSZeJ83O4c4UV3fKtAFBsCUi0mIkw+3k7fWH+Gx7D09YQu9Dqa7zOyu26yHYQ6fpn4sn6Fv/4oHmmtgakrozQjezbaxIjUhzpcP0r8HNn8A1r8Kw42DhL+GZr/Zsv7Zx0jwizc4hPjPcmaycNLd/nzSp7hQEuyIiLUaG5WcysiCTpbtEpPVL0v3md5pFA6ZIK/KINP/igWiHq5u4M0OHFxsrIKsgtvX2BKV0a5ErX4ATb4cjG3uWp2Y6cZY7ab0h3OkpHEhmdaf/xAE7C1ZB6MeISIuD2aMKWbarEiPRidWC/fEfsl66RjsexZP0z+k5kDOsa/FAtMPVTVyZoZvZNqYo3BmMAYN0M+PW+vj30VgOqNQKzWC4ekO4M9mFA35VxB3tUt0pCDZFRFoczBlTQFVjG9uP9OCEJfRO0nN8FZula2Hw1K4nuOIJPXTSwhUOVFoncEz3y8wri4eGcl056nAmZk3x4nXSbCzSiiboIpHcocnZv/9YKHHSBMG2iEiLgzmj9Ylyya5Ki1cipBwzJ62zU4s0M9RpUjRRj4YyXdZYnTR3VvBwZ2ujdtisctLM523swTFv9bQBE6+TZmP3aNRJ8OO9vjFdica/H5/kpAmCbRGRFgclBVkMzk1nmYi0/oeZk1a9W7tkQ6d3vb94gg4J1h7QP8fqpPlX3fnT6MnnyrTISTPFVWNPnLQK6/PRoHc4acnGnQkdLfpiQyYOCIJtEZEWB0op5owuZOnOCslL62+k52jhdXCN/jmYkwa+Cs+YnbRMnfvV2dH1900WN4I1w6yNPSiYaSyHbIsb2ULvyElLNuZr0N4sEwcEwcaISIuT2aMLOFLXwp6KEO0ShL6JGe4sXavdh0GTu95f7BFp5dv0ya+9KbZZm2Z/rMC8NFMcWSbSTCetByLN6rmdJr1h4kCyMQe4tzdLTpog2BgRaXFywhjtLEjIs5+RnqtPbPtXaIHmSu96f3axHttUvsVv2kCM1Z3QvaGtd6SSReHO9Bx9Io+3cKCzU7uBtshJ8zho/VmYmNWj7c0ycUAQbIyItDgZWzyAguw0lki/tP6FmV+2fzkMm979fqW0m1a2FVpquj4mGsyTZ2BDW6udNKX0c8frpDVVgdFpMyetP4c7/RxbmTggCLZFRFqcKKWYPapAnLT+htm3qqOlez6aSdGE+J00s4lpYIVnYyUpGa4ejuyi+EWaXaYNQO+Y3ZlsuuWk9ePXQhBsjIi0HjBnTAH7q5o4UB2ir5XQ9/BvLhpY2WlSPBEayqB6j/45lpw0cxxQYIVnYwVk5lub4J1VEL9I887ttEHhgDhpvtxHyUkTBFsjIq0HzB5t5qVJyLPfYLpiyqkb2QbDHA+1f4W+jSvcGUykWdypP6uvOGlSOOC9GGhrlokDgmBjRKT1gElDcsnNcEnIsz9hOmnFk3xuRCCBIi2ucGcQkWa1C5VVGH/hgNdJs4FI6w2zO5ONv2MrTpog2BYRaT3A6VDMGlXA0p0i0voNpuAKlY8GkF+iT4IHV+uf4wp3BuSkNVk4t9MkqxCaq7XzEitWFz74I33S/Ko7W3ROmhQOCIItEZHWQ2aPLmBneQNH6oKM8hH6HtlF+uReckLobRxOKBzvyyuLZUi2t09aYHWnDUSaGapsiuOipKEc0vN8SftW4pQWHF2rO6UFhyDYFctEmlIqQym1TCm1Vim1QSl1b5Bt0pVS/1RKbVdKLVVKjUr9SsMzZ4w+cUrIs5+QmQ+3LYMZV4XfrtgT8nRnxXYC9Io0P9FvGJ5wZ5LmOEZLT6YO2GXaAEhOGgT0SRMnTRDsipVOWgtwmmEY04DpwJlKqUB74gagyjCMccADwG9SvMaITB2WS1aaU0Raf6JgtHbLwmGOh4olHw38mtn65aS1NeqTqdVOmplPFk9eml2mDYDM7gS/wgFPTlp/FqyCYGMsE2mGpt7zo9vzFTgI83zg757vXwS+qJRSKVpiVLidDmYeNVBEmtAV00mLpbITgld3Nlo8t9PEfP64nLQKe1R2guSkQVeRZnT279CvINgYS3PSlFJOpdQa4AjwnmEYSwM2GQ7sAzAMox2oAbqdqZRSNymlViilVpSVlSV72d2YM7qAzYfqqGpoTflzCzYlXictWDNbUxRZ3YIjuwfzOxvKrReZJkUTIXsQDBhk9Uqswwyrt3quk6UFhyDYEktFmmEYHYZhTAdGALOVUkfHuZ/HDMM43jCM44uLixO7yCiYPVqffJaKmyaYFI4F5YjdSXO6dQ82/3CnXSojM+PMSTNz6uzipJXMgR9s0/mF/RWHSx+fLXWen8VJEwQ7YovqTsMwqoEPgTMD7joAjARQSrmAPMB2nWOnjcyjaEAaTy/ZbfVSBLvgSodBUyB3WOyPdWd2DXc2Velbq0WaK007g7GKtOYanfdkl5w0Qc9idWVCi2d0meSkCYItsbK6s1gple/5PhP4ErA5YLPXgGs9318M/NcwjMC8NctJdzm5Zf44Pt1ewWc74mz2KfQ9rvo3fPmXsT8uUKTZxUkz1xBr4YC5frs4aYLGnQEtnnCnOGmCYEusdNKGAh8qpT4HlqNz0t5QSv1cKXWeZ5vHgUKl1HbgTuDHFq01IlfOKWFoXgb3/2cLNtSRghXkDI6tka2JK7NrM9vGCkDZIzyXVRi7k1a9V99mpz4VQQiDK9MX7pScNEGwJZa9Mw3D+ByYEeT3P/P7vhm4JJXripcMt5NvnTaen7y8joVbyjh1Uj9OShZ6hjuju5OWmR+57UcqyC6C2oOxPWbLW7qacOSc5KxJiA9XuuSkCYLNsUVOWl/hkuNHUFKQxf3vbqGzU9w0IU66hTttMG3AJFYnrbMDNr4K478E6QOSty4hdtyZftWdItIEwY6ISEsgbqeD75w+ng0Ha3lnwyGrlyP0VlyZ3as7bSPSCvR6og3p710M9Ydh6oXJXZcQO64MPydNwp2CYEdEpCWY86cPZ9ygAfz+va10iJsmxIM7I6BPWqX1PdJMsop0vlxrQ3Tbb3hZi87xX07uuoTYcWVIdacg2BwRaQnG6VDc+aUJbD9SzyurD1i9HKE34gpS3WkbJy2GqQNmqHPCGRLqtCPuDMlJEwSbIyItCZw5dQhTh+Xy4AdbaevotHo5Qm/D7RfuNAxoqvQNN7eaWKYO7PkUGsok1GlXXBl6JBSIkyYINkVEWhJwOBTfP2Mi+yqb+NeK/VYvR+htuDN94U7vcHWbiLRYnLQNr+gxV+PPSO6ahPgw53eC5KQJgk0RkZYk5k8sZtqIPBYs2imVnkJsuDK0OAN7NbKF6EVaRztseg0mfBnSspO/LiF23H4iTZw0QbAlItKShFKK6+eNZmd5Ax9tS/3Qd6EX4/ZrZmtXkRZp6oCEOu2PK9P3veSkCYItEZGWRM46ZiiDctJ54tPdVi9F6E2YfdIMQ1d2gn1EWkaeDo1FctI2vAzubBj3pdSsS4idLk6ahDsFwY6ISEsiaS4HV59wFB9vLWP7kXqrlyP0FlwZgAHtLT6RZpcWHEp5GtqGcdLMUOfEMyEtK3VrE2KjS06aOGmCYEdEpCWZr80pIc3l4MnPdlm9FKG34PYIm/Ym+4U7wSPSKkPfv3uRXveUC1K3JiF2XJKTJgh2R0RakikckM7504bx0soD1DS2Wb0coTdghqHamnX7DbsMVzeJNBrKDHWOl1CnrXFLTpog2B0RaSng+nmjaWrr4Pnle61eitAbMBO62xo9w9UH2mO4uklWYejCgY422PQ6TPxKVxEg2A9Xuu97yUkTBFsiIi0FTBmWy5zRBTy1eA/t0txWiIQpbtqbPdMGbJKPZhLOSdvzqXb/pKrT/kh1pyDYHhFpKeL6eaM5UN3EexsPW70Uwe6YIq2t2V4joUyyi6CpSo99CmTvUkDBmFNSviwhRqRPmiDYHhFpKeJLUwYzYmCmtOMQImMmdLc1QmOV/URaViFgaKEWSOlaKBoP6TkpX5YQI12cNAl3CoIdEZGWIpwOxbUnjmLZ7krWH6ixejmCnfFWd3qcNLu03zAJN3WgdA0MnZba9Qjx0SUnTZw0QbAjItJSyKWzRpKV5uT+d7fQIaOihFC4/Z00m+akQffigfoyqD0AQ6enfk1C7Eh1pyDYHhFpKSQv082PzpzEwi1l/PSVdRiGCDUhCGYYqrECOlrsF+7MLtK3gU5a6Vp9K05a70D6pAmC7ZFEhBRz7dxRHKlr5s8f7qAgO40ffHmS1UsS7IbpcNQc0Ld2E2necGeAk1a6Rt8OPTa16xHiwyvSlL1avAiC4EVEmgV8/4yJVDa0eoRaOjecNNrqJQl2whRptaZIs2m4s5uTtgYKxuj5noL9McPq4qIJgm0RkWYBSin+94JjqGpo4xdvbKQg282FM0ZYvSzBLpgOR81+fWs3J82VDmk53UdDla6F4TOtWZMQO2ZYXfLRBMG2SE6aRTgdigcvn86JYwr5wb8+58PNR6xekmAXTJFWa9NwJ2h3z79woLESqvdK0UBvwuukybW6INgVEWkWkuF28tg1M5k0NIc7nlvNgeomq5ck2AGHQws1u+akgS4e8A93StFA78O8GBAnTRBsi4g0i8nJcPPw12bSaRh8/4W1dEprDgH0CbSjBVD2zPHKKuxaOCAirffhkpw0QbA7ItJsQElhFnefM4XFOyt44rPdVi9HsANmQ1u7DVc3ySrqmpNWugbyS+xX5CCERikt1MRJEwTbIiLNJlw2aySnTx7Eb97ZzLbDdVYvR7AaM1/IjqFO6J6TVrpWXLTeiCtdctIEwcaISLMJSil+9dVjGZDu4rsvrKG1vdPqJQlWYlbe2dWZyiqE9iZobYTmGqjcKUUDvRFXpjhpgmBjRKTZiOKcdH554TGsP1DLH/+7zerlCFZidyfNf+pA6ef6exFpvQ93huSkCYKNEZFmM848eggXHTeCP3+4nVV7q6xejmAVZk6anZ000MUD3kkDEu7sdbgywSHhTkGwKyLSbMg9501haF4md/5zDY2t7VYvR7ACl82dtCx/J20t5A6HAcXWrkmIHVe6OGmCYGNEpNmQ3Aw3v7t0GnsqG/nVW5utXo5gBWa4M9PmTlpDBRxcI6HO3kpaNjjTrV6FIAghEJFmU04YU8gN80bz9JI9fLS1zOrlCKnGG+60q5PmEY/Ve6Biu4Q6eyvzfwzzf2T1KgRBCIGINBvz/S9PZPygAfzwxbXUNLZZvRwhldg93JmRD8oJOxcChoi03sroL+gvQRBsiYg0G5PhdvLAZdOpqG/l7lfXW70cIZW4zRYcNhVpDod20/Yt1T8Pk3CnIAhCohGRZnOOHp7Ht784ntfWHuT1tQetXo6QKtw275MGunigsx0GDIacIVavRhAEoc8hIq0XcMv8sUwbmc/dr67ncG2z1csRUoHL5k4a+NYmRQOCIAhJQURaL8DldPD7S6fR3NbBD178nPYOmUbQ55lwBsy6Uc/utCvZpkiTfDRBEIRkICKtlzC2eAA/PXsKH28t45tPr5T+aX2dYTPg7Pv1EGy7kiUiTRAEIZmISOtFXHXCUfzi/Kl8uOUIV/x1KeX1LVYvSejPmCJNigYEQRCSgoi0XsbVJ47ikatmsuVQLRf95TN2lzdYvSShvzLtCjjj//S0AUEQBCHhiEjrhZwxdQjP3ngCtU1tXPSXz1izr9rqJQn9kcKxMPd2e4dkBUEQejEi0nopx5UM5KVb5pKd7uLyxxbLVAJBEARB6GOISOvFjCkewEu3zGVM0QC+8fflvLO+1OolCYIgCIKQIESk9XKKc9J57qYTOGZ4Hrf+YxUvrdxv9ZIEQRAEQUgAItL6AHmZbp6+YQ4nji3ke/9ay9OLd1u9JEEQBEEQeoiItD5CdrqLx6+dxemTB3H3qxt4eOF2q5ckCIIgCEIPsEykKaVGKqU+VEptVEptUEp9O8g285VSNUqpNZ6vn1mx1t5ChtvJX66ayXnThvHbd7bwk5fX0dLeYfWyBEEQBEGIA5eFz90OfM8wjFVKqRxgpVLqPcMwNgZst8gwjHMsWF+vxO108MBl0xman8GjH+1kU2ktf7lyJkPyMqxemiAIgiAIMWCZk2YYRqlhGKs839cBmwDpipkAnA7FXV+ZzMNXHseWQ3Wc88dPWLar0uplCYIgCIIQA7bISVNKjQJmAEuD3H2iUmqtUuptpdTUEI+/SSm1Qim1oqxM+oWZnHXMUF65bR45GS6+9tcl/O2TXRyobmL7kTo+31/Nkp0VfLS1jIYWmQMqCIIgCHZDGYZh7QKUGgB8BPyfYRj/DrgvF+g0DKNeKXUW8JBhGOPD7e/44483VqxYkbwF90Jqm9u4859reX/T4aD3TxuRx/M3nUhmmjPFKxMEQRCE/o1SaqVhGMcHvc9KkaaUcgNvAP8xDOP3UWy/GzjeMIzyUNuISAtOZ6fBOxsOUdfcRmaaiyy3k8w0J/sqG7nr5XWcOXUIf/7acTgcMuJHEARBEFJFOJFmWeGAUkoBjwObQgk0pdQQ4LBhGIZSajY6PFuRwmX2GRwOxVnHDA16X31LO//75ibue3cLPzpzUopXJgiCIAhCMKys7pwHXA2sU0qt8fzuJ0AJgGEYjwAXA7copdqBJuByw+r4bB/khpNGs7O8gb8s3MHowmwunTXS6iUJgiAIQr/HMpFmGMYnQNjYmmEYfwL+lJoV9V+UUtx73lT2VTbyk5fXMaIgk7lji6xeliAIgiD0a2xR3SlYj9vp4E9fO47RRdnc/PRKdpTVW70kQRAEQejXiEgTvORluvnbdbNwOx1c8dgSthyqs3pJgiAIgtBvEZEmdGFkQRbP3ngCSsElj3zGyj3SBFcQBEEQrEBEmtCNiUNyePHmuRQOSOfKBUv5cPMRq5ckCIIgCP0OEWlCUEYWZPGvm09k3KAB3PjUCl5ZfcDqJQmCIAhCv8LKFhyCzSkakM5zN57ATU+t5Dv/XMPCLUdIczlo6zBo7eiktb2TkoIsvnfGBLLS5FASBEEQhEQiZ1YhLDkZbp64fhY/+fc6PtpahtvpwO1SpDkduJ0O3t90mE+2lfPo1TMZVZRt9XIFQRAEoc9g+ezORCNjoVLLR1vL+Pbzq+noNHjwsul8cfJgq5ckCIIgCL2GcGOhJCdN6BGnTCjm9dtPYuTALG74+woeeG8rnZ19S/gLgiAIghVIuFPoMSMLsvj3rXP5fy+v56EPtvHxtjKOKsgizeXQX04nBdlurpk7itwMt9XLFQRBEIRegYg0ISFkuJ3cf8mxzCjJ56nFu1m5t4q2dl1g0NbeSX1rO88v38dDl09n5lEFVi9XEARBEGyP5KQJKWHV3iq+/fxqDlY3c8dp47nt1LG4nBJtFwRBEPo3kpMmWM5xJQN5646TOW/aMB54fytX/HUJB6qbrF6WIAiCINgWEWlCysjJcPPAZdN54LJpbCqt48wHP2blniqrlyUIgiAItkREmpByLpwxgrfuOJnC7DS+8ffl7Cyrt3pJgiAIgmA7RKQJllBSmMWT189GKcV1TyynvL7F6iUJgiAIgq0QkSZYxqiibBZcezxH6pq54e8raGrtsHpJgiAIgmAbRKQJlnJcyUAeunwGn++v5g7P5AJBEARBEESkCTbgy1OHcM85U3hv42HufX0Dfa0tjCAIgiDEgzSzFWzBdfNGc6C6ib8u2sXCLWUcMzyPqcNzOXpYHlOH5VI4IN3qJQqCIAhCShGRJtiGu74ymREDs1i6q4J1B2p4c12p975LZo7g/y48hjSXmL+CIAhC/0BEmmAbHA7FtXNHce3cUQDUNLaxobSGDzYd4fFPdlFa08zDVx0n8z8FQRCEfoHYEoJtyctyM3dsEXefM4XfXTKNJTsruPSRxZTWyKQCQRAEoe8jTprQK7ho5ggG5aZzyzOruPDPn/Hk12cxaUgubR2drNlXzaKtZSzaXk5VQyuDcjIYlJvuvZ151EBmjZKh7oIgCELvQgasC72KjQdruf7JZTS2dDBnTAFLdlZS39KOQ8G0kfkMz8+krK6FI3UtHK5tprG1A6Xg95dO48IZI6xeviAIgiB0IdyAdXHShF7FlGG5vHzrPG5/dhVbDtdx3vRhfGF8ESeOKSIvq3uuWk1jG7f8YyXfe2EtToeD86YNs2DVgiAIghA74qQJfZ7G1naue2I5K/dU8ccrZnDWMUOtXpIgCIIgAOGdNCkcEPo8WWku/nbdLKaPzOeO51bzDJw4FAAAIABJREFU7oZDVi9JEARBECIiIk3oFwxId/Hk9bOYOjyP255dxXsbD8tkA0EQBMHWSE6a0G/IyXDz1Ndnc+WCJdz41AqKBqRzXEk+M0oGMqMkn2NH5JGVJm8JQRAEwR7IGUnoV+Rlunn2xhN4dfUBVu+tZvW+at7deBiATLeTX190DOdPH27xKgVBEARBRJrQD8nNcHP1iaO4+kT9c2VDK2v2VfHIRzv59vNr2HKoju+fMRGHQ1m7UEEQBKFfIyJN6PcUZKdx2qTBnDSumHte28DDC3ew9XA9D14+nQHpvrdIeX0L/1qxn/c2HuKLkwdz0xfG4HZKWqcgCIKQHKQFhyD4YRgGTy3ew8/f2Mi44gH89ZrjOVjTxD+W7uWd9aW0dRiMKcpmZ3kDRw/P5bcXTWPKsFyrly0IgiD0UsK14BCRJghB+GRbObf+YyUNrR10dBrkZri4aOYIrpxTwrhBOby9rpS7X11PdWMbt546jttPHUeaS1w1QRAEITZEpAlCHOwqb+Cvi3YyY2Q+5xw7jMw0Z5f7qxpauff1Dbyy5iATB+dw9zlTmDeuEKUkl00QBEGIDhFpgpBE3t94mJ++sp5Dtc1MGpLDN04ew7nThpLuckZ+sCAIgtCvkYkDgpBETp8ymIU/mM9vLzqWTsPg+/9ay8m/+ZA/f7idqobWuPZZ2dDKJ9vKE7xSQRAEoTchTpogJBDDMFi0rZwFn+zi461lZLgdXHr8SL5x0hhKCrOi2kdVQyuXPbaYrYfrefTqmXx56pAkr1oQBEGwCgl3CoIFbDlUx4JFO3llzQE6Og3OPHoIN548hhklA0M+pr6lnSsXLGVTaS0j8jOpbmrjne+czKCcjBSuXBAEQUgVEu4UBAuYOCSH+y6Zxic/Oo1vnjKWRdvKufDhz7hywRI2H6rttn1zWwc3PbWC9Qdq+PPXjuOxa2bS0NLOD1/8XOaMCoIg9ENEpAlCkhmcm8GPzpzE4ru+yE/PnsyGg7Wc9dAi7n5lvTdnrb2jkzueW81nOyq47+Jj+dKUwYwblMNPzprMwi1lPLN0r8V/hSAIgpBqJNwpCCmmurGVB97byjNL9zIg3cWdX5rAugM1vLhyP/9z7hSumzfau61hGFz7xHKW7argzTtOZmzxAAtXLgiCICQaCXcKgo3Iz0rj3vOP5q07TmbqsFzueW0DL67cz3dPn9BFoAEopbjv4mPJcDv57j/X0NbRGXbfhmHwwabDXPboYt5eVxrz2jo6DXaW1VPb3BbzYwVBEITEIk6aIFiIYRi8t/EwR+pauHJOSchGuG+vK+WWf6zijtPGcecZE4Nus/VwHb94YyOLtpWT5nLQ3tHJA5dN5/zpw0M+//oDNXy6vZwth+vYeriObYfraWnvpDA7jadumM3UYXkJ+TsFQRCE4Eh1pyD0Ab73wlpeWrWfowqzmHnUQGYeNZDjjyqgcEAaD72/jX8s3cOAdBffOX0CFx03gpueXsGy3ZXcd/E0Lp45osu+mts6+N27W1jwyS4MAwbnpjNhcA6ThuQwqiibP/93O3Ut7Txx3SyOH1Vg0V8sCILQ97GlSFNKjQSeAgYDBvCYYRgPBWyjgIeAs4BG4DrDMFaF26+INKGv0tTawbPL9rJsVwUr91RRXu9rlOt0KK6aU8J3Tp/AwOw07/Y3PrWCT3eU88sLj+GK2SUAfL6/mjtfWMv2I/VcOaeE750xkQLPY0wOVDdx9YKlHKxp4tGrj+eUCcWp+0MFQRD6EXYVaUOBoYZhrFJK5QArgQsMw9jot81ZwLfQIm0O8JBhGHPC7VdEmtAfMAyDPRWNrNxTxc7yei6YPpzxg3O6bdfc1sHNz6xk4ZYy7jl3CjVNbfzxv9spHpDOby4+Nqz4Kq9v4ZrHl7HtSB0PXT6Ds44ZGnLbzk6DVXureGvdIbYdqePXFx3L8PzMhPytgiAIfRlbirRAlFKvAn8yDOM9v989Ciw0DOM5z89bgPmGYYTMiBaRJghdaWnv4PZnV/PexsMAfHXGcO45dyp5We6Ij61pauOGJ5ezam8Vt582nrHF2eRkuMjJcJOT4aKqoY3/bDjE2+tLOVzbQprLgVMphg/M5MWbTyQ/Ky3icwiCINiRA9VNDM3NwOEIniucKMKJNFdSnzlKlFKjgBnA0oC7hgP7/H7e7/ld7GVrgtBPSXc5efjK4/jjB9uYOjwvpjFTeZlunrphNrf9YxV/+GBbiP07mD+xmLOOGcppkwax/kAt1/5tGTc+tYKnb5hDhlsGzcfK2n3V/OGDbfzm4mMpGpBu9XKECOwsq8ehFKOKsq1eipAgDMPgqw9/yhfGF3PfJdMsW4flIk0pNQB4CfiOYRjd27BHt4+bgJsASkpKErg6QegbuJ2OkFWhkchKc/G362ZRVt9CXXO756uNuuZ2XA7FvHFFZKf7PkpOHFvI7y+bxreeW813nl/Dn688DmeSr0T7EoZh8LPXNrB2XzW/fnsz91t4ghAiYxgGNz61gqbWDv77/flyUdJHWH+glsO1LcwZU2jpOiwVaUopN1qg/cMwjH8H2eQAMNLv5xGe33XBMIzHgMdAhzuTsFRB6NcopRiUk8Gg7mlvQTnn2GEcqW3h529s5N7XN3DveVO97UU6Og3WH6hh8c4KqhpbaWrtoKm1g8a2DlraOhhdlM3csUXMGl3AAD/x197Ryco9Vby78TDvbzrMwKw07j1vKtNG5ifjT6ahpZ2fvbqB8YMHcMH04QzJS8381P9sOMzafdVMGZrLiyv3c+nxI5k9uvdW2Da3dfDU4t2cNmkw4wb1vWbM24/Us6OsAYAFi3Zy+2njLV6RkAje33QYh4JTJ1pbNGWZSPNUbj4ObDIM4/chNnsNuF0p9Ty6cKAmXD6aIAj24esnjeZQbTOPfbyT/Kw0Sgqy+GhrGZ9sK6OqUTfLTXM5yEpzkul2kpnmJM3p4OOt5fx10S6cDsWxI/I4cUwhZXUtfLD5CJUNraQ5HcwdV8jGg7Vc+PCnXDd3NN87Y0IXNy8R/Prtzby0aj8Av3lnMyeNK+Ki40ZwxtTBZKUl56OzvaOT+9/dwtjibP75zRM480E9PuyNO07C7ex9vccbWtq58akVfLajgvvf3cp3T5/AjSePxtUL/5ZQ/GfDIQBmjy7g4YU7uPT4kQzKTY2gF5LHB5sPc1zJQAotTjew0kmbB1wNrFNKrfH87idACYBhGI8Ab6ErO7ejW3Bcb8E6BUGIkx+fOYnDtc3efLaiAemcOmkQp0wo5qRxRUE/AJvbOli5p4rFOyr4bEc5j368k6w0J1+cNIgzpg7hCxOKGZDuora5jfve2cITn+3infWl/OKCo/ni5MER17ThYA1/WbiDu8+ZwuAQJ9PPdpTz9JI93HDSaK464SheXrWfl1Yd4Dv/XENWmpNBOem0dxp0dhr61oCvnzSKW+eP69Hr9e/VB9h+pJ5HrjqOnAw395w7hZueXsnfP9vNN04e06N9p5ra5jauf2I5q/dWce95U1mys4LfvLOZt9aVct8lxzJpSK7VS0wI72w4xIySfH570bF86YGPuP/dLfz2YglR92ZKa5pYf6CWH505yeql2Ke6M1FIdacg2IvW9k7e+PwgE4fkMHlIbsyVUk2tHbicKqSTtHJPJXf9ex1bD9dz8cwR/PaiY0M+R3NbB2f/YRE7yhqYPDSXF755AjkZXatcG1ra+fKDH+N2OnjrjpPJTNM5Rp2dBst3V/L65wepbdL5eE6HwuVU7ChrYMXuSl6+dV7c4dfmtg5Ou38hxTnpvHLbPJRSGIbBDX9fwdKdFbz/vVMYmpf8tibrD9TQ2NrRoxBrVUMr1/xtGZtKa/nDFb72LW+tK+Vnr66npqmNW+eP47ZTx5Hm6r2u2r7KRk7+7Yfc9ZVJfPOUsfzfmxtZ8MkuXr/9JI4eHv+0jprGNt5cV8pFM4eT7gqf47Zufw2ji7O7pAYIPeOZJXv46Svree+7Xwja2ijRyOxOQRAsI83l4KvHjWDqsLy4Stkz05xhQ30zjyrgjW+dzC3zx/Liyv08vHB7yG0feG8rO8oa+NZp49h2uI6bn1lJa3vXeai/eWczB6qb+O3Fx3oFGoDDoZgzppD/veAY/nDFDH5/2XTuu2Qav/rqsSy49niKc9L58b/XhZ2v+uD7W7lqwVL2VDR0u++ZJXs4WNPMj86c5M3fU0rxP+dOpb3T4H/f2BRyv/40t3Wwr7KRjs7oL8ANw2DRtjKuXLCEc/74CZc9tpgXlu+L/MAglNW1cPljS9hyuI7HrpnZpb/eWccM5d3vnsLZxwzloQ+2cf2Ty2hoaY/reRJJbXMbD72/jZ1l9TE97l1PWxuzYvr208YzMCuN/31zI/EaIOX1LVz+1yX85OV1PPHp7rDbrj9Qw7l/+oSvP7k84lzfRFPZ0Mqraw7QHuF5m1o7uPrxpXHNEk4Weyoawv5/Pth0mJKCLFvkUIpIEwSh15PmcvDDL0/kvGnD+N17W1m0razbNiv3VPLYop3eKQu/uehYPt1ewQ9eXEunR9As3lHBU4v3cP3c0cyKYRxWboabe887mk2ltSxYtCvoNs8u3cuD729j8c4Kzv7DJ7y8er/3vrrmNh5euIOTxhUxd1xRl8eVFGZx+6njeHNdKR9t9f1dFfUtfLj5CA+9v407/7mGSx75jBN++QGT7n6Hk3/7IZc/tpjy+paw627v6OT1tQc554+fcPXjy9h2uJ67vjKJL4wv5ocvfc7Ti3dH/RqAdtAue3QxeysbeeK6WZw2qXv4uSA7jQcvn8H9l0xjyc5KrlywlOrG1iB7Sw37Khu56OHPeOD9rVzw50/5ZFt51I/9z/pD3lFqoFvWfPf08SzZWekVcLFQWtPEpY8uZld5PZOG5PDIRzuoa24Luf3v3t1CusvBsl2V/PrtzSG3q29p5+rHl3L9E8vC7i8aWts7WbBoJ6fc9yHffn4Nzy3bG3b755btZdG2cu56eR2VDdb9n01W7qnilPsW8sySPUHvb2xt59MdFZw+eXDIWcqpRPxRQRD6BEopfn3RMWw+VMsdz63mjTtO9k49aGrt4Pv/+pzh+ZncddZkAC6aOYJDtc3c958tDMnN4I4vjueHL61lVGEWP/hy7O1Kzjx6CGdMGcyD72/lrGOGcFShr2fWp9vL+dmr65k/sZhfnH8033thLd/951o+2lLGLy44mgWLdlHZ0BryeW86ZQz/Xn2A//fyOqaPzGft/mr2VTZ5/m4YmpvBiIIs5o0rYmRBJm6ngz98sI3z//Qpj10zk6nDuofePt1ezj2vbWD7kXrGFGfzm4uO4YIZOrx23bxR3PaP1dz96gZa2jujzodb8MlOdlU08PyNJ0RsXXDxzBHkZLj41rOruezRJTx9w+yoEu47Og2eXbaX1XurGJaXyfCBmQzLz2R4fibpLgdbDtWxqbSWzZ7bmqY2rp07ihtOGt2tuGTlnkpuemolbR2dPHDZNB5ZuJNrn1jGPedO4ZoTR4VdR1ldC8v3VHJHQDXnFbNL+PviPfzqrU2cOnFQ1OHcvRWNfG3BEqob23jq63PIdDs590+f8LdPdvPt07tXjK7YXcmHW8r44ZkTOVLbwuOf7GL6yHzOnTasy3b1Le1c/8QyVu2tRgGXPbqEJ78+i0E5sRU3GIbBuxsP86u3NrG7opEvTCimqqGVP324nUuOHxm09UhzWwePfryDCYMHsLOsgV+9tSlsz7GXV+/ng01HqG1up7apjdrmNmqb2hlTlM39l0yjpDArpjUHY8GinQAh171oWzmt7Z2cPnlQj58rEUhOmiAIfYqdZfWc96dPGVuczQs3n0i6y8nPX9/I3z7dxbM3zmHuWJ9TZRgGP3t1A08v2cPkoblsPlTLC988MSYXzZ9DNc2c/vuPmD4yn6dvmI1Siu1H6vnqw58yJC+Dl26ZS06Gm45Ogz9/uJ2HPtjG8PxMKupbOGViMQ9fOTPkvj/dXs41f1vGkNwMpo/MZ9rIPKaNyOfo4XlBK1vX7a/hpqdXUNXYyu8umc7Zx+qw44HqJn755ibeXFdKSUEWP/7KJM6cOqRbKLqto5PvPL+GN9eV8v0zJkRsLVHX3MbcX/+Xk8YV8ZerQv8dwf6uG59aQXFOOs/cMIeRBaFPxBsO1vCTf69j7f4aigakUdXYFjKsW1KQxeShObS2d/LhljKKBqRzxxfHcfmsEtJcDl5dc4AfvPg5w/Iy+Nt1sxhTPID6lna+/dxqPth8hKtOKOGec6eGDLU/t2wvd/17HW9/+2QmD+1aBPHhliNc/8Ryvnv6BG49dWzEytxth+u4csFSWjs6eerrszl2hM5r/ObTK/hsewWLfnRql+kdhmFw2WNL2FnWwMc/nI/L4eBrf13CxtJaXrltHhM8eVQNLe1c/8RyVu6t4g+XzyA73cktz6yiOCedp74+O2zzXcMwOFLXwvYj9Ww/Us876w+xeGcF4wYN4KdnT2b+xEF8tqOcr/11KfecO4Xr543uto+nl+zh7lfW849vzGHRtnIe+WgH/7o5+Pvrjc8Pcvuzqxmal8Gg3AxyM1zkZrrJSXfx1rpSDOB3l0zjjBiacQeyt6KR+fd/yOzRBSzZWRl03T98cS1vrz/Eqru/lLKK6l4xFipRiEgTBOGd9aXc/MwqrpxTwnnThnH5X5dwzQlHce/5R3fbtqPT4NZ/rOQ/Gw7z9Xmj+dm5U3r03E8v3s3dr27gd5dM47RJg7jg4U9paGnn5VvndRMgK/dUcsdzazhU28x/vvOFiDkwre2dMSXaH6lr5pZnVrFyTxXf+v/t3Xl0ldW9xvHvLwkBEjCMMipTwiwyKDLIKFRQCmpV1DoUFe8VUbS11KnrlmWHpW0RFQe4glr1olYRwVpcDEIQyxxBJcxzGBIhQEgIGc6+f5w3IQknEKacF/J81jrr5H2zT85ONjs8effw9o+nSqVIJs7fhMPxSN94RvZuftLNV/PyA4z9ZA3Tk1J4rH/8STdEfmPBZl6YvY5Zo6/lisanN2l+1Y50Rry9nCqVIhg3tD0dGsfRIK5K4XBTVk4eE+ZuZMo3W6kZU4nfD2nL0Csbkh9w7Ms4Rkr6UVIOZpGdG6Blveq0ql+92ET6ldvTeWH2OpZtPcDltWLo0aI2Hy7fyTXNavHm3V2oGXs8AOUHHC/OXsekxC30jK/N63d1CXkLtfumLmPb/kwWPNk35LDY/e8sZ/66VKpVjqJ7i9r0TqhDr4S6NKkdw77Dx9j6Uybb9mey9adMPlm5i8gI4/0HrqFV/eMT1dftPczglxcxqm8Lfnv98ZWGiRvSuHfqMsYNbcd9PZoCsO9wNje+8g2XVIlixuieRJox4p3lrNyezoThHQuvsCXtSOf+d5YTGWG8M6Jr4QKHrJw8lm45wKKNP7FqRzqb046QkX18vmBByL2r6+XFtlC5c/ISNqYeYdHYfsXmcObkBej3twXUu6Qynz7cg6O5+Qwcn0hs5Uj+9VivYgEoaUc6d0xewhWN4vhg5DUnLJbYeSCLUR+s4vuUQ4zs1Yyxg1oXvj43P0DihjSmr0ph2/5M3hnRlbrVQ2+bMW7Wj7z3n+1887v+PP5REpvTMlk0tl9hHwgEHF3/PI9uzWsx8a7OIb/G+aCQJiIVzl++TGZS4hbiqlYirmolZj/eq9T9zbJz8/nqx71c367+We8YHwg4bn3zW7b+lEmLutVYk3KIaSO70aVJzZDlM7Jz2Xc4m/iy7hR8mo7l5fP7GT/w8YrgHLjB7evz7I1taFyzbENHgYDjqelr+HjFLqb+6qqQ88yyc/O59oWvadOgOu89cM0Z1XPd3sPcO2UZqRnBeXRxVSvRun51WtevztzkVFIOHuXOrpfx1KA2ZbrvbEnOORZsSOPF2etJ3nOYW7s05s83X1Fq6P3nip084w0vv/9g8eBwODuXLs/PYUTPZjzjDZ+XlJ2bz4L1aSRuTCNxQxq70oPD09FREcUWq0RHRdC2wSVMGN4x5JWtR6clMS95H4lj+1GnWmWccwyduJgDmTnMf7JPsXot3bKfu95aSr9Wl5KRncvybQeYcEcnhpYYAt2cdoR7pyzjYFYO9/ZoStKOdFZuTyc331E5KoJOl9egZb3qtKhbjfhLg49Lq1cOGUaXbT3A7ZP+w7M3tGFk7+PD4h8v38nYT9fw9oir6dcqOHQ4Z+0+Rv5jBU8Nbs1/92kBwK70LG567VuqRkcwY1TPUvclO5aXzx+/SOa9Jdvp0qQmjw9IYF5yKrNW72Z/Zg61YqPJyM7lxisaMOGOTie8/tDRXHr8ZR4/a1efl4Z3ZOmW/QyfvITnbmxTOJyftCOdm1//lpfv6Miwjo1C1uN8UEgTkQonLz/A3VOWsnTrAT56qHu57tq/fm8GQ15dRG6+K/df+KE455i1Zg91YqNPWJhQFsfy8hn66mLSs3KY80SfE0JSwbDWtJHd6N7izG+jk5WTx4+7D5O85zDJe4JzytbvzeDyWjH88eb2ZzwMXVQg4NiUdoSES6udcmL4rNW7eXRaEjd3asT4268sLP/5dymM+fA7Pn24R6nhuyjnHNv2Z7FoYxo79mfRpHYMTevE0qxOLA3iqp70tmmb044wcPxC7u/ZjOeGtC28SvzXWztw21WXnVB+yjdbef6LtUQYvDS89H97+w5nc9/UZazbm0HbBpfQy7vSd1XTmqf9h8o9U5by4+7DLBrbj9jKUeTlB7hu/EIuqVKJmaN7Fvs5P/juChZv+ok5v+5NjZhobn3jW1LSjzJ9VI8ybXcxc/Vunv50DZk5+URHRTCwTT1u7tSIPq3q8ur8TbwybyPvPdCVXgnF7xQwOXEzf/5yHV88enx7lLv+dwkb9h2/CvjXr9bx5sItrHpu4Bn9IXCmFNJEpELKPJbHtv2ZISfOn2+ff5dCTl4g5H+kF6IfUg4x7LXFDOvYkPG3dyw8n5cfoN/fF1CnWmWmP9zjnK+ICwTcGW3dcq68Om8jf58TvFtCwQT+h99fycrt6Sx5+rpyqduT/1zNrNW7+frJvtw3dRkB5/jq8d4h79zgnOP1BZtJuLTaKedv5QccR7LzzjqQrNqRzi2vf8vYQa0Y1Teez5J28cRHq5l0T5fC7UkK7ErPYuD4RHrG1ybgYOGGNN7+1dX0bln22y9t35/J9ymH6JVQl7iqx+uenZvP4JcXFf58CsJmbn6APi9+zeW1Y/jwoe6F5ZdvO8Btbx6/CjhoQiJxVSvx0X91P+E9zyftkyYiFVJs5aiwBDSAYR0bXTQBDaB9ozge6duC6atSmFtke4kv1uxh54GjjOobf162LAhnQAMY3T+eWzo34qW5G/j8u5TCYczrQyy2OF/GXJdAfsBxz5SlbEw9wm9+1qrUW2uZGY/0iy/TBPvICDsnV4w6X16Tfq3qMjlxC4eO5jJx/iZa16/OwBB3AGlcM4YxAxKYm5zK/HWp/GFou9MKaABNascypEPDYgENoEqlSP50U3u2789i4vzj+yX++4e97D6UzYPXFl+lfHXTWvRKqMObCzezcV8G6/ZmMKAMdy0pTwppIiJSJqP7J9C6fnWe/ux7DmblEAg43lgQ3GLhutb+2LLgXDMz/nLLFXRtVovf/nMNL83dwNHc/BOuEJ1Pl9WKYfjVl7E5LZN2DS9hUDm+d1n9emArDmblMuLtZWxOy2R0//hSQ+wD1zajT8u6PNY/nnu6NTmn9egRX4dbOjdiUuJmNuzLwDnHW4u20KxOLP1D/Bt9fEBL9mfmMOqDVQBc55OtNwoopImISJlER0Xwt9uuJD0zh3Gz1jJ/XSrr92XwcN8WYb/idT5Vjopk0t1daFijCpMWBhejXNO8/OY4AjzaP4FW9arz3I1tffmzvqJxHAPb1mPVjoM0rxvL4PYNSi1bKTKCd+/vetLVwmfj2RvaEFs5imc/+55lWw+wZtch7r+2WcifW5cmNendsi4bvf0Cm9cN/10GilJIExGRMmvfKI5R/eL5LCmFZ2d8T+OaVfl5h4anfuEFrmZsNFN/dTU1Yyox9MqG5baHVoH6cVX46oneZ7Uw43z79cCWREdF8MSAliddDHG+1a5WmWduaMPybek8Oi2JGjGV+EXn0hfvPOHNNQw1PBtuWjggIiKnJScvwLDXFpO85zDPD2vHPafYnf9ikpWTR6XIiHIPaReKozn5xfZLC5eCDX+XbT3AI/2K7zMXyqKNaXRoVKNcV3UW0MIBERE5Z6KjIph4Vyce6t38olocURYx0VEKaCfhh4AGwbmEL/yiAz9rWy/k3RBK6pVQNywB7VR0JU1EREQkTHQlTUREROQCo5AmIiIi4kMKaSIiIiI+pJAmIiIi4kMKaSIiIiI+pJAmIiIi4kMKaSIiIiI+pJAmIiIi4kMKaSIiIiI+pJAmIiIi4kMKaSIiIiI+pJAmIiIi4kMKaSIiIiI+pJAmIiIi4kMKaSIiIiI+pJAmIiIi4kMKaSIiIiI+pJAmIiIi4kPmnAt3Hc4pM0sDtpfDW9UBfiqH95HTo3bxL7WNP6ld/Ent4l/num2aOOfqhvrERRfSyouZrXDOXRXuekhxahf/Utv4k9rFn9Qu/lWebaPhThEREREfUkgTERER8SGFtDM3OdwVkJDULv6ltvEntYs/qV38q9zaRnPSRERERHxIV9JEREREfEghTURERMSHFNJOk5kNMrP1ZrbJzJ4Kd30qKjO7zMy+NrO1ZvajmY3xztcyszlmttF7rhnuulZUZhZpZklm9oV33MzMlnp95yMziw53HSsaM6thZp+Y2TozSzaz7uoz/mBmT3i/y34ws2lmVkV9JjzMbKqZpZrZD0XOhewnFvSK10ZrzKzzuayLQtppMLNI4DVgMNAWuNPM2oa3VhVWHvAb51xboBvwiNcWTwHznHMJwDzvWMJjDJBc5PgF4CXnXDyQDjwQllpVbC8Ds51zrYErCbaP+kyYmVkj4DGYslM4AAAGAUlEQVTgKudceyASuAP1mXB5BxhU4lxp/WQwkOA9HgLeOJcVUUg7PV2BTc65Lc65HOBDYFiY61QhOef2OOdWeR9nEPzPphHB9njXK/YucFN4alixmVlj4EbgLe/YgP7AJ14RtU05M7M4oDcwBcA5l+OcO4j6jF9EAVXNLAqIAfagPhMWzrlE4ECJ06X1k2HAP1zQEqCGmTU4V3VRSDs9jYCdRY53eeckjMysKdAJWArUc87t8T61F6gXpmpVdBOAsUDAO64NHHTO5XnH6jvlrxmQBrztDUO/ZWaxqM+EnXMuBfgbsINgODsErER9xk9K6yfnNRcopMkFzcyqAZ8CjzvnDhf9nAvuL6M9ZsqZmQ0BUp1zK8NdFykmCugMvOGc6wRkUmJoU30mPLz5TcMIBumGQCwnDreJT5RnP1FIOz0pwGVFjht75yQMzKwSwYD2gXNuund6X8GlZu85NVz1q8B6AkPNbBvBKQH9Cc6FquEN5YD6TjjsAnY555Z6x58QDG3qM+E3ANjqnEtzzuUC0wn2I/UZ/yitn5zXXKCQdnqWAwneiptoghM7Z4a5ThWSN8dpCpDsnBtf5FMzgfu8j+8DPi/vulV0zrmnnXONnXNNCfaR+c65XwJfA7d6xdQ25cw5txfYaWatvFPXAWtRn/GDHUA3M4vxfrcVtI36jH+U1k9mAvd6qzy7AYeKDIueNd1x4DSZ2Q0E59tEAlOdc38Kc5UqJDO7FlgEfM/xeU/PEJyX9jFwObAduN05V3ICqJQTM+sLPOmcG2JmzQleWasFJAF3O+eOhbN+FY2ZdSS4mCMa2AKMIPjHuvpMmJnZOGA4wZXrScCDBOc2qc+UMzObBvQF6gD7gP8BZhCin3iheiLB4eksYIRzbsU5q4tCmoiIiIj/aLhTRERExIcU0kRERER8SCFNRERExIcU0kRERER8SCFNRERExIcU0kREyomZLfA2+RUROSWFNBG5oJlZXzNzJ3nknfqriIj4T9Spi4iIXBCmAV+GOB8IcU5ExPcU0kTkYrHKOfd+uCshInKuaLhTRCoEM2vqDX/+wczuNLM1ZpZtZju8cyf80WpmHczsMzPb75Vda2ZjzSwyRNn6ZvaKmW0xs2Nmlmpmc8xsYIiyDc1smpmlm1mWmX1lZi3P1/cuIhcmXUkTkYtFjJnVCXE+xzl3uMjxUKA58Bqw1zv+H6AJwXtZAmBmVwELgdwiZX8OvABcCfyySNmmwGKgHvAPYAUQC3QDBgBzirx/LJAILCF4v9lmwBjgczNr75zLP5NvXkQuPrp3p4hc0LybuH99kiL/8m7w3hTYSnCO2tXOuVXe6w2YDtwEdHfOLfHOLwauATo759YUKfsRcBswwDk3zzv/JTAYGOSc+6pE/SKccwHv4wVAH+B3zrkXi5T5LfBiqNeLSMWl4U4RuVhMBgaGeDxbotycgoAG4IJ/qRYEppsBzOxSoAcwsyCgFSn7pxJlawGDgNmhAlZBQCsiALxS4tx87znhlN+liFQYGu4UkYvFRufc3DKUSw5xbq333Nx7buY9/1jK6wNFysYDBiSVsZ67nXPZJc7t955rl/FriEgFoCtpIiLl62RzzqzcaiEivqeQJiIVTZsQ59p6z1u8563ec7sQZVsT/N1ZUHYT4ICO56qCIiKgkCYiFc9AM+tccOAtBhjrHc4AcM6lAt8CPzez9iXKPu0dfuaVPQD8GxhsZgNKvpn3GhGR06Y5aSJysehsZneX8rkZRT5eDcw3s9eAPcAwgttkvOec+0+RcmMIbsGxyCu7FxgCXA/8X8HKTs9ogqHu32b2LrASqEpwdeg24Hdn+b2JSAWkkCYiF4s7vUcoCUDBPTxnAusJXhFrBaQCz3uPQs65FWbWAxgHjCK4v9kWgoHr7yXKbvX2Vfs9cANwL5BOMBBOPttvTEQqJu2TJiIVQpF90sY55/4Q1sqIiJSB5qSJiIiI+JBCmoiIiIgPKaSJiIiI+JDmpImIiIj4kK6kiYiIiPiQQpqIiIiIDymkiYiIiPiQQpqIiIiIDymkiYiIiPjQ/wNQPHugHmFW8gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "MmYJ-VHlpxCs"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uITzxd6qqL9p",
        "outputId": "75187181-da74-4059-8d38-6afb3f3cbffd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.25      1.00      0.40         1\n",
            "           2       0.00      0.00      0.00         1\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.00      0.00      0.00         1\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         1\n",
            "           8       0.25      1.00      0.40         1\n",
            "           9       0.00      0.00      0.00         1\n",
            "          10       1.00      1.00      1.00         1\n",
            "          11       0.25      1.00      0.40         1\n",
            "          12       1.00      1.00      1.00         1\n",
            "          13       0.50      1.00      0.67         1\n",
            "          14       0.50      1.00      0.67         1\n",
            "          15       1.00      1.00      1.00         1\n",
            "          16       0.00      0.00      0.00         1\n",
            "          17       1.00      1.00      1.00         1\n",
            "          18       0.00      0.00      0.00         1\n",
            "          19       0.00      0.00      0.00         1\n",
            "          20       0.00      0.00      0.00         1\n",
            "          21       0.00      0.00      0.00         1\n",
            "          22       0.00      0.00      0.00         2\n",
            "          23       0.00      0.00      0.00         1\n",
            "          24       0.00      0.00      0.00         1\n",
            "          25       0.00      0.00      0.00         1\n",
            "          26       0.00      0.00      0.00         1\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       0.00      0.00      0.00         1\n",
            "          29       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.30        30\n",
            "   macro avg       0.20      0.31      0.23        30\n",
            "weighted avg       0.19      0.30      0.22        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"Create a post for me\"]"
      ],
      "metadata": {
        "id": "pb3CPNXVqz3z"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.batch_encode_plus(\n",
        "    text,\n",
        "    max_length = max_seq_len,\n",
        "    padding='max_length',\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "seq = torch.tensor(tokens['input_ids'])\n",
        "mask = torch.tensor(tokens['attention_mask'])"
      ],
      "metadata": {
        "id": "yaYMkT5mqNS4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds =  model(seq.to(device), mask.to(device))"
      ],
      "metadata": {
        "id": "mcCSaxAgq9pw"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xzy3drTrNUV",
        "outputId": "78f6e2f4-e0d9-43c6-d8f8-d5cf0ceac26f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-18.0270, -16.2133,  -4.8115, -21.9217,  -7.4955,  -2.4414,  -2.0587,\n",
              "         -13.3455,  -3.5186,  -4.2336,  -4.9252, -14.7103,  -9.5600,  -8.0068,\n",
              "         -15.1043, -17.2597, -13.1308, -11.9756,  -8.8245,  -9.4739,  -6.6512,\n",
              "         -15.6235,  -0.7322,  -1.4909,  -5.1152,  -8.5736, -11.1156,  -6.0432,\n",
              "          -8.0856,  -4.7806]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = preds.detach().cpu().numpy()\n",
        "preds = np.argmax(preds, axis = 1)"
      ],
      "metadata": {
        "id": "Q3iOtfVQrOPj"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgCU6_KtrsL-",
        "outputId": "c20ab573-f7bd-4fbb-f188-15cf873e8726"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([22])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lbl_enc.inverse_transform(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bLN5c5Rr53k",
        "outputId": "b27e3ef1-a611-4b00-c9ca-69cab7033a7d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['navigate_auth'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}