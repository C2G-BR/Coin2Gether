{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatbot-ig.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ChatBot Evaluation using Pytorch and Integrated Gradients"
      ],
      "metadata": {
        "id": "ajHMgD6WSM5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "9yC25Z6iSrW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from preprocess_data import raw_to_json, unzip_entities, tags_patterns_mix, remove_fallback, get_responses"
      ],
      "metadata": {
        "id": "8xh9XL_EHeq6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "TcIJv8uJK6U0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install captum"
      ],
      "metadata": {
        "id": "C2Wi-1Cpb2Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from captum.attr import IntegratedGradients"
      ],
      "metadata": {
        "id": "knrf9sQyb3jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "CwrM5tOPTuH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('data/Training - Training.csv')\n",
        "df_test = pd.read_csv('data/Training - Test.csv')"
      ],
      "metadata": {
        "id": "HDFJeSGDSa98"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare training data\n",
        "parent_tags = ['navigate', 'find', 'action']\n",
        "intents = raw_to_json(df_train)\n",
        "data = unzip_entities(intents, parent_tags)\n",
        "tags_patterns = tags_patterns_mix(remove_fallback(data))"
      ],
      "metadata": {
        "id": "aDyGe9wtgmYO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare test data\n",
        "df_test = df_test.drop(df_test[df_test['Tag'] == 'fallback'].index)\n",
        "df_test.reset_index(inplace=True, drop=True)"
      ],
      "metadata": {
        "id": "VnIGVwtVgpay"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responses = get_responses(data)"
      ],
      "metadata": {
        "id": "PKidnk36JAzr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "def lemmatizer(text):\n",
        "    doc = nlp(text)\n",
        "    return [d.lemma_ for d in doc]\n",
        "\n",
        "def train_pipeline(tags_patterns):\n",
        "    \n",
        "    word_list = []\n",
        "    tags = []\n",
        "    word_tag_data = []\n",
        "    \n",
        "    for i, row in tags_patterns.iterrows():\n",
        "        tag = row['tag']\n",
        "        pattern = row['pattern']\n",
        "        tags.append(tag)\n",
        "        word = lemmatizer(pattern)\n",
        "        word_list.extend(word)\n",
        "        word_tag_data.append((word, tag))\n",
        "        \n",
        "    return tags, word_list, word_tag_data\n",
        "\n",
        "def prepare_training_data(word_tag_data, word_list, tags):\n",
        "    X = []\n",
        "    y = []\n",
        "    \n",
        "    for (pattern, tag) in word_tag_data:\n",
        "        bog = bag_of_words(pattern, word_list)\n",
        "        X.append(bog)\n",
        "        label = tags.index(tag)\n",
        "        y.append(label)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def bag_of_words(tokenized_sentence, words):\n",
        "\n",
        "    bog = np.zeros(len(words), dtype=np.float32)\n",
        "    for idx, word in enumerate(words):\n",
        "        if word in tokenized_sentence:\n",
        "            bog[idx] = 1\n",
        "    return bog\n",
        "\n",
        "def pipe_new_input(text):\n",
        "    if text == '': #otherwise error\n",
        "        text = ' '\n",
        "    text = lemmatizer(text)\n",
        "    bog = bag_of_words(text, word_list)\n",
        "    x = bog.reshape(1, bog.shape[0])\n",
        "    return x\n",
        "    \n",
        "def get_tag_from_prediction(result, tags, threshold, fallback = 'fallback'):\n",
        "    \n",
        "    max_proba = torch.max(result)\n",
        "    \n",
        "    if max_proba < threshold:\n",
        "        return fallback\n",
        "    \n",
        "    predicted_tag = tags[torch.argmax(result)]\n",
        "    \n",
        "    return predicted_tag\n",
        "    \n",
        "def test(df, model, tags, threshold = 0.4, col_name = 'Sentence', col_tag = 'Tag'):\n",
        "    predicted_tags = []\n",
        "    matches = []\n",
        "    probas = []\n",
        "    predicted_tags_if_not_fallback = []\n",
        "    \n",
        "    for i, row in df.iterrows():\n",
        "        sentence = row[col_name]\n",
        "        tag = row[col_tag]\n",
        "\n",
        "        text = lemmatizer(sentence)\n",
        "        bog = bag_of_words(text, word_list) # word_list is \"global\"\n",
        "        x = bog.reshape(1, bog.shape[0])\n",
        "        x = torch.from_numpy(x)\n",
        "        result = model(x)\n",
        "\n",
        "        max_proba = torch.max(result[0])\n",
        "        \n",
        "        predicted_tag = get_tag_from_prediction(result, tags, threshold)\n",
        "        \n",
        "        predicted_tag_except_fallback = get_tag_from_prediction(result, tags, 0.0)\n",
        "        \n",
        "        predicted_tags_if_not_fallback.append(predicted_tag_except_fallback)\n",
        "        probas.append(max_proba)\n",
        "        predicted_tags.append(predicted_tag)\n",
        "        matches.append(predicted_tag == tag)\n",
        "\n",
        "    df = df.assign(predicted_tags = predicted_tags, matches = matches, probas = probas, predicted_tags_if_not_fallback = predicted_tags_if_not_fallback)\n",
        "    \n",
        "    acc = df['matches'].sum() / len(df)\n",
        "    output = f'Accuracy: {acc}'\n",
        "    \n",
        "    return df, output"
      ],
      "metadata": {
        "id": "_vB7ADWlI0HE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags, word_list, word_tag_data = train_pipeline(tags_patterns)\n",
        "IGNORE = ['?', '!', '.', ',']\n",
        "word_list = [word for word in word_list if word not in IGNORE]\n",
        "word_list = sorted(set(word_list))\n",
        "tags = sorted(set(tags))\n",
        "X, y = prepare_training_data(word_tag_data, word_list, tags)"
      ],
      "metadata": {
        "id": "wdTFedhGI0e6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.from_numpy(X)\n",
        "y = torch.from_numpy(y)\n",
        "y = F.one_hot(y)\n",
        "y = y.type(torch.FloatTensor)"
      ],
      "metadata": {
        "id": "X1Eyp6eiOzmt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition"
      ],
      "metadata": {
        "id": "QabI5UYuKOcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "AI-MoN7ZN9Kr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omOdBQ57L197",
        "outputId": "355febdc-1ba2-48c9-8f8e-6d38abc7a349"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1137, 154]), torch.Size([1137, 30]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input Size: 154\n",
        "\n",
        "Output Size: 30 (all possible tags)\n",
        "\n",
        "Hidden Layer Size: 16 (self defined)"
      ],
      "metadata": {
        "id": "3LYqC8SBOQEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(154, 16),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(16, 30),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "    self.optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
        "    self.loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)\n",
        "\n",
        "  def train(self, X, y):\n",
        "    self.optimizer.zero_grad()\n",
        "    output = self(X)\n",
        "    loss = self.loss_function(output, y)\n",
        "    loss.backward()\n",
        "    self.optimizer.step()\n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "tK1b7FRFJ_NS"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLP().to(device)"
      ],
      "metadata": {
        "id": "I4KuKexAK_dR"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "T2GQNVqydQ6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(0, 50):\n",
        "  print(f'Epoch: {epoch}')\n",
        "  current_loss = 0.0\n",
        "  for a in range(2):\n",
        "    for i in range(len(X)):\n",
        "      loss = mlp.train(torch.unsqueeze(X[i], dim=0), torch.unsqueeze(y[i], dim=0))\n",
        "      current_loss += loss\n",
        "      if (i % 100) == 0:\n",
        "        print(f'Loss after {i} iterations: {current_loss}')\n",
        "        current_loss = 0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k98YfG3LCxb",
        "outputId": "2ca5e6c4-a8a3-4b70-923f-e609921e3c3f"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "Loss after 0 iterations: 3.368842601776123\n",
            "Loss after 100 iterations: 336.77941393852234\n",
            "Loss after 200 iterations: 339.8909981250763\n",
            "Loss after 300 iterations: 342.05718302726746\n",
            "Loss after 400 iterations: 341.2761664390564\n",
            "Loss after 500 iterations: 340.630264043808\n",
            "Loss after 600 iterations: 342.6890251636505\n",
            "Loss after 700 iterations: 341.31024074554443\n",
            "Loss after 800 iterations: 336.8361930847168\n",
            "Loss after 900 iterations: 340.4233407974243\n",
            "Loss after 1000 iterations: 342.4567756652832\n",
            "Loss after 1100 iterations: 340.7729856967926\n",
            "Loss after 0 iterations: 127.13477897644043\n",
            "Loss after 100 iterations: 335.2034683227539\n",
            "Loss after 200 iterations: 338.25338315963745\n",
            "Loss after 300 iterations: 339.2520761489868\n",
            "Loss after 400 iterations: 338.38466477394104\n",
            "Loss after 500 iterations: 336.8469581604004\n",
            "Loss after 600 iterations: 340.71096181869507\n",
            "Loss after 700 iterations: 337.6544828414917\n",
            "Loss after 800 iterations: 332.8676838874817\n",
            "Loss after 900 iterations: 338.0057005882263\n",
            "Loss after 1000 iterations: 340.04483938217163\n",
            "Loss after 1100 iterations: 339.1661682128906\n",
            "Epoch: 1\n",
            "Loss after 0 iterations: 3.3709607124328613\n",
            "Loss after 100 iterations: 333.8237156867981\n",
            "Loss after 200 iterations: 336.7564206123352\n",
            "Loss after 300 iterations: 335.41120171546936\n",
            "Loss after 400 iterations: 334.1847939491272\n",
            "Loss after 500 iterations: 330.8358700275421\n",
            "Loss after 600 iterations: 337.67640686035156\n",
            "Loss after 700 iterations: 331.6653981208801\n",
            "Loss after 800 iterations: 327.6010785102844\n",
            "Loss after 900 iterations: 333.98678851127625\n",
            "Loss after 1000 iterations: 335.89480209350586\n",
            "Loss after 1100 iterations: 336.4995210170746\n",
            "Loss after 0 iterations: 127.32981610298157\n",
            "Loss after 100 iterations: 331.90858364105225\n",
            "Loss after 200 iterations: 334.84990191459656\n",
            "Loss after 300 iterations: 330.07014632225037\n",
            "Loss after 400 iterations: 328.6161994934082\n",
            "Loss after 500 iterations: 322.43343687057495\n",
            "Loss after 600 iterations: 333.51759004592896\n",
            "Loss after 700 iterations: 324.13187289237976\n",
            "Loss after 800 iterations: 320.838684797287\n",
            "Loss after 900 iterations: 328.51946568489075\n",
            "Loss after 1000 iterations: 331.0061981678009\n",
            "Loss after 1100 iterations: 333.1261465549469\n",
            "Epoch: 2\n",
            "Loss after 0 iterations: 3.410482406616211\n",
            "Loss after 100 iterations: 330.22189712524414\n",
            "Loss after 200 iterations: 333.3637704849243\n",
            "Loss after 300 iterations: 324.6371488571167\n",
            "Loss after 400 iterations: 323.29634308815\n",
            "Loss after 500 iterations: 314.1204240322113\n",
            "Loss after 600 iterations: 329.6979613304138\n",
            "Loss after 700 iterations: 317.3521625995636\n",
            "Loss after 800 iterations: 314.1204056739807\n",
            "Loss after 900 iterations: 322.8649580478668\n",
            "Loss after 1000 iterations: 326.5015494823456\n",
            "Loss after 1100 iterations: 329.6546440124512\n",
            "Loss after 0 iterations: 127.16331434249878\n",
            "Loss after 100 iterations: 328.9964089393616\n",
            "Loss after 200 iterations: 332.3667597770691\n",
            "Loss after 300 iterations: 319.87230038642883\n",
            "Loss after 400 iterations: 318.95222067832947\n",
            "Loss after 500 iterations: 307.1126651763916\n",
            "Loss after 600 iterations: 326.7233371734619\n",
            "Loss after 700 iterations: 311.94263648986816\n",
            "Loss after 800 iterations: 308.00551891326904\n",
            "Loss after 900 iterations: 317.49942207336426\n",
            "Loss after 1000 iterations: 322.2883229255676\n",
            "Loss after 1100 iterations: 326.0989077091217\n",
            "Epoch: 3\n",
            "Loss after 0 iterations: 3.4495251178741455\n",
            "Loss after 100 iterations: 327.9537456035614\n",
            "Loss after 200 iterations: 331.5459027290344\n",
            "Loss after 300 iterations: 315.65344500541687\n",
            "Loss after 400 iterations: 315.31829285621643\n",
            "Loss after 500 iterations: 301.2920389175415\n",
            "Loss after 600 iterations: 324.16518807411194\n",
            "Loss after 700 iterations: 307.48462748527527\n",
            "Loss after 800 iterations: 302.51478576660156\n",
            "Loss after 900 iterations: 312.4258143901825\n",
            "Loss after 1000 iterations: 318.1436629295349\n",
            "Loss after 1100 iterations: 322.3570411205292\n",
            "Loss after 0 iterations: 126.27619981765747\n",
            "Loss after 100 iterations: 326.8991560935974\n",
            "Loss after 200 iterations: 330.6014657020569\n",
            "Loss after 300 iterations: 311.69634199142456\n",
            "Loss after 400 iterations: 312.07124280929565\n",
            "Loss after 500 iterations: 296.36027216911316\n",
            "Loss after 600 iterations: 321.72108697891235\n",
            "Loss after 700 iterations: 303.60197496414185\n",
            "Loss after 800 iterations: 297.7924656867981\n",
            "Loss after 900 iterations: 307.4958004951477\n",
            "Loss after 1000 iterations: 313.8934762477875\n",
            "Loss after 1100 iterations: 318.3481328487396\n",
            "Epoch: 4\n",
            "Loss after 0 iterations: 3.4698596000671387\n",
            "Loss after 100 iterations: 325.6390817165375\n",
            "Loss after 200 iterations: 329.3264172077179\n",
            "Loss after 300 iterations: 307.7845175266266\n",
            "Loss after 400 iterations: 309.0153384208679\n",
            "Loss after 500 iterations: 292.1727843284607\n",
            "Loss after 600 iterations: 319.2663531303406\n",
            "Loss after 700 iterations: 300.1707179546356\n",
            "Loss after 800 iterations: 293.81937170028687\n",
            "Loss after 900 iterations: 302.75882625579834\n",
            "Loss after 1000 iterations: 309.55361700057983\n",
            "Loss after 1100 iterations: 314.1482903957367\n",
            "Loss after 0 iterations: 124.82799673080444\n",
            "Loss after 100 iterations: 324.08473014831543\n",
            "Loss after 200 iterations: 327.6816062927246\n",
            "Loss after 300 iterations: 303.8998034000397\n",
            "Loss after 400 iterations: 306.0544798374176\n",
            "Loss after 500 iterations: 288.6004981994629\n",
            "Loss after 600 iterations: 316.6909182071686\n",
            "Loss after 700 iterations: 297.05977511405945\n",
            "Loss after 800 iterations: 290.37118649482727\n",
            "Loss after 900 iterations: 298.2738962173462\n",
            "Loss after 1000 iterations: 305.14101934432983\n",
            "Loss after 1100 iterations: 309.840656042099\n",
            "Epoch: 5\n",
            "Loss after 0 iterations: 3.4753026962280273\n",
            "Loss after 100 iterations: 322.30728578567505\n",
            "Loss after 200 iterations: 325.6714782714844\n",
            "Loss after 300 iterations: 300.1348123550415\n",
            "Loss after 400 iterations: 303.1624639034271\n",
            "Loss after 500 iterations: 285.5633268356323\n",
            "Loss after 600 iterations: 313.9439218044281\n",
            "Loss after 700 iterations: 294.18458700180054\n",
            "Loss after 800 iterations: 287.378573179245\n",
            "Loss after 900 iterations: 294.00469160079956\n",
            "Loss after 1000 iterations: 300.76743602752686\n",
            "Loss after 1100 iterations: 305.6130590438843\n",
            "Loss after 0 iterations: 123.17126560211182\n",
            "Loss after 100 iterations: 320.3281817436218\n",
            "Loss after 200 iterations: 323.25694465637207\n",
            "Loss after 300 iterations: 296.481076002121\n",
            "Loss after 400 iterations: 300.3103060722351\n",
            "Loss after 500 iterations: 283.02708554267883\n",
            "Loss after 600 iterations: 310.9850506782532\n",
            "Loss after 700 iterations: 291.53086161613464\n",
            "Loss after 800 iterations: 284.7453291416168\n",
            "Loss after 900 iterations: 289.99440264701843\n",
            "Loss after 1000 iterations: 296.53838181495667\n",
            "Loss after 1100 iterations: 301.5328698158264\n",
            "Epoch: 6\n",
            "Loss after 0 iterations: 3.4714066982269287\n",
            "Loss after 100 iterations: 318.1991584300995\n",
            "Loss after 200 iterations: 320.4471321105957\n",
            "Loss after 300 iterations: 292.9882080554962\n",
            "Loss after 400 iterations: 297.4815845489502\n",
            "Loss after 500 iterations: 280.8906145095825\n",
            "Loss after 600 iterations: 307.81490325927734\n",
            "Loss after 700 iterations: 289.0085554122925\n",
            "Loss after 800 iterations: 282.3698663711548\n",
            "Loss after 900 iterations: 286.2313001155853\n",
            "Loss after 1000 iterations: 292.5304448604584\n",
            "Loss after 1100 iterations: 297.7455406188965\n",
            "Loss after 0 iterations: 121.58700513839722\n",
            "Loss after 100 iterations: 316.00473976135254\n",
            "Loss after 200 iterations: 317.3024699687958\n",
            "Loss after 300 iterations: 289.70453810691833\n",
            "Loss after 400 iterations: 294.69458413124084\n",
            "Loss after 500 iterations: 279.08636927604675\n",
            "Loss after 600 iterations: 304.4700810909271\n",
            "Loss after 700 iterations: 286.6133027076721\n",
            "Loss after 800 iterations: 280.2106878757477\n",
            "Loss after 900 iterations: 282.70163798332214\n",
            "Loss after 1000 iterations: 288.81020998954773\n",
            "Loss after 1100 iterations: 294.2156174182892\n",
            "Epoch: 7\n",
            "Loss after 0 iterations: 3.460587501525879\n",
            "Loss after 100 iterations: 313.7937982082367\n",
            "Loss after 200 iterations: 313.91286158561707\n",
            "Loss after 300 iterations: 286.64292097091675\n",
            "Loss after 400 iterations: 291.98528599739075\n",
            "Loss after 500 iterations: 277.5518636703491\n",
            "Loss after 600 iterations: 300.99162435531616\n",
            "Loss after 700 iterations: 284.3408713340759\n",
            "Loss after 800 iterations: 278.2144207954407\n",
            "Loss after 900 iterations: 279.4449825286865\n",
            "Loss after 1000 iterations: 285.3943831920624\n",
            "Loss after 1100 iterations: 290.9756724834442\n",
            "Loss after 0 iterations: 120.21982884407043\n",
            "Loss after 100 iterations: 311.6357309818268\n",
            "Loss after 200 iterations: 310.3049347400665\n",
            "Loss after 300 iterations: 283.8265292644501\n",
            "Loss after 400 iterations: 289.3362946510315\n",
            "Loss after 500 iterations: 276.2181429862976\n",
            "Loss after 600 iterations: 297.45644879341125\n",
            "Loss after 700 iterations: 282.16092348098755\n",
            "Loss after 800 iterations: 276.33640217781067\n",
            "Loss after 900 iterations: 276.44614243507385\n",
            "Loss after 1000 iterations: 282.28698921203613\n",
            "Loss after 1100 iterations: 288.01770067214966\n",
            "Epoch: 8\n",
            "Loss after 0 iterations: 3.444676160812378\n",
            "Loss after 100 iterations: 309.52581667900085\n",
            "Loss after 200 iterations: 306.5962333679199\n",
            "Loss after 300 iterations: 281.27879452705383\n",
            "Loss after 400 iterations: 286.7691419124603\n",
            "Loss after 500 iterations: 274.9786858558655\n",
            "Loss after 600 iterations: 293.94541692733765\n",
            "Loss after 700 iterations: 280.10510897636414\n",
            "Loss after 800 iterations: 274.55087018013\n",
            "Loss after 900 iterations: 273.7457263469696\n",
            "Loss after 1000 iterations: 279.4556348323822\n",
            "Loss after 1100 iterations: 285.2841444015503\n",
            "Loss after 0 iterations: 119.08637690544128\n",
            "Loss after 100 iterations: 307.4914116859436\n",
            "Loss after 200 iterations: 302.81378197669983\n",
            "Loss after 300 iterations: 278.99653220176697\n",
            "Loss after 400 iterations: 284.2984445095062\n",
            "Loss after 500 iterations: 273.7959234714508\n",
            "Loss after 600 iterations: 290.49946689605713\n",
            "Loss after 700 iterations: 278.1447649002075\n",
            "Loss after 800 iterations: 272.8598825931549\n",
            "Loss after 900 iterations: 271.38877177238464\n",
            "Loss after 1000 iterations: 276.8930332660675\n",
            "Loss after 1100 iterations: 282.7548711299896\n",
            "Epoch: 9\n",
            "Loss after 0 iterations: 3.42511248588562\n",
            "Loss after 100 iterations: 305.5101239681244\n",
            "Loss after 200 iterations: 299.0054278373718\n",
            "Loss after 300 iterations: 276.9552299976349\n",
            "Loss after 400 iterations: 281.92020297050476\n",
            "Loss after 500 iterations: 272.61333441734314\n",
            "Loss after 600 iterations: 287.19260239601135\n",
            "Loss after 700 iterations: 276.30226278305054\n",
            "Loss after 800 iterations: 271.2613785266876\n",
            "Loss after 900 iterations: 269.3614692687988\n",
            "Loss after 1000 iterations: 274.59194135665894\n",
            "Loss after 1100 iterations: 280.41717886924744\n",
            "Loss after 0 iterations: 118.16125297546387\n",
            "Loss after 100 iterations: 303.5849645137787\n",
            "Loss after 200 iterations: 295.24644351005554\n",
            "Loss after 300 iterations: 275.13311743736267\n",
            "Loss after 400 iterations: 279.6396942138672\n",
            "Loss after 500 iterations: 271.3895626068115\n",
            "Loss after 600 iterations: 284.08990120887756\n",
            "Loss after 700 iterations: 274.5782709121704\n",
            "Loss after 800 iterations: 269.7376754283905\n",
            "Loss after 900 iterations: 267.62858414649963\n",
            "Loss after 1000 iterations: 272.50298595428467\n",
            "Loss after 1100 iterations: 278.2372941970825\n",
            "Epoch: 10\n",
            "Loss after 0 iterations: 3.403179407119751\n",
            "Loss after 100 iterations: 301.7286400794983\n",
            "Loss after 200 iterations: 291.57096791267395\n",
            "Loss after 300 iterations: 273.5075273513794\n",
            "Loss after 400 iterations: 277.4756236076355\n",
            "Loss after 500 iterations: 270.1240670681\n",
            "Loss after 600 iterations: 281.1839690208435\n",
            "Loss after 700 iterations: 272.96774554252625\n",
            "Loss after 800 iterations: 268.2559151649475\n",
            "Loss after 900 iterations: 266.20723128318787\n",
            "Loss after 1000 iterations: 270.61911249160767\n",
            "Loss after 1100 iterations: 276.20041823387146\n",
            "Loss after 0 iterations: 117.3930139541626\n",
            "Loss after 100 iterations: 299.94606614112854\n",
            "Loss after 200 iterations: 287.9948515892029\n",
            "Loss after 300 iterations: 272.05313444137573\n",
            "Loss after 400 iterations: 275.40881085395813\n",
            "Loss after 500 iterations: 268.8150403499603\n",
            "Loss after 600 iterations: 278.5209712982178\n",
            "Loss after 700 iterations: 271.45874190330505\n",
            "Loss after 800 iterations: 266.839768409729\n",
            "Loss after 900 iterations: 265.0196146965027\n",
            "Loss after 1000 iterations: 268.9168884754181\n",
            "Loss after 1100 iterations: 274.30374360084534\n",
            "Epoch: 11\n",
            "Loss after 0 iterations: 3.379591464996338\n",
            "Loss after 100 iterations: 298.2001895904541\n",
            "Loss after 200 iterations: 284.5802192687988\n",
            "Loss after 300 iterations: 270.71393847465515\n",
            "Loss after 400 iterations: 273.45007514953613\n",
            "Loss after 500 iterations: 267.45798444747925\n",
            "Loss after 600 iterations: 276.0690701007843\n",
            "Loss after 700 iterations: 270.0061056613922\n",
            "Loss after 800 iterations: 265.46426272392273\n",
            "Loss after 900 iterations: 264.03141474723816\n",
            "Loss after 1000 iterations: 267.41571402549744\n",
            "Loss after 1100 iterations: 272.56137561798096\n",
            "Loss after 0 iterations: 116.7258083820343\n",
            "Loss after 100 iterations: 296.5478849411011\n",
            "Loss after 200 iterations: 281.39262771606445\n",
            "Loss after 300 iterations: 269.48572874069214\n",
            "Loss after 400 iterations: 271.58126878738403\n",
            "Loss after 500 iterations: 266.0681142807007\n",
            "Loss after 600 iterations: 273.87495946884155\n",
            "Loss after 700 iterations: 268.6278772354126\n",
            "Loss after 800 iterations: 264.1456208229065\n",
            "Loss after 900 iterations: 263.16795206069946\n",
            "Loss after 1000 iterations: 266.05043506622314\n",
            "Loss after 1100 iterations: 270.94873046875\n",
            "Epoch: 12\n",
            "Loss after 0 iterations: 3.355006456375122\n",
            "Loss after 100 iterations: 294.9775152206421\n",
            "Loss after 200 iterations: 278.4436659812927\n",
            "Loss after 300 iterations: 268.3695237636566\n",
            "Loss after 400 iterations: 269.8259320259094\n",
            "Loss after 500 iterations: 264.680180311203\n",
            "Loss after 600 iterations: 271.8547532558441\n",
            "Loss after 700 iterations: 267.2981848716736\n",
            "Loss after 800 iterations: 262.86928725242615\n",
            "Loss after 900 iterations: 262.40669226646423\n",
            "Loss after 1000 iterations: 264.8350737094879\n",
            "Loss after 1100 iterations: 269.4662139415741\n",
            "Loss after 0 iterations: 116.14159846305847\n",
            "Loss after 100 iterations: 293.4945001602173\n",
            "Loss after 200 iterations: 275.73904252052307\n",
            "Loss after 300 iterations: 267.310170173645\n",
            "Loss after 400 iterations: 268.17032265663147\n",
            "Loss after 500 iterations: 263.3176236152649\n",
            "Loss after 600 iterations: 270.03590297698975\n",
            "Loss after 700 iterations: 266.034476518631\n",
            "Loss after 800 iterations: 261.6546311378479\n",
            "Loss after 900 iterations: 261.6730840206146\n",
            "Loss after 1000 iterations: 263.7422616481781\n",
            "Loss after 1100 iterations: 268.10724425315857\n",
            "Epoch: 13\n",
            "Loss after 0 iterations: 3.3295493125915527\n",
            "Loss after 100 iterations: 292.0947389602661\n",
            "Loss after 200 iterations: 273.32241702079773\n",
            "Loss after 300 iterations: 266.33851504325867\n",
            "Loss after 400 iterations: 266.6216094493866\n",
            "Loss after 500 iterations: 261.99203181266785\n",
            "Loss after 600 iterations: 268.39914751052856\n",
            "Loss after 700 iterations: 264.83624243736267\n",
            "Loss after 800 iterations: 260.5143804550171\n",
            "Loss after 900 iterations: 260.956458568573\n",
            "Loss after 1000 iterations: 262.7398808002472\n",
            "Loss after 1100 iterations: 266.8540999889374\n",
            "Loss after 0 iterations: 115.62504363059998\n",
            "Loss after 100 iterations: 290.77942061424255\n",
            "Loss after 200 iterations: 271.17598366737366\n",
            "Loss after 300 iterations: 265.4233422279358\n",
            "Loss after 400 iterations: 265.17356514930725\n",
            "Loss after 500 iterations: 260.74997186660767\n",
            "Loss after 600 iterations: 266.91504406929016\n",
            "Loss after 700 iterations: 263.68364906311035\n",
            "Loss after 800 iterations: 259.4441797733307\n",
            "Loss after 900 iterations: 260.2330174446106\n",
            "Loss after 1000 iterations: 261.8322277069092\n",
            "Loss after 1100 iterations: 265.7218918800354\n",
            "Epoch: 14\n",
            "Loss after 0 iterations: 3.3030319213867188\n",
            "Loss after 100 iterations: 289.5344924926758\n",
            "Loss after 200 iterations: 269.2985291481018\n",
            "Loss after 300 iterations: 264.55086278915405\n",
            "Loss after 400 iterations: 263.8375744819641\n",
            "Loss after 500 iterations: 259.5767939090729\n",
            "Loss after 600 iterations: 265.57015013694763\n",
            "Loss after 700 iterations: 262.5833933353424\n",
            "Loss after 800 iterations: 258.44517850875854\n",
            "Loss after 900 iterations: 259.4945411682129\n",
            "Loss after 1000 iterations: 261.01577043533325\n",
            "Loss after 1100 iterations: 264.6883895397186\n",
            "Loss after 0 iterations: 115.16507911682129\n",
            "Loss after 100 iterations: 288.35813760757446\n",
            "Loss after 200 iterations: 267.64598846435547\n",
            "Loss after 300 iterations: 263.7277419567108\n",
            "Loss after 400 iterations: 262.5981366634369\n",
            "Loss after 500 iterations: 258.4794292449951\n",
            "Loss after 600 iterations: 264.35908460617065\n",
            "Loss after 700 iterations: 261.5415720939636\n",
            "Loss after 800 iterations: 257.516681432724\n",
            "Loss after 900 iterations: 258.7529001235962\n",
            "Loss after 1000 iterations: 260.2537524700165\n",
            "Loss after 1100 iterations: 263.7406210899353\n",
            "Epoch: 15\n",
            "Loss after 0 iterations: 3.2762577533721924\n",
            "Loss after 100 iterations: 287.23854756355286\n",
            "Loss after 200 iterations: 266.20494556427\n",
            "Loss after 300 iterations: 262.94035959243774\n",
            "Loss after 400 iterations: 261.45310401916504\n",
            "Loss after 500 iterations: 257.45141887664795\n",
            "Loss after 600 iterations: 263.2548997402191\n",
            "Loss after 700 iterations: 260.5570116043091\n",
            "Loss after 800 iterations: 256.6349334716797\n",
            "Loss after 900 iterations: 258.029953956604\n",
            "Loss after 1000 iterations: 259.5482385158539\n",
            "Loss after 1100 iterations: 262.8805351257324\n",
            "Loss after 0 iterations: 114.75488066673279\n",
            "Loss after 100 iterations: 286.1802968978882\n",
            "Loss after 200 iterations: 264.9457712173462\n",
            "Loss after 300 iterations: 262.1827321052551\n",
            "Loss after 400 iterations: 260.3977313041687\n",
            "Loss after 500 iterations: 256.5166988372803\n",
            "Loss after 600 iterations: 262.2460389137268\n",
            "Loss after 700 iterations: 259.62700939178467\n",
            "Loss after 800 iterations: 255.79926228523254\n",
            "Loss after 900 iterations: 257.3128252029419\n",
            "Loss after 1000 iterations: 258.89035511016846\n",
            "Loss after 1100 iterations: 262.0971233844757\n",
            "Epoch: 16\n",
            "Loss after 0 iterations: 3.2490971088409424\n",
            "Loss after 100 iterations: 285.179319858551\n",
            "Loss after 200 iterations: 263.8301770687103\n",
            "Loss after 300 iterations: 261.44361186027527\n",
            "Loss after 400 iterations: 259.42238426208496\n",
            "Loss after 500 iterations: 255.65418672561646\n",
            "Loss after 600 iterations: 261.3341257572174\n",
            "Loss after 700 iterations: 258.752201795578\n",
            "Loss after 800 iterations: 255.00814294815063\n",
            "Loss after 900 iterations: 256.6318428516388\n",
            "Loss after 1000 iterations: 258.2681317329407\n",
            "Loss after 1100 iterations: 261.38737750053406\n",
            "Loss after 0 iterations: 114.3893609046936\n",
            "Loss after 100 iterations: 284.232364654541\n",
            "Loss after 200 iterations: 262.8333659172058\n",
            "Loss after 300 iterations: 260.7187407016754\n",
            "Loss after 400 iterations: 258.5231487751007\n",
            "Loss after 500 iterations: 254.85719347000122\n",
            "Loss after 600 iterations: 260.5000810623169\n",
            "Loss after 700 iterations: 257.9316544532776\n",
            "Loss after 800 iterations: 254.2492232322693\n",
            "Loss after 900 iterations: 255.9693443775177\n",
            "Loss after 1000 iterations: 257.6862552165985\n",
            "Loss after 1100 iterations: 260.7483580112457\n",
            "Epoch: 17\n",
            "Loss after 0 iterations: 3.221851348876953\n",
            "Loss after 100 iterations: 283.34378266334534\n",
            "Loss after 200 iterations: 261.95329093933105\n",
            "Loss after 300 iterations: 260.0236837863922\n",
            "Loss after 400 iterations: 257.7045202255249\n",
            "Loss after 500 iterations: 254.1284739971161\n",
            "Loss after 600 iterations: 259.7474045753479\n",
            "Loss after 700 iterations: 257.17400074005127\n",
            "Loss after 800 iterations: 253.5222945213318\n",
            "Loss after 900 iterations: 255.32259511947632\n",
            "Loss after 1000 iterations: 257.1141800880432\n",
            "Loss after 1100 iterations: 260.1571044921875\n",
            "Loss after 0 iterations: 114.07041144371033\n",
            "Loss after 100 iterations: 282.495934009552\n",
            "Loss after 200 iterations: 261.15620851516724\n",
            "Loss after 300 iterations: 259.33870244026184\n",
            "Loss after 400 iterations: 256.94719672203064\n",
            "Loss after 500 iterations: 253.46394038200378\n",
            "Loss after 600 iterations: 259.0564033985138\n",
            "Loss after 700 iterations: 256.46805357933044\n",
            "Loss after 800 iterations: 252.82976722717285\n",
            "Loss after 900 iterations: 254.6884047985077\n",
            "Loss after 1000 iterations: 256.58392119407654\n",
            "Loss after 1100 iterations: 259.63056778907776\n",
            "Epoch: 18\n",
            "Loss after 0 iterations: 3.1941943168640137\n",
            "Loss after 100 iterations: 281.70002722740173\n",
            "Loss after 200 iterations: 260.4409213066101\n",
            "Loss after 300 iterations: 258.68267250061035\n",
            "Loss after 400 iterations: 256.2559189796448\n",
            "Loss after 500 iterations: 252.85560631752014\n",
            "Loss after 600 iterations: 258.42809104919434\n",
            "Loss after 700 iterations: 255.81863021850586\n",
            "Loss after 800 iterations: 252.16663479804993\n",
            "Loss after 900 iterations: 254.0640254020691\n",
            "Loss after 1000 iterations: 256.0808389186859\n",
            "Loss after 1100 iterations: 259.15464210510254\n",
            "Loss after 0 iterations: 113.7935848236084\n",
            "Loss after 100 iterations: 280.9380440711975\n",
            "Loss after 200 iterations: 259.7837219238281\n",
            "Loss after 300 iterations: 258.0555729866028\n",
            "Loss after 400 iterations: 255.6229555606842\n",
            "Loss after 500 iterations: 252.30190062522888\n",
            "Loss after 600 iterations: 257.85975456237793\n",
            "Loss after 700 iterations: 255.2151916027069\n",
            "Loss after 800 iterations: 251.55735039710999\n",
            "Loss after 900 iterations: 253.45315384864807\n",
            "Loss after 1000 iterations: 255.60594058036804\n",
            "Loss after 1100 iterations: 258.7246732711792\n",
            "Epoch: 19\n",
            "Loss after 0 iterations: 3.166043281555176\n",
            "Loss after 100 iterations: 280.2183265686035\n",
            "Loss after 200 iterations: 259.1898076534271\n",
            "Loss after 300 iterations: 257.4573104381561\n",
            "Loss after 400 iterations: 255.0438470840454\n",
            "Loss after 500 iterations: 251.79061317443848\n",
            "Loss after 600 iterations: 257.33746099472046\n",
            "Loss after 700 iterations: 254.6620752811432\n",
            "Loss after 800 iterations: 250.99319696426392\n",
            "Loss after 900 iterations: 252.85856318473816\n",
            "Loss after 1000 iterations: 255.1573576927185\n",
            "Loss after 1100 iterations: 258.336532831192\n",
            "Loss after 0 iterations: 113.55824732780457\n",
            "Loss after 100 iterations: 279.53365087509155\n",
            "Loss after 200 iterations: 258.6378984451294\n",
            "Loss after 300 iterations: 256.8778591156006\n",
            "Loss after 400 iterations: 254.51076126098633\n",
            "Loss after 500 iterations: 251.3381745815277\n",
            "Loss after 600 iterations: 256.86221742630005\n",
            "Loss after 700 iterations: 254.15427803993225\n",
            "Loss after 800 iterations: 250.47224617004395\n",
            "Loss after 900 iterations: 252.27446293830872\n",
            "Loss after 1000 iterations: 254.75074219703674\n",
            "Loss after 1100 iterations: 257.9894812107086\n",
            "Epoch: 20\n",
            "Loss after 0 iterations: 3.137573719024658\n",
            "Loss after 100 iterations: 278.8811662197113\n",
            "Loss after 200 iterations: 258.12736558914185\n",
            "Loss after 300 iterations: 256.3328719139099\n",
            "Loss after 400 iterations: 254.02297520637512\n",
            "Loss after 500 iterations: 250.9253158569336\n",
            "Loss after 600 iterations: 256.42794704437256\n",
            "Loss after 700 iterations: 253.6961829662323\n",
            "Loss after 800 iterations: 250.00838661193848\n",
            "Loss after 900 iterations: 251.7276952266693\n",
            "Loss after 1000 iterations: 254.36408376693726\n",
            "Loss after 1100 iterations: 257.66810393333435\n",
            "Loss after 0 iterations: 113.35487461090088\n",
            "Loss after 100 iterations: 278.248827457428\n",
            "Loss after 200 iterations: 257.64588928222656\n",
            "Loss after 300 iterations: 255.81004738807678\n",
            "Loss after 400 iterations: 253.56949758529663\n",
            "Loss after 500 iterations: 250.5473084449768\n",
            "Loss after 600 iterations: 256.0256140232086\n",
            "Loss after 700 iterations: 253.27565383911133\n",
            "Loss after 800 iterations: 249.59004426002502\n",
            "Loss after 900 iterations: 251.22458338737488\n",
            "Loss after 1000 iterations: 253.99890160560608\n",
            "Loss after 1100 iterations: 257.37293887138367\n",
            "Epoch: 21\n",
            "Loss after 0 iterations: 3.1081321239471436\n",
            "Loss after 100 iterations: 277.63561153411865\n",
            "Loss after 200 iterations: 257.20383739471436\n",
            "Loss after 300 iterations: 255.32751655578613\n",
            "Loss after 400 iterations: 253.1554296016693\n",
            "Loss after 500 iterations: 250.2016317844391\n",
            "Loss after 600 iterations: 255.6451439857483\n",
            "Loss after 700 iterations: 252.8981990814209\n",
            "Loss after 800 iterations: 249.22197818756104\n",
            "Loss after 900 iterations: 250.75785565376282\n",
            "Loss after 1000 iterations: 253.6500928401947\n",
            "Loss after 1100 iterations: 257.10133385658264\n",
            "Loss after 0 iterations: 113.17871689796448\n",
            "Loss after 100 iterations: 277.03123474121094\n",
            "Loss after 200 iterations: 256.7858531475067\n",
            "Loss after 300 iterations: 254.8558485507965\n",
            "Loss after 400 iterations: 252.77118301391602\n",
            "Loss after 500 iterations: 249.89803266525269\n",
            "Loss after 600 iterations: 255.29250049591064\n",
            "Loss after 700 iterations: 252.54921340942383\n",
            "Loss after 800 iterations: 248.88960528373718\n",
            "Loss after 900 iterations: 250.32516145706177\n",
            "Loss after 1000 iterations: 253.33888792991638\n",
            "Loss after 1100 iterations: 256.85020446777344\n",
            "Epoch: 22\n",
            "Loss after 0 iterations: 3.0790209770202637\n",
            "Loss after 100 iterations: 276.4428038597107\n",
            "Loss after 200 iterations: 256.3935089111328\n",
            "Loss after 300 iterations: 254.4177532196045\n",
            "Loss after 400 iterations: 252.41997408866882\n",
            "Loss after 500 iterations: 249.61759996414185\n",
            "Loss after 600 iterations: 254.95942521095276\n",
            "Loss after 700 iterations: 252.23969674110413\n",
            "Loss after 800 iterations: 248.59375071525574\n",
            "Loss after 900 iterations: 249.9352102279663\n",
            "Loss after 1000 iterations: 253.03674721717834\n",
            "Loss after 1100 iterations: 256.6189179420471\n",
            "Loss after 0 iterations: 113.02414608001709\n",
            "Loss after 100 iterations: 275.85491132736206\n",
            "Loss after 200 iterations: 256.0245409011841\n",
            "Loss after 300 iterations: 254.00143480300903\n",
            "Loss after 400 iterations: 252.09325289726257\n",
            "Loss after 500 iterations: 249.36448693275452\n",
            "Loss after 600 iterations: 254.6442060470581\n",
            "Loss after 700 iterations: 251.95892000198364\n",
            "Loss after 800 iterations: 248.32915878295898\n",
            "Loss after 900 iterations: 249.58404326438904\n",
            "Loss after 1000 iterations: 252.75008463859558\n",
            "Loss after 1100 iterations: 256.3977634906769\n",
            "Epoch: 23\n",
            "Loss after 0 iterations: 3.050661087036133\n",
            "Loss after 100 iterations: 275.2749888896942\n",
            "Loss after 200 iterations: 255.67786645889282\n",
            "Loss after 300 iterations: 253.61091923713684\n",
            "Loss after 400 iterations: 251.79538488388062\n",
            "Loss after 500 iterations: 249.1350338459015\n",
            "Loss after 600 iterations: 254.33392691612244\n",
            "Loss after 700 iterations: 251.71040225028992\n",
            "Loss after 800 iterations: 248.0894250869751\n",
            "Loss after 900 iterations: 249.270352602005\n",
            "Loss after 1000 iterations: 252.47777247428894\n",
            "Loss after 1100 iterations: 256.19844675064087\n",
            "Loss after 0 iterations: 112.88750982284546\n",
            "Loss after 100 iterations: 274.69617462158203\n",
            "Loss after 200 iterations: 255.3478581905365\n",
            "Loss after 300 iterations: 253.23631024360657\n",
            "Loss after 400 iterations: 251.5190510749817\n",
            "Loss after 500 iterations: 248.92939519882202\n",
            "Loss after 600 iterations: 254.044695854187\n",
            "Loss after 700 iterations: 251.48640942573547\n",
            "Loss after 800 iterations: 247.87834548950195\n",
            "Loss after 900 iterations: 248.97742342948914\n",
            "Loss after 1000 iterations: 252.22619891166687\n",
            "Loss after 1100 iterations: 256.00007724761963\n",
            "Epoch: 24\n",
            "Loss after 0 iterations: 3.02463436126709\n",
            "Loss after 100 iterations: 274.12542366981506\n",
            "Loss after 200 iterations: 255.03499603271484\n",
            "Loss after 300 iterations: 252.87881898880005\n",
            "Loss after 400 iterations: 251.26138067245483\n",
            "Loss after 500 iterations: 248.7429177761078\n",
            "Loss after 600 iterations: 253.76787519454956\n",
            "Loss after 700 iterations: 251.2894217967987\n",
            "Loss after 800 iterations: 247.6845314502716\n",
            "Loss after 900 iterations: 248.7178463935852\n",
            "Loss after 1000 iterations: 251.98390698432922\n",
            "Loss after 1100 iterations: 255.8143274784088\n",
            "Loss after 0 iterations: 112.76685881614685\n",
            "Loss after 100 iterations: 273.55482482910156\n",
            "Loss after 200 iterations: 254.74088835716248\n",
            "Loss after 300 iterations: 252.5403814315796\n",
            "Loss after 400 iterations: 251.0302815437317\n",
            "Loss after 500 iterations: 248.57078862190247\n",
            "Loss after 600 iterations: 253.4956455230713\n",
            "Loss after 700 iterations: 251.11163902282715\n",
            "Loss after 800 iterations: 247.51153206825256\n",
            "Loss after 900 iterations: 248.48217630386353\n",
            "Loss after 1000 iterations: 251.75371408462524\n",
            "Loss after 1100 iterations: 255.6288070678711\n",
            "Epoch: 25\n",
            "Loss after 0 iterations: 2.9987568855285645\n",
            "Loss after 100 iterations: 272.983274936676\n",
            "Loss after 200 iterations: 254.46627044677734\n",
            "Loss after 300 iterations: 252.21096420288086\n",
            "Loss after 400 iterations: 250.8098430633545\n",
            "Loss after 500 iterations: 248.41237044334412\n",
            "Loss after 600 iterations: 253.23051738739014\n",
            "Loss after 700 iterations: 250.9489848613739\n",
            "Loss after 800 iterations: 247.35494303703308\n",
            "Loss after 900 iterations: 248.27102994918823\n",
            "Loss after 1000 iterations: 251.53904509544373\n",
            "Loss after 1100 iterations: 255.4501600265503\n",
            "Loss after 0 iterations: 112.65742182731628\n",
            "Loss after 100 iterations: 272.4230258464813\n",
            "Loss after 200 iterations: 254.20656514167786\n",
            "Loss after 300 iterations: 251.89087653160095\n",
            "Loss after 400 iterations: 250.6068913936615\n",
            "Loss after 500 iterations: 248.2646927833557\n",
            "Loss after 600 iterations: 252.97493934631348\n",
            "Loss after 700 iterations: 250.80112504959106\n",
            "Loss after 800 iterations: 247.21445965766907\n",
            "Loss after 900 iterations: 248.07789015769958\n",
            "Loss after 1000 iterations: 251.3395960330963\n",
            "Loss after 1100 iterations: 255.27351880073547\n",
            "Epoch: 26\n",
            "Loss after 0 iterations: 2.9745657444000244\n",
            "Loss after 100 iterations: 271.8789384365082\n",
            "Loss after 200 iterations: 253.96315670013428\n",
            "Loss after 300 iterations: 251.5837950706482\n",
            "Loss after 400 iterations: 250.41935110092163\n",
            "Loss after 500 iterations: 248.12380242347717\n",
            "Loss after 600 iterations: 252.72687482833862\n",
            "Loss after 700 iterations: 250.66832065582275\n",
            "Loss after 800 iterations: 247.08599138259888\n",
            "Loss after 900 iterations: 247.90528464317322\n",
            "Loss after 1000 iterations: 251.14995956420898\n",
            "Loss after 1100 iterations: 255.10325121879578\n",
            "Loss after 0 iterations: 112.56009674072266\n",
            "Loss after 100 iterations: 271.3397011756897\n",
            "Loss after 200 iterations: 253.73355555534363\n",
            "Loss after 300 iterations: 251.29093408584595\n",
            "Loss after 400 iterations: 250.2416067123413\n",
            "Loss after 500 iterations: 247.99038243293762\n",
            "Loss after 600 iterations: 252.48328757286072\n",
            "Loss after 700 iterations: 250.54686856269836\n",
            "Loss after 800 iterations: 246.97169017791748\n",
            "Loss after 900 iterations: 247.741938829422\n",
            "Loss after 1000 iterations: 250.9767038822174\n",
            "Loss after 1100 iterations: 254.93443751335144\n",
            "Epoch: 27\n",
            "Loss after 0 iterations: 2.95082688331604\n",
            "Loss after 100 iterations: 270.81952953338623\n",
            "Loss after 200 iterations: 253.51950192451477\n",
            "Loss after 300 iterations: 251.01801681518555\n",
            "Loss after 400 iterations: 250.07721853256226\n",
            "Loss after 500 iterations: 247.8618586063385\n",
            "Loss after 600 iterations: 252.24839854240417\n",
            "Loss after 700 iterations: 250.43631672859192\n",
            "Loss after 800 iterations: 246.8686294555664\n",
            "Loss after 900 iterations: 247.59407472610474\n",
            "Loss after 1000 iterations: 250.8097848892212\n",
            "Loss after 1100 iterations: 254.76988911628723\n",
            "Loss after 0 iterations: 112.47137928009033\n",
            "Loss after 100 iterations: 270.31442499160767\n",
            "Loss after 200 iterations: 253.31763744354248\n",
            "Loss after 300 iterations: 250.7618489265442\n",
            "Loss after 400 iterations: 249.92489910125732\n",
            "Loss after 500 iterations: 247.74079155921936\n",
            "Loss after 600 iterations: 252.0175313949585\n",
            "Loss after 700 iterations: 250.33523654937744\n",
            "Loss after 800 iterations: 246.77456545829773\n",
            "Loss after 900 iterations: 247.4572398662567\n",
            "Loss after 1000 iterations: 250.6542055606842\n",
            "Loss after 1100 iterations: 254.60977578163147\n",
            "Epoch: 28\n",
            "Loss after 0 iterations: 2.928584337234497\n",
            "Loss after 100 iterations: 269.8210210800171\n",
            "Loss after 200 iterations: 253.12974452972412\n",
            "Loss after 300 iterations: 250.52373576164246\n",
            "Loss after 400 iterations: 249.78353476524353\n",
            "Loss after 500 iterations: 247.62501788139343\n",
            "Loss after 600 iterations: 251.79544234275818\n",
            "Loss after 700 iterations: 250.24270868301392\n",
            "Loss after 800 iterations: 246.69072031974792\n",
            "Loss after 900 iterations: 247.3314299583435\n",
            "Loss after 1000 iterations: 250.50492405891418\n",
            "Loss after 1100 iterations: 254.4498929977417\n",
            "Loss after 0 iterations: 112.38897156715393\n",
            "Loss after 100 iterations: 269.3353681564331\n",
            "Loss after 200 iterations: 252.95441150665283\n",
            "Loss after 300 iterations: 250.3048961162567\n",
            "Loss after 400 iterations: 249.64948773384094\n",
            "Loss after 500 iterations: 247.51446509361267\n",
            "Loss after 600 iterations: 251.57727527618408\n",
            "Loss after 700 iterations: 250.15989875793457\n",
            "Loss after 800 iterations: 246.61519646644592\n",
            "Loss after 900 iterations: 247.21373510360718\n",
            "Loss after 1000 iterations: 250.36433720588684\n",
            "Loss after 1100 iterations: 254.29629516601562\n",
            "Epoch: 29\n",
            "Loss after 0 iterations: 2.9068562984466553\n",
            "Loss after 100 iterations: 268.85895252227783\n",
            "Loss after 200 iterations: 252.7887909412384\n",
            "Loss after 300 iterations: 250.10259652137756\n",
            "Loss after 400 iterations: 249.5253667831421\n",
            "Loss after 500 iterations: 247.4093964099884\n",
            "Loss after 600 iterations: 251.36590552330017\n",
            "Loss after 700 iterations: 250.08430337905884\n",
            "Loss after 800 iterations: 246.54609966278076\n",
            "Loss after 900 iterations: 247.10300517082214\n",
            "Loss after 1000 iterations: 250.23175144195557\n",
            "Loss after 1100 iterations: 254.151629447937\n",
            "Loss after 0 iterations: 112.31258988380432\n",
            "Loss after 100 iterations: 268.3930809497833\n",
            "Loss after 200 iterations: 252.63516449928284\n",
            "Loss after 300 iterations: 249.91513538360596\n",
            "Loss after 400 iterations: 249.408136844635\n",
            "Loss after 500 iterations: 247.31031966209412\n",
            "Loss after 600 iterations: 251.1595742702484\n",
            "Loss after 700 iterations: 250.01497864723206\n",
            "Loss after 800 iterations: 246.4828817844391\n",
            "Loss after 900 iterations: 246.99961972236633\n",
            "Loss after 1000 iterations: 250.10838174819946\n",
            "Loss after 1100 iterations: 254.0115213394165\n",
            "Epoch: 30\n",
            "Loss after 0 iterations: 2.885899305343628\n",
            "Loss after 100 iterations: 267.9326922893524\n",
            "Loss after 200 iterations: 252.4921953678131\n",
            "Loss after 300 iterations: 249.74221897125244\n",
            "Loss after 400 iterations: 249.29752945899963\n",
            "Loss after 500 iterations: 247.214772939682\n",
            "Loss after 600 iterations: 250.95580554008484\n",
            "Loss after 700 iterations: 249.95124673843384\n",
            "Loss after 800 iterations: 246.42616200447083\n",
            "Loss after 900 iterations: 246.9052197933197\n",
            "Loss after 1000 iterations: 249.9896261692047\n",
            "Loss after 1100 iterations: 253.88205361366272\n",
            "Loss after 0 iterations: 112.23970675468445\n",
            "Loss after 100 iterations: 267.4851191043854\n",
            "Loss after 200 iterations: 252.35952186584473\n",
            "Loss after 300 iterations: 249.5859739780426\n",
            "Loss after 400 iterations: 249.1948208808899\n",
            "Loss after 500 iterations: 247.1256721019745\n",
            "Loss after 600 iterations: 250.75737309455872\n",
            "Loss after 700 iterations: 249.8938868045807\n",
            "Loss after 800 iterations: 246.37364411354065\n",
            "Loss after 900 iterations: 246.8187916278839\n",
            "Loss after 1000 iterations: 249.8748540878296\n",
            "Loss after 1100 iterations: 253.7560956478119\n",
            "Epoch: 31\n",
            "Loss after 0 iterations: 2.8657467365264893\n",
            "Loss after 100 iterations: 267.0394883155823\n",
            "Loss after 200 iterations: 252.23412895202637\n",
            "Loss after 300 iterations: 249.4377727508545\n",
            "Loss after 400 iterations: 249.0957214832306\n",
            "Loss after 500 iterations: 247.03945302963257\n",
            "Loss after 600 iterations: 250.5660982131958\n",
            "Loss after 700 iterations: 249.8372983932495\n",
            "Loss after 800 iterations: 246.3267126083374\n",
            "Loss after 900 iterations: 246.73578214645386\n",
            "Loss after 1000 iterations: 249.7645013332367\n",
            "Loss after 1100 iterations: 253.64311265945435\n",
            "Loss after 0 iterations: 112.17029929161072\n",
            "Loss after 100 iterations: 266.60431146621704\n",
            "Loss after 200 iterations: 252.11705088615417\n",
            "Loss after 300 iterations: 249.3024866580963\n",
            "Loss after 400 iterations: 249.00212025642395\n",
            "Loss after 500 iterations: 246.9579780101776\n",
            "Loss after 600 iterations: 250.37972021102905\n",
            "Loss after 700 iterations: 249.78592252731323\n",
            "Loss after 800 iterations: 246.2841989994049\n",
            "Loss after 900 iterations: 246.6623089313507\n",
            "Loss after 1000 iterations: 249.65549659729004\n",
            "Loss after 1100 iterations: 253.53588485717773\n",
            "Epoch: 32\n",
            "Loss after 0 iterations: 2.8458855152130127\n",
            "Loss after 100 iterations: 266.1760675907135\n",
            "Loss after 200 iterations: 252.00766944885254\n",
            "Loss after 300 iterations: 249.18008708953857\n",
            "Loss after 400 iterations: 248.91361904144287\n",
            "Loss after 500 iterations: 246.88212776184082\n",
            "Loss after 600 iterations: 250.1985297203064\n",
            "Loss after 700 iterations: 249.73639631271362\n",
            "Loss after 800 iterations: 246.24623107910156\n",
            "Loss after 900 iterations: 246.5934865474701\n",
            "Loss after 1000 iterations: 249.54361772537231\n",
            "Loss after 1100 iterations: 253.4332365989685\n",
            "Loss after 0 iterations: 112.10351872444153\n",
            "Loss after 100 iterations: 265.7506160736084\n",
            "Loss after 200 iterations: 251.90353679656982\n",
            "Loss after 300 iterations: 249.06483602523804\n",
            "Loss after 400 iterations: 248.82950258255005\n",
            "Loss after 500 iterations: 246.81025767326355\n",
            "Loss after 600 iterations: 250.02673363685608\n",
            "Loss after 700 iterations: 249.68780779838562\n",
            "Loss after 800 iterations: 246.21120190620422\n",
            "Loss after 900 iterations: 246.52871870994568\n",
            "Loss after 1000 iterations: 249.43640637397766\n",
            "Loss after 1100 iterations: 253.34424090385437\n",
            "Epoch: 33\n",
            "Loss after 0 iterations: 2.8267767429351807\n",
            "Loss after 100 iterations: 265.3388590812683\n",
            "Loss after 200 iterations: 251.80423069000244\n",
            "Loss after 300 iterations: 248.96268701553345\n",
            "Loss after 400 iterations: 248.75207138061523\n",
            "Loss after 500 iterations: 246.7413730621338\n",
            "Loss after 600 iterations: 249.86143589019775\n",
            "Loss after 700 iterations: 249.6429364681244\n",
            "Loss after 800 iterations: 246.18059992790222\n",
            "Loss after 900 iterations: 246.4712507724762\n",
            "Loss after 1000 iterations: 249.32504105567932\n",
            "Loss after 1100 iterations: 253.25370240211487\n",
            "Loss after 0 iterations: 112.03835844993591\n",
            "Loss after 100 iterations: 264.92064905166626\n",
            "Loss after 200 iterations: 251.71044540405273\n",
            "Loss after 300 iterations: 248.86619019508362\n",
            "Loss after 400 iterations: 248.67886352539062\n",
            "Loss after 500 iterations: 246.67710828781128\n",
            "Loss after 600 iterations: 249.70204138755798\n",
            "Loss after 700 iterations: 249.60154247283936\n",
            "Loss after 800 iterations: 246.15242910385132\n",
            "Loss after 900 iterations: 246.41652703285217\n",
            "Loss after 1000 iterations: 249.21750831604004\n",
            "Loss after 1100 iterations: 253.1737575531006\n",
            "Epoch: 34\n",
            "Loss after 0 iterations: 2.808469772338867\n",
            "Loss after 100 iterations: 264.50947403907776\n",
            "Loss after 200 iterations: 251.61934280395508\n",
            "Loss after 300 iterations: 248.77764916419983\n",
            "Loss after 400 iterations: 248.61345648765564\n",
            "Loss after 500 iterations: 246.61809849739075\n",
            "Loss after 600 iterations: 249.55024790763855\n",
            "Loss after 700 iterations: 249.56005835533142\n",
            "Loss after 800 iterations: 246.12705731391907\n",
            "Loss after 900 iterations: 246.36592292785645\n",
            "Loss after 1000 iterations: 249.10652828216553\n",
            "Loss after 1100 iterations: 253.09606528282166\n",
            "Loss after 0 iterations: 111.97653818130493\n",
            "Loss after 100 iterations: 264.10569047927856\n",
            "Loss after 200 iterations: 251.53110074996948\n",
            "Loss after 300 iterations: 248.69391322135925\n",
            "Loss after 400 iterations: 248.55015993118286\n",
            "Loss after 500 iterations: 246.5590305328369\n",
            "Loss after 600 iterations: 249.40771198272705\n",
            "Loss after 700 iterations: 249.51796793937683\n",
            "Loss after 800 iterations: 246.1034734249115\n",
            "Loss after 900 iterations: 246.32035613059998\n",
            "Loss after 1000 iterations: 249.00743913650513\n",
            "Loss after 1100 iterations: 253.0187385082245\n",
            "Epoch: 35\n",
            "Loss after 0 iterations: 2.790787696838379\n",
            "Loss after 100 iterations: 263.70065546035767\n",
            "Loss after 200 iterations: 251.44448494911194\n",
            "Loss after 300 iterations: 248.616393327713\n",
            "Loss after 400 iterations: 248.49667143821716\n",
            "Loss after 500 iterations: 246.50620198249817\n",
            "Loss after 600 iterations: 249.271418094635\n",
            "Loss after 700 iterations: 249.4769902229309\n",
            "Loss after 800 iterations: 246.08199858665466\n",
            "Loss after 900 iterations: 246.2775423526764\n",
            "Loss after 1000 iterations: 248.904447555542\n",
            "Loss after 1100 iterations: 252.94690036773682\n",
            "Loss after 0 iterations: 111.9152901172638\n",
            "Loss after 100 iterations: 263.3010151386261\n",
            "Loss after 200 iterations: 251.3587784767151\n",
            "Loss after 300 iterations: 248.5426480770111\n",
            "Loss after 400 iterations: 248.44587421417236\n",
            "Loss after 500 iterations: 246.45559859275818\n",
            "Loss after 600 iterations: 249.14293146133423\n",
            "Loss after 700 iterations: 249.4385244846344\n",
            "Loss after 800 iterations: 246.06286311149597\n",
            "Loss after 900 iterations: 246.23904061317444\n",
            "Loss after 1000 iterations: 248.81308960914612\n",
            "Loss after 1100 iterations: 252.87258768081665\n",
            "Epoch: 36\n",
            "Loss after 0 iterations: 2.773761510848999\n",
            "Loss after 100 iterations: 262.9010078907013\n",
            "Loss after 200 iterations: 251.27095437049866\n",
            "Loss after 300 iterations: 248.4686291217804\n",
            "Loss after 400 iterations: 248.40306305885315\n",
            "Loss after 500 iterations: 246.4088158607483\n",
            "Loss after 600 iterations: 249.01670050621033\n",
            "Loss after 700 iterations: 249.3983268737793\n",
            "Loss after 800 iterations: 246.04427337646484\n",
            "Loss after 900 iterations: 246.2020661830902\n",
            "Loss after 1000 iterations: 248.72510075569153\n",
            "Loss after 1100 iterations: 252.79936003684998\n",
            "Loss after 0 iterations: 111.85573029518127\n",
            "Loss after 100 iterations: 262.50446248054504\n",
            "Loss after 200 iterations: 251.18337965011597\n",
            "Loss after 300 iterations: 248.39808821678162\n",
            "Loss after 400 iterations: 248.36829328536987\n",
            "Loss after 500 iterations: 246.36434030532837\n",
            "Loss after 600 iterations: 248.89842224121094\n",
            "Loss after 700 iterations: 249.3609881401062\n",
            "Loss after 800 iterations: 246.02817463874817\n",
            "Loss after 900 iterations: 246.16905617713928\n",
            "Loss after 1000 iterations: 248.6409788131714\n",
            "Loss after 1100 iterations: 252.7168836593628\n",
            "Epoch: 37\n",
            "Loss after 0 iterations: 2.75776743888855\n",
            "Loss after 100 iterations: 262.11168217658997\n",
            "Loss after 200 iterations: 251.09266090393066\n",
            "Loss after 300 iterations: 248.32751202583313\n",
            "Loss after 400 iterations: 248.33942651748657\n",
            "Loss after 500 iterations: 246.3233015537262\n",
            "Loss after 600 iterations: 248.7833309173584\n",
            "Loss after 700 iterations: 249.32382559776306\n",
            "Loss after 800 iterations: 246.0130488872528\n",
            "Loss after 900 iterations: 246.1395571231842\n",
            "Loss after 1000 iterations: 248.56477856636047\n",
            "Loss after 1100 iterations: 252.63240242004395\n",
            "Loss after 0 iterations: 111.79899716377258\n",
            "Loss after 100 iterations: 261.7249331474304\n",
            "Loss after 200 iterations: 250.99951314926147\n",
            "Loss after 300 iterations: 248.25591325759888\n",
            "Loss after 400 iterations: 248.3192982673645\n",
            "Loss after 500 iterations: 246.28540802001953\n",
            "Loss after 600 iterations: 248.67511224746704\n",
            "Loss after 700 iterations: 249.28578186035156\n",
            "Loss after 800 iterations: 245.99912905693054\n",
            "Loss after 900 iterations: 246.11273789405823\n",
            "Loss after 1000 iterations: 248.49347376823425\n",
            "Loss after 1100 iterations: 252.5417320728302\n",
            "Epoch: 38\n",
            "Loss after 0 iterations: 2.742424964904785\n",
            "Loss after 100 iterations: 261.3367190361023\n",
            "Loss after 200 iterations: 250.9014732837677\n",
            "Loss after 300 iterations: 248.18029642105103\n",
            "Loss after 400 iterations: 248.30602264404297\n",
            "Loss after 500 iterations: 246.2488672733307\n",
            "Loss after 600 iterations: 248.57405757904053\n",
            "Loss after 700 iterations: 249.2428469657898\n",
            "Loss after 800 iterations: 245.98591423034668\n",
            "Loss after 900 iterations: 246.0868775844574\n",
            "Loss after 1000 iterations: 248.43050599098206\n",
            "Loss after 1100 iterations: 252.44608449935913\n",
            "Loss after 0 iterations: 111.74515056610107\n",
            "Loss after 100 iterations: 260.9588611125946\n",
            "Loss after 200 iterations: 250.797602891922\n",
            "Loss after 300 iterations: 248.10385727882385\n",
            "Loss after 400 iterations: 248.2959439754486\n",
            "Loss after 500 iterations: 246.21590948104858\n",
            "Loss after 600 iterations: 248.4775071144104\n",
            "Loss after 700 iterations: 249.19961643218994\n",
            "Loss after 800 iterations: 245.97354292869568\n",
            "Loss after 900 iterations: 246.0638337135315\n",
            "Loss after 1000 iterations: 248.37088179588318\n",
            "Loss after 1100 iterations: 252.34417366981506\n",
            "Epoch: 39\n",
            "Loss after 0 iterations: 2.7280380725860596\n",
            "Loss after 100 iterations: 260.58853340148926\n",
            "Loss after 200 iterations: 250.68736839294434\n",
            "Loss after 300 iterations: 248.02629852294922\n",
            "Loss after 400 iterations: 248.29139399528503\n",
            "Loss after 500 iterations: 246.18448448181152\n",
            "Loss after 600 iterations: 248.38393187522888\n",
            "Loss after 700 iterations: 249.15522074699402\n",
            "Loss after 800 iterations: 245.96169090270996\n",
            "Loss after 900 iterations: 246.04287385940552\n",
            "Loss after 1000 iterations: 248.31932282447815\n",
            "Loss after 1100 iterations: 252.24274158477783\n",
            "Loss after 0 iterations: 111.69014835357666\n",
            "Loss after 100 iterations: 260.2299554347992\n",
            "Loss after 200 iterations: 250.57018566131592\n",
            "Loss after 300 iterations: 247.95029377937317\n",
            "Loss after 400 iterations: 248.28845191001892\n",
            "Loss after 500 iterations: 246.15617513656616\n",
            "Loss after 600 iterations: 248.29503202438354\n",
            "Loss after 700 iterations: 249.10962057113647\n",
            "Loss after 800 iterations: 245.9512062072754\n",
            "Loss after 900 iterations: 246.02429389953613\n",
            "Loss after 1000 iterations: 248.26992678642273\n",
            "Loss after 1100 iterations: 252.14246726036072\n",
            "Epoch: 40\n",
            "Loss after 0 iterations: 2.7143971920013428\n",
            "Loss after 100 iterations: 259.87276458740234\n",
            "Loss after 200 iterations: 250.44783329963684\n",
            "Loss after 300 iterations: 247.87763381004333\n",
            "Loss after 400 iterations: 248.28273034095764\n",
            "Loss after 500 iterations: 246.1294867992401\n",
            "Loss after 600 iterations: 248.21100759506226\n",
            "Loss after 700 iterations: 249.06324100494385\n",
            "Loss after 800 iterations: 245.94073748588562\n",
            "Loss after 900 iterations: 246.0077691078186\n",
            "Loss after 1000 iterations: 248.22623991966248\n",
            "Loss after 1100 iterations: 252.04539704322815\n",
            "Loss after 0 iterations: 111.63614821434021\n",
            "Loss after 100 iterations: 259.527006149292\n",
            "Loss after 200 iterations: 250.32431054115295\n",
            "Loss after 300 iterations: 247.81199598312378\n",
            "Loss after 400 iterations: 248.27147388458252\n",
            "Loss after 500 iterations: 246.10462403297424\n",
            "Loss after 600 iterations: 248.13045978546143\n",
            "Loss after 700 iterations: 249.0190224647522\n",
            "Loss after 800 iterations: 245.93174862861633\n",
            "Loss after 900 iterations: 245.99229073524475\n",
            "Loss after 1000 iterations: 248.1858081817627\n",
            "Loss after 1100 iterations: 251.95112562179565\n",
            "Epoch: 41\n",
            "Loss after 0 iterations: 2.701584577560425\n",
            "Loss after 100 iterations: 259.1860752105713\n",
            "Loss after 200 iterations: 250.20170164108276\n",
            "Loss after 300 iterations: 247.750648021698\n",
            "Loss after 400 iterations: 248.25666522979736\n",
            "Loss after 500 iterations: 246.0820620059967\n",
            "Loss after 600 iterations: 248.05356621742249\n",
            "Loss after 700 iterations: 248.97170543670654\n",
            "Loss after 800 iterations: 245.92287683486938\n",
            "Loss after 900 iterations: 245.9780457019806\n",
            "Loss after 1000 iterations: 248.14969062805176\n",
            "Loss after 1100 iterations: 251.86443281173706\n",
            "Loss after 0 iterations: 111.58093976974487\n",
            "Loss after 100 iterations: 258.859411239624\n",
            "Loss after 200 iterations: 250.0810489654541\n",
            "Loss after 300 iterations: 247.6965458393097\n",
            "Loss after 400 iterations: 248.23168540000916\n",
            "Loss after 500 iterations: 246.06081914901733\n",
            "Loss after 600 iterations: 247.98200130462646\n",
            "Loss after 700 iterations: 248.926255941391\n",
            "Loss after 800 iterations: 245.9147264957428\n",
            "Loss after 900 iterations: 245.9646053314209\n",
            "Loss after 1000 iterations: 248.113107919693\n",
            "Loss after 1100 iterations: 251.7875111103058\n",
            "Epoch: 42\n",
            "Loss after 0 iterations: 2.6894419193267822\n",
            "Loss after 100 iterations: 258.5409007072449\n",
            "Loss after 200 iterations: 249.96289896965027\n",
            "Loss after 300 iterations: 247.6474061012268\n",
            "Loss after 400 iterations: 248.2045967578888\n",
            "Loss after 500 iterations: 246.04116201400757\n",
            "Loss after 600 iterations: 247.91255235671997\n",
            "Loss after 700 iterations: 248.88334345817566\n",
            "Loss after 800 iterations: 245.90725755691528\n",
            "Loss after 900 iterations: 245.95301938056946\n",
            "Loss after 1000 iterations: 248.07903361320496\n",
            "Loss after 1100 iterations: 251.71128916740417\n",
            "Loss after 0 iterations: 111.52531719207764\n",
            "Loss after 100 iterations: 258.22726559638977\n",
            "Loss after 200 iterations: 249.8507113456726\n",
            "Loss after 300 iterations: 247.6044533252716\n",
            "Loss after 400 iterations: 248.17040467262268\n",
            "Loss after 500 iterations: 246.02392148971558\n",
            "Loss after 600 iterations: 247.84896516799927\n",
            "Loss after 700 iterations: 248.84419751167297\n",
            "Loss after 800 iterations: 245.9003849029541\n",
            "Loss after 900 iterations: 245.9420304298401\n",
            "Loss after 1000 iterations: 248.04624390602112\n",
            "Loss after 1100 iterations: 251.64609670639038\n",
            "Epoch: 43\n",
            "Loss after 0 iterations: 2.6779375076293945\n",
            "Loss after 100 iterations: 257.9244885444641\n",
            "Loss after 200 iterations: 249.74113607406616\n",
            "Loss after 300 iterations: 247.5703797340393\n",
            "Loss after 400 iterations: 248.12792873382568\n",
            "Loss after 500 iterations: 246.00752353668213\n",
            "Loss after 600 iterations: 247.7862946987152\n",
            "Loss after 700 iterations: 248.8103313446045\n",
            "Loss after 800 iterations: 245.89433240890503\n",
            "Loss after 900 iterations: 245.93203687667847\n",
            "Loss after 1000 iterations: 248.01426601409912\n",
            "Loss after 1100 iterations: 251.58499360084534\n",
            "Loss after 0 iterations: 111.47045493125916\n",
            "Loss after 100 iterations: 257.62419629096985\n",
            "Loss after 200 iterations: 249.63283514976501\n",
            "Loss after 300 iterations: 247.53680562973022\n",
            "Loss after 400 iterations: 248.08903217315674\n",
            "Loss after 500 iterations: 245.99240112304688\n",
            "Loss after 600 iterations: 247.73051738739014\n",
            "Loss after 700 iterations: 248.7717661857605\n",
            "Loss after 800 iterations: 245.88806653022766\n",
            "Loss after 900 iterations: 245.92290377616882\n",
            "Loss after 1000 iterations: 247.98542404174805\n",
            "Loss after 1100 iterations: 251.5316915512085\n",
            "Epoch: 44\n",
            "Loss after 0 iterations: 2.6670188903808594\n",
            "Loss after 100 iterations: 257.33642864227295\n",
            "Loss after 200 iterations: 249.52738523483276\n",
            "Loss after 300 iterations: 247.50800681114197\n",
            "Loss after 400 iterations: 248.04671669006348\n",
            "Loss after 500 iterations: 245.97901058197021\n",
            "Loss after 600 iterations: 247.67669987678528\n",
            "Loss after 700 iterations: 248.74245977401733\n",
            "Loss after 800 iterations: 245.88287663459778\n",
            "Loss after 900 iterations: 245.9147036075592\n",
            "Loss after 1000 iterations: 247.9555652141571\n",
            "Loss after 1100 iterations: 251.4811475276947\n",
            "Loss after 0 iterations: 111.41512084007263\n",
            "Loss after 100 iterations: 257.05111289024353\n",
            "Loss after 200 iterations: 249.4248411655426\n",
            "Loss after 300 iterations: 247.48329854011536\n",
            "Loss after 400 iterations: 248.00072288513184\n",
            "Loss after 500 iterations: 245.96500182151794\n",
            "Loss after 600 iterations: 247.62443232536316\n",
            "Loss after 700 iterations: 248.70968770980835\n",
            "Loss after 800 iterations: 245.87728786468506\n",
            "Loss after 900 iterations: 245.90667033195496\n",
            "Loss after 1000 iterations: 247.9324324131012\n",
            "Loss after 1100 iterations: 251.43714594841003\n",
            "Epoch: 45\n",
            "Loss after 0 iterations: 2.6566765308380127\n",
            "Loss after 100 iterations: 256.7764210700989\n",
            "Loss after 200 iterations: 249.3241319656372\n",
            "Loss after 300 iterations: 247.45868158340454\n",
            "Loss after 400 iterations: 247.95842051506042\n",
            "Loss after 500 iterations: 245.95290732383728\n",
            "Loss after 600 iterations: 247.57798647880554\n",
            "Loss after 700 iterations: 248.68073678016663\n",
            "Loss after 800 iterations: 245.87238931655884\n",
            "Loss after 900 iterations: 245.89965415000916\n",
            "Loss after 1000 iterations: 247.90572786331177\n",
            "Loss after 1100 iterations: 251.39485454559326\n",
            "Loss after 0 iterations: 111.35989141464233\n",
            "Loss after 100 iterations: 256.5126123428345\n",
            "Loss after 200 iterations: 249.22586178779602\n",
            "Loss after 300 iterations: 247.43759179115295\n",
            "Loss after 400 iterations: 247.91468811035156\n",
            "Loss after 500 iterations: 245.94125127792358\n",
            "Loss after 600 iterations: 247.5326280593872\n",
            "Loss after 700 iterations: 248.65432715415955\n",
            "Loss after 800 iterations: 245.86748266220093\n",
            "Loss after 900 iterations: 245.89335560798645\n",
            "Loss after 1000 iterations: 247.88327145576477\n",
            "Loss after 1100 iterations: 251.3552951812744\n",
            "Epoch: 46\n",
            "Loss after 0 iterations: 2.646587371826172\n",
            "Loss after 100 iterations: 256.2549035549164\n",
            "Loss after 200 iterations: 249.13216161727905\n",
            "Loss after 300 iterations: 247.41845202445984\n",
            "Loss after 400 iterations: 247.87164640426636\n",
            "Loss after 500 iterations: 245.92976331710815\n",
            "Loss after 600 iterations: 247.49127101898193\n",
            "Loss after 700 iterations: 248.62715077400208\n",
            "Loss after 800 iterations: 245.86330652236938\n",
            "Loss after 900 iterations: 245.88739562034607\n",
            "Loss after 1000 iterations: 247.86177372932434\n",
            "Loss after 1100 iterations: 251.3193392753601\n",
            "Loss after 0 iterations: 111.30428385734558\n",
            "Loss after 100 iterations: 256.0032641887665\n",
            "Loss after 200 iterations: 249.0419476032257\n",
            "Loss after 300 iterations: 247.40055513381958\n",
            "Loss after 400 iterations: 247.83235096931458\n",
            "Loss after 500 iterations: 245.91973090171814\n",
            "Loss after 600 iterations: 247.4508171081543\n",
            "Loss after 700 iterations: 248.60439157485962\n",
            "Loss after 800 iterations: 245.85946440696716\n",
            "Loss after 900 iterations: 245.88201665878296\n",
            "Loss after 1000 iterations: 247.83923077583313\n",
            "Loss after 1100 iterations: 251.28517532348633\n",
            "Epoch: 47\n",
            "Loss after 0 iterations: 2.637399196624756\n",
            "Loss after 100 iterations: 255.7577052116394\n",
            "Loss after 200 iterations: 248.9554362297058\n",
            "Loss after 300 iterations: 247.38452100753784\n",
            "Loss after 400 iterations: 247.79246258735657\n",
            "Loss after 500 iterations: 245.90985822677612\n",
            "Loss after 600 iterations: 247.41496682167053\n",
            "Loss after 700 iterations: 248.5799596309662\n",
            "Loss after 800 iterations: 245.85558032989502\n",
            "Loss after 900 iterations: 245.8769633769989\n",
            "Loss after 1000 iterations: 247.8192982673645\n",
            "Loss after 1100 iterations: 251.25259494781494\n",
            "Loss after 0 iterations: 111.24854040145874\n",
            "Loss after 100 iterations: 255.52109289169312\n",
            "Loss after 200 iterations: 248.87264466285706\n",
            "Loss after 300 iterations: 247.36786317825317\n",
            "Loss after 400 iterations: 247.75305843353271\n",
            "Loss after 500 iterations: 245.90010857582092\n",
            "Loss after 600 iterations: 247.379558801651\n",
            "Loss after 700 iterations: 248.55745244026184\n",
            "Loss after 800 iterations: 245.85193347930908\n",
            "Loss after 900 iterations: 245.87225437164307\n",
            "Loss after 1000 iterations: 247.80240178108215\n",
            "Loss after 1100 iterations: 251.2229928970337\n",
            "Epoch: 48\n",
            "Loss after 0 iterations: 2.628509044647217\n",
            "Loss after 100 iterations: 255.29315400123596\n",
            "Loss after 200 iterations: 248.79348492622375\n",
            "Loss after 300 iterations: 247.3539912700653\n",
            "Loss after 400 iterations: 247.7158043384552\n",
            "Loss after 500 iterations: 245.89090204238892\n",
            "Loss after 600 iterations: 247.34609866142273\n",
            "Loss after 700 iterations: 248.53790974617004\n",
            "Loss after 800 iterations: 245.8488667011261\n",
            "Loss after 900 iterations: 245.8682599067688\n",
            "Loss after 1000 iterations: 247.78402495384216\n",
            "Loss after 1100 iterations: 251.19562911987305\n",
            "Loss after 0 iterations: 111.19068813323975\n",
            "Loss after 100 iterations: 255.07213973999023\n",
            "Loss after 200 iterations: 248.71663308143616\n",
            "Loss after 300 iterations: 247.33947801589966\n",
            "Loss after 400 iterations: 247.67958045005798\n",
            "Loss after 500 iterations: 245.8820526599884\n",
            "Loss after 600 iterations: 247.3153121471405\n",
            "Loss after 700 iterations: 248.517418384552\n",
            "Loss after 800 iterations: 245.84556651115417\n",
            "Loss after 900 iterations: 245.86446976661682\n",
            "Loss after 1000 iterations: 247.76693892478943\n",
            "Loss after 1100 iterations: 251.168470621109\n",
            "Epoch: 49\n",
            "Loss after 0 iterations: 2.6203601360321045\n",
            "Loss after 100 iterations: 254.85558199882507\n",
            "Loss after 200 iterations: 248.64378547668457\n",
            "Loss after 300 iterations: 247.32642769813538\n",
            "Loss after 400 iterations: 247.64718461036682\n",
            "Loss after 500 iterations: 245.87402415275574\n",
            "Loss after 600 iterations: 247.2857277393341\n",
            "Loss after 700 iterations: 248.49924039840698\n",
            "Loss after 800 iterations: 245.84284448623657\n",
            "Loss after 900 iterations: 245.8606915473938\n",
            "Loss after 1000 iterations: 247.7508888244629\n",
            "Loss after 1100 iterations: 251.14458465576172\n",
            "Loss after 0 iterations: 111.13304948806763\n",
            "Loss after 100 iterations: 254.64224123954773\n",
            "Loss after 200 iterations: 248.57164096832275\n",
            "Loss after 300 iterations: 247.31286311149597\n",
            "Loss after 400 iterations: 247.6124188899994\n",
            "Loss after 500 iterations: 245.86567521095276\n",
            "Loss after 600 iterations: 247.25903487205505\n",
            "Loss after 700 iterations: 248.4809935092926\n",
            "Loss after 800 iterations: 245.83986639976501\n",
            "Loss after 900 iterations: 245.85763096809387\n",
            "Loss after 1000 iterations: 247.73586988449097\n",
            "Loss after 1100 iterations: 251.12066292762756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "8KODGsvbdV4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  df_test_result, acc = test(df_test, mlp, tags, col_name = 'Sentence', col_tag = 'Tag', threshold = 0.25)"
      ],
      "metadata": {
        "id": "hZ2UTccCoXJL"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rKo2LIfaodYI",
        "outputId": "83b10c21-9d8c-4e99-c83b-ebf6bf54f762"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Accuracy: 0.6666666666666666'"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "y3IuWFHcI_Hd",
        "outputId": "3ec81172-8a0f-4637-e2f4-1cd6c987e982"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9f48cd00-45b7-4c22-9e52-a1d5a6a79812\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Tag</th>\n",
              "      <th>Tag_parent</th>\n",
              "      <th>predicted_tags</th>\n",
              "      <th>matches</th>\n",
              "      <th>probas</th>\n",
              "      <th>predicted_tags_if_not_fallback</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Where can I unfollow another person?</td>\n",
              "      <td>find_follow</td>\n",
              "      <td>find</td>\n",
              "      <td>find_follow</td>\n",
              "      <td>True</td>\n",
              "      <td>tensor(0.9996)</td>\n",
              "      <td>find_follow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How to get to the homepage?</td>\n",
              "      <td>find_homepage</td>\n",
              "      <td>find</td>\n",
              "      <td>find_homepage</td>\n",
              "      <td>True</td>\n",
              "      <td>tensor(0.9979)</td>\n",
              "      <td>find_homepage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Where do I find my profile?</td>\n",
              "      <td>find_profile</td>\n",
              "      <td>find</td>\n",
              "      <td>find_profile</td>\n",
              "      <td>True</td>\n",
              "      <td>tensor(0.9986)</td>\n",
              "      <td>find_profile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Where can I view my feed?</td>\n",
              "      <td>find_personal_feed</td>\n",
              "      <td>find</td>\n",
              "      <td>find_personal_feed</td>\n",
              "      <td>True</td>\n",
              "      <td>tensor(0.9944)</td>\n",
              "      <td>find_personal_feed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Where can I access the public feed?</td>\n",
              "      <td>find_public_feed</td>\n",
              "      <td>find</td>\n",
              "      <td>find_public_feed</td>\n",
              "      <td>True</td>\n",
              "      <td>tensor(0.9984)</td>\n",
              "      <td>find_public_feed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Where can I change my name?</td>\n",
              "      <td>find_edit_profile</td>\n",
              "      <td>find</td>\n",
              "      <td>find_edit_profile</td>\n",
              "      <td>True</td>\n",
              "      <td>tensor(0.9973)</td>\n",
              "      <td>find_edit_profile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Where can I login?</td>\n",
              "      <td>find_auth</td>\n",
              "      <td>find</td>\n",
              "      <td>find_auth</td>\n",
              "      <td>True</td>\n",
              "      <td>tensor(0.9994)</td>\n",
              "      <td>find_auth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Where can I change the language to german?</td>\n",
              "      <td>find_language</td>\n",
              "      <td>find</td>\n",
              "      <td>find_language</td>\n",
              "      <td>True</td>\n",
              "      <td>tensor(1.)</td>\n",
              "      <td>find_language</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How do I write a post?</td>\n",
              "      <td>find_create_post</td>\n",
              "      <td>find</td>\n",
              "      <td>find_create_post</td>\n",
              "      <td>True</td>\n",
              "      <td>tensor(0.9979)</td>\n",
              "      <td>find_create_post</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>What do I have to do to publish my own trade?</td>\n",
              "      <td>find_create_trade</td>\n",
              "      <td>find</td>\n",
              "      <td>find_create_trade</td>\n",
              "      <td>True</td>\n",
              "      <td>tensor(0.9989)</td>\n",
              "      <td>find_create_trade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Get me to the homepage.</td>\n",
              "      <td>navigate_homepage</td>\n",
              "      <td>navigate</td>\n",
              "      <td>navigate_homepage</td>\n",
              "      <td>True</td>\n",
              "      <td>tensor(0.9849)</td>\n",
              "      <td>navigate_homepage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>I would like to visit my profile.</td>\n",
              "      <td>navigate_profile</td>\n",
              "      <td>navigate</td>\n",
              "      <td>navigate_profile</td>\n",
              "      <td>True</td>\n",
              "      <td>tensor(0.9991)</td>\n",
              "      <td>navigate_profile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Show my personal feed.</td>\n",
              "      <td>navigate_personal_feed</td>\n",
              "      <td>navigate</td>\n",
              "      <td>navigate_personal_feed</td>\n",
              "      <td>True</td>\n",
              "      <td>tensor(0.9903)</td>\n",
              "      <td>navigate_personal_feed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>View the overall feed.</td>\n",
              "      <td>navigate_public_feed</td>\n",
              "      <td>navigate</td>\n",
              "      <td>navigate_personal_feed</td>\n",
              "      <td>False</td>\n",
              "      <td>tensor(0.8123)</td>\n",
              "      <td>navigate_personal_feed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>I want to sign in.</td>\n",
              "      <td>navigate_auth</td>\n",
              "      <td>navigate</td>\n",
              "      <td>navigate_auth</td>\n",
              "      <td>True</td>\n",
              "      <td>tensor(0.9976)</td>\n",
              "      <td>navigate_auth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>I would like to register.</td>\n",
              "      <td>navigate_auth</td>\n",
              "      <td>navigate</td>\n",
              "      <td>navigate_auth</td>\n",
              "      <td>True</td>\n",
              "      <td>tensor(0.9998)</td>\n",
              "      <td>navigate_auth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Expose the page where I can make a post.</td>\n",
              "      <td>navigate_create_post</td>\n",
              "      <td>navigate</td>\n",
              "      <td>find_create_trade</td>\n",
              "      <td>False</td>\n",
              "      <td>tensor(0.7278)</td>\n",
              "      <td>find_create_trade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Display the page for creating a trade.</td>\n",
              "      <td>navigate_create_trade</td>\n",
              "      <td>navigate</td>\n",
              "      <td>fallback</td>\n",
              "      <td>False</td>\n",
              "      <td>tensor(0.0295)</td>\n",
              "      <td>joke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>I would like to create a new post.</td>\n",
              "      <td>action_create_post</td>\n",
              "      <td>action</td>\n",
              "      <td>navigate_create_post</td>\n",
              "      <td>False</td>\n",
              "      <td>tensor(0.9998)</td>\n",
              "      <td>navigate_create_post</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Could you log me out, please?</td>\n",
              "      <td>action_logout</td>\n",
              "      <td>action</td>\n",
              "      <td>action_logout</td>\n",
              "      <td>True</td>\n",
              "      <td>tensor(1.0000)</td>\n",
              "      <td>action_logout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Hello bot.</td>\n",
              "      <td>greeting</td>\n",
              "      <td>greeting</td>\n",
              "      <td>greeting</td>\n",
              "      <td>True</td>\n",
              "      <td>tensor(0.8933)</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>That's all. Bye.</td>\n",
              "      <td>goodbye</td>\n",
              "      <td>goodbye</td>\n",
              "      <td>goodbye</td>\n",
              "      <td>True</td>\n",
              "      <td>tensor(0.9413)</td>\n",
              "      <td>goodbye</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Great. Thanks for your help.</td>\n",
              "      <td>thanks</td>\n",
              "      <td>thanks</td>\n",
              "      <td>thanks</td>\n",
              "      <td>True</td>\n",
              "      <td>tensor(0.9696)</td>\n",
              "      <td>thanks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>I don't know what to do.</td>\n",
              "      <td>help</td>\n",
              "      <td>help</td>\n",
              "      <td>fallback</td>\n",
              "      <td>False</td>\n",
              "      <td>tensor(0.0247)</td>\n",
              "      <td>find_create_trade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>I'm bored. Tell me something funny.</td>\n",
              "      <td>joke</td>\n",
              "      <td>joke</td>\n",
              "      <td>joke</td>\n",
              "      <td>True</td>\n",
              "      <td>tensor(0.8705)</td>\n",
              "      <td>joke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>What's C2G?</td>\n",
              "      <td>about_c2g</td>\n",
              "      <td>about_c2g</td>\n",
              "      <td>fallback</td>\n",
              "      <td>False</td>\n",
              "      <td>tensor(0.0350)</td>\n",
              "      <td>joke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Do you have a name?</td>\n",
              "      <td>about_bot_name</td>\n",
              "      <td>about_bot_name</td>\n",
              "      <td>fallback</td>\n",
              "      <td>False</td>\n",
              "      <td>tensor(0.0047)</td>\n",
              "      <td>goodbye</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Who are your parents?</td>\n",
              "      <td>about_bot_background</td>\n",
              "      <td>about_bot_background</td>\n",
              "      <td>fallback</td>\n",
              "      <td>False</td>\n",
              "      <td>tensor(0.0112)</td>\n",
              "      <td>joke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Alexa is better than you.</td>\n",
              "      <td>about_bot_other_bots</td>\n",
              "      <td>about_bot_other_bots</td>\n",
              "      <td>joke</td>\n",
              "      <td>False</td>\n",
              "      <td>tensor(0.3882)</td>\n",
              "      <td>joke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Is there anything you could do for me?</td>\n",
              "      <td>about_bot_skills</td>\n",
              "      <td>about_bot_motto</td>\n",
              "      <td>joke</td>\n",
              "      <td>False</td>\n",
              "      <td>tensor(0.2972)</td>\n",
              "      <td>joke</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f48cd00-45b7-4c22-9e52-a1d5a6a79812')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f48cd00-45b7-4c22-9e52-a1d5a6a79812 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f48cd00-45b7-4c22-9e52-a1d5a6a79812');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                         Sentence  ... predicted_tags_if_not_fallback\n",
              "0            Where can I unfollow another person?  ...                    find_follow\n",
              "1                     How to get to the homepage?  ...                  find_homepage\n",
              "2                     Where do I find my profile?  ...                   find_profile\n",
              "3                       Where can I view my feed?  ...             find_personal_feed\n",
              "4             Where can I access the public feed?  ...               find_public_feed\n",
              "5                     Where can I change my name?  ...              find_edit_profile\n",
              "6                              Where can I login?  ...                      find_auth\n",
              "7      Where can I change the language to german?  ...                  find_language\n",
              "8                          How do I write a post?  ...               find_create_post\n",
              "9   What do I have to do to publish my own trade?  ...              find_create_trade\n",
              "10                        Get me to the homepage.  ...              navigate_homepage\n",
              "11              I would like to visit my profile.  ...               navigate_profile\n",
              "12                         Show my personal feed.  ...         navigate_personal_feed\n",
              "13                         View the overall feed.  ...         navigate_personal_feed\n",
              "14                             I want to sign in.  ...                  navigate_auth\n",
              "15                      I would like to register.  ...                  navigate_auth\n",
              "16       Expose the page where I can make a post.  ...              find_create_trade\n",
              "17         Display the page for creating a trade.  ...                           joke\n",
              "18             I would like to create a new post.  ...           navigate_create_post\n",
              "19                  Could you log me out, please?  ...                  action_logout\n",
              "20                                     Hello bot.  ...                       greeting\n",
              "21                               That's all. Bye.  ...                        goodbye\n",
              "22                   Great. Thanks for your help.  ...                         thanks\n",
              "23                       I don't know what to do.  ...              find_create_trade\n",
              "24            I'm bored. Tell me something funny.  ...                           joke\n",
              "25                                    What's C2G?  ...                           joke\n",
              "26                            Do you have a name?  ...                        goodbye\n",
              "27                          Who are your parents?  ...                           joke\n",
              "28                      Alexa is better than you.  ...                           joke\n",
              "29         Is there anything you could do for me?  ...                           joke\n",
              "\n",
              "[30 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation"
      ],
      "metadata": {
        "id": "Nyu0UEALdZbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ig = IntegratedGradients(mlp)"
      ],
      "metadata": {
        "id": "M-kcX419ODue"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def explain_choice(ig, text):\n",
        "  x = pipe_new_input(text)\n",
        "  x = torch.from_numpy(x)\n",
        "  with torch.no_grad():\n",
        "    outputs = mlp(x)\n",
        "    target = torch.argmax(outputs) # is prediction not actual\n",
        "    print(tags[target])\n",
        "    # apply integrated gradients and receive importance of input nodes\n",
        "    outputs = ig.attribute(\n",
        "        inputs=x,\n",
        "        target=target,\n",
        "        baselines=torch.unsqueeze(torch.zeros(154), dim=0),\n",
        "        n_steps=50)\n",
        "  sorted, indices = torch.sort(torch.absolute(outputs), descending=True)\n",
        "  sorted, indices = sorted[0].tolist(), indices[0].tolist()\n",
        "\n",
        "  s = []\n",
        "  i = []\n",
        "\n",
        "  for ind, value in enumerate(sorted):\n",
        "    if not (value > 0):\n",
        "      break\n",
        "    i.append(word_list[indices[ind]])\n",
        "    s.append(value)\n",
        "  print(list(zip(s, i)))"
      ],
      "metadata": {
        "id": "cf7Eas8aYkmm"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wrong prediction\n",
        "text = 'I would like to create a new post.'\n",
        "explain_choice(ig, text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1vwdXG5OkR1",
        "outputId": "26296524-1ddb-4506-9f66-1a7dad822f91"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "navigate_create_post\n",
            "[(0.6177329100201314, 'post'), (0.18393473152185524, 'new'), (0.17071351897738424, 'create'), (0.1499542321187939, 'like'), (0.13358355625404758, '-PRON-'), (0.10438274771541241, 'would'), (0.07845328218236938, 'a'), (0.037957520685217266, 'to')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wrong prediction\n",
        "text = 'Create a post.'\n",
        "explain_choice(ig, text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqMF5AIFONhx",
        "outputId": "5363d30b-6db0-4d4d-d65f-79f92b7f4215"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "navigate_create_post\n",
            "[(0.8853112790963429, 'post'), (0.22318878729466662, 'create'), (0.118740701145351, 'a')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# correct prediction\n",
        "text = 'Create a post for me.'\n",
        "explain_choice(ig, text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ3RIq2xYQR6",
        "outputId": "f8d0bf7e-7076-430b-fb1c-9bcfdb512d10"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action_create_post\n",
            "[(0.6527565482046565, 'post'), (0.2666675698634774, 'create'), (0.1877163463185576, 'for'), (0.1419184454426143, '-PRON-'), (0.01056351783490079, 'a')]\n"
          ]
        }
      ]
    }
  ]
}