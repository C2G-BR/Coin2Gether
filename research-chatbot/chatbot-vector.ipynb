{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59920b91-784e-49d8-89c5-f8e3b3e6762d",
   "metadata": {},
   "source": [
    "# Data\n",
    "- spacy's input vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df84a72-bc03-443c-aefe-c3a4fe157de4",
   "metadata": {},
   "source": [
    "# Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f189d-c846-4ba9-908b-b45ff2c86391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from joblib import dump, load\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from preprocess_data import raw_to_json, unzip_entities, split_entities, tags_patterns_mix, get_responses, remove_fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b90c024-20fd-4ef3-823a-55b262662265",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d975a9a4-4964-4269-aa38-15fe6883c00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/Training - Training.csv')\n",
    "df_test = pd.read_csv('data/Training - Test.csv')\n",
    "intents = raw_to_json(df_train)\n",
    "parent_tags = ['navigate', 'find', 'action']\n",
    "data = unzip_entities(intents, parent_tags)\n",
    "responses = get_responses(data)\n",
    "data = remove_fallback(data)\n",
    "tags_patterns = tags_patterns_mix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a297841-9e06-4776-bb0b-cfab40616603",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def lemmatizer(text):\n",
    "    doc = nlp(text)\n",
    "    return [d.lemma_ for d in doc]\n",
    "\n",
    "def train_pipeline(tags_patterns):\n",
    "    \n",
    "    word_list = []\n",
    "    tags = []\n",
    "    word_tag_data = []\n",
    "    word_vector = []\n",
    "    \n",
    "    for i, row in tags_patterns.iterrows():\n",
    "        tag = row['tag']\n",
    "        pattern = row['pattern']\n",
    "        \n",
    "        tags.append(tag)\n",
    "        word = lemmatizer(pattern)\n",
    "        word_list.extend(word)\n",
    "        word_tag_data.append((word, tag))\n",
    "        word_vector.append(nlp(pattern))\n",
    "        \n",
    "    return tags, word_list, word_tag_data, word_vector\n",
    "\n",
    "def prepare_training_data(word_tag_data, word_list, tags, word_vector):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for (pattern, tag) in word_tag_data:\n",
    "        bog = bag_of_words(pattern, word_list)\n",
    "        vec = nlp(' '.join(pattern)).vector\n",
    "        \n",
    "        vec = np.array(vec)\n",
    "        x = vec\n",
    "        \n",
    "        X.append(x)\n",
    "        label = tags.index(tag)\n",
    "        y.append(label)\n",
    "\n",
    "    # X = np.squeeze(X, axis=1)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def bag_of_words(tokenized_sentence, words):\n",
    "\n",
    "    bog = np.zeros(len(words), dtype=np.float32)\n",
    "    for idx, word in enumerate(words):\n",
    "        if word in tokenized_sentence:\n",
    "            bog[idx] = 1\n",
    "    return bog\n",
    "\n",
    "def pipe_new_input(text):\n",
    "    \n",
    "    if text == '': #otherwise error\n",
    "        text = ' '\n",
    "\n",
    "    text = lemmatizer(text)\n",
    "    vec = nlp(' '.join(text)).vector\n",
    "    \n",
    "    bog = bag_of_words(text, word_list)\n",
    "    \n",
    "    bog = np.array(bog)\n",
    "    vec = np.array(vec)\n",
    "    \n",
    "    # x = np.vstack((bog.reshape(-1, 1), vec.reshape(-1, 1))).reshape(1, -1)\n",
    "    x = vec.reshape(1, -1)\n",
    "    # x = bog.reshape(1, bog.shape[0])\n",
    "    \n",
    "    return x\n",
    "    \n",
    "def predict(text, model):\n",
    "    x = pipe_new_input(text)\n",
    "    result = model.predict_proba(x)\n",
    "    return result\n",
    "\n",
    "def get_tag_from_prediction(result, tags, threshold, fallback = 'fallback'):\n",
    "    \n",
    "    max_proba = np.max(result)\n",
    "    \n",
    "    if max_proba < threshold:\n",
    "        return fallback\n",
    "    \n",
    "    predicted_tag = tags[np.argmax(result)]\n",
    "    \n",
    "    return predicted_tag\n",
    "    \n",
    "def test(df, model, tags, threshold = 0.4, col_name = 'Sentence', col_tag = 'Tag'):\n",
    "    predicted_tags = []\n",
    "    matches = []\n",
    "    probas = []\n",
    "    predicted_tags_if_not_fallback = []\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        sentence = row[col_name]\n",
    "        tag = row[col_tag]\n",
    "        \n",
    "        result = predict(sentence, model)\n",
    "        max_proba = np.max(result)\n",
    "        \n",
    "        predicted_tag = get_tag_from_prediction(result, tags, threshold)\n",
    "        \n",
    "        predicted_tag_except_fallback = get_tag_from_prediction(result, tags, 0.0)\n",
    "        \n",
    "        predicted_tags_if_not_fallback.append(predicted_tag_except_fallback)\n",
    "        probas.append(max_proba)\n",
    "        predicted_tags.append(predicted_tag)\n",
    "        matches.append(predicted_tag == tag)\n",
    "\n",
    "    df = df.assign(predicted_tags = predicted_tags, matches = matches, probas = probas, predicted_tags_if_not_fallback = predicted_tags_if_not_fallback)\n",
    "    \n",
    "    acc = df['matches'].sum() / len(df)\n",
    "    output = f'Accuracy: {acc}'\n",
    "    \n",
    "    return df, output\n",
    "\n",
    "def get_random_response_from_tag(tag, responses):\n",
    "    return np.random.choice(responses[tag])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab86f4e-4852-4528-a5cd-f8b9b974ab57",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd9931-800f-4847-b3f0-727422457c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags, word_list, word_tag_data, word_vector = train_pipeline(tags_patterns)\n",
    "IGNORE = ['?', '!', '.', ',']\n",
    "word_list = [word for word in word_list if word not in IGNORE]\n",
    "word_list = sorted(set(word_list))\n",
    "tags = sorted(set(tags))\n",
    "X, y = prepare_training_data(word_tag_data, word_list, tags, word_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a910bc4-2c8c-4a3c-b604-35ea775a766a",
   "metadata": {},
   "source": [
    "### Model training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0900cd-ce30-4b5c-857f-b55d20936eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(random_state=1, activation = 'logistic', max_iter=50000, hidden_layer_sizes = (16)).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015bef1d-e83a-41e2-a916-913d9724ab70",
   "metadata": {},
   "source": [
    "### Testing\n",
    "- calculates the accuracy of the model on test data\n",
    "- plots the dataframe with all misclassified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87838ac4-4191-42a1-b6a1-64754955fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_result, acc = test(df_test, clf, tags, col_name = 'Sentence', col_tag = 'Tag', threshold = 0.25)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ff263c-4b9d-4c09-a243-50cd48ab6943",
   "metadata": {},
   "source": [
    "Accuracy: 0.43333333333333335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce481051-8d4f-4c53-9c5e-9e22967bc80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_result[(df_test_result['matches'] == False)].to_markdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee27557-94c0-4261-a1f1-f27ccb2aaf9e",
   "metadata": {},
   "source": [
    "|    | Sentence                                      | Tag                    | Tag_parent           | predicted_tags     | matches   |   probas | predicted_tags_if_not_fallback   |\n",
    "|---:|:----------------------------------------------|:-----------------------|:---------------------|:-------------------|:----------|---------:|:---------------------------------|\n",
    "|  3 | Where can I view my feed?                     | find_personal_feed     | find                 | find_edit_profile  | False     | 0.842587 | find_edit_profile                |\n",
    "|  9 | What do I have to do to publish my own trade? | find_create_trade      | find                 | find_edit_profile  | False     | 0.955156 | find_edit_profile                |\n",
    "| 10 | supercalifragilisticexpialidocious            | fallback               | fallback             | help               | False     | 0.914312 | help                             |\n",
    "| 11 | Get me to the homepage.                       | navigate_homepage      | navigate             | action_logout      | False     | 0.797475 | action_logout                    |\n",
    "| 13 | Show my personal feed.                        | navigate_personal_feed | navigate             | find_personal_feed | False     | 0.925741 | find_personal_feed               |\n",
    "| 14 | View the overall feed.                        | navigate_public_feed   | navigate             | action_create_post | False     | 0.960393 | action_create_post               |\n",
    "| 15 | I want to sign in.                            | navigate_auth          | navigate             | action_logout      | False     | 0.976178 | action_logout                    |\n",
    "| 16 | I would like to register.                     | navigate_auth          | navigate             | action_logout      | False     | 0.535739 | action_logout                    |\n",
    "| 17 | Expose the page where I can make a post.      | navigate_create_post   | navigate             | find_create_trade  | False     | 0.942616 | find_create_trade                |\n",
    "| 18 | Display the page for creating a trade.        | navigate_create_trade  | navigate             | find_auth          | False     | 0.691495 | find_auth                        |\n",
    "| 21 | Hello bot.                                    | greeting               | greeting             | find_homepage      | False     | 0.403676 | find_homepage                    |\n",
    "| 22 | That's all. Bye.                              | goodbye                | goodbye              | action_logout      | False     | 0.515347 | action_logout                    |\n",
    "| 23 | Great. Thanks for your help.                  | thanks                 | thanks               | help               | False     | 0.389974 | help                             |\n",
    "| 24 | I don't know what to do.                      | help                   | help                 | joke               | False     | 0.822507 | joke                             |\n",
    "| 25 | I'm bored. Tell me something funny.           | joke                   | joke                 | action_create_post | False     | 0.69906  | action_create_post               |\n",
    "| 26 | What's C2G?                                   | about_c2g              | about_c2g            | find_follow        | False     | 0.573128 | find_follow                      |\n",
    "| 29 | Alexa is better than you.                     | about_bot_other_bots   | about_bot_other_bots | action_logout      | False     | 0.976478 | action_logout                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e753da8c-4b15-4933-aeaa-15e3b27ceee4",
   "metadata": {},
   "source": [
    "### Saving the model & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901dab41-80fa-4bae-99c8-e1ff6c6fb2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(clf, 'utils/classifier.model');\n",
    "dump(responses, 'utils/responses.data');\n",
    "dump(tags, 'utils/tags.data');\n",
    "dump(word_list, 'utils/word_list.data');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20b8192-4e14-413b-a4e0-2fd50ed98abe",
   "metadata": {},
   "source": [
    "### Testing the model with own input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3f5088-83b6-4d1a-8e39-1d832fc3d5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = 'Get me to my homepage'\n",
    "r = predict(txt, clf)\n",
    "pred = get_tag_from_prediction(r, tags, 0.20)\n",
    "get_random_response_from_tag(pred, responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695b3564-b0d3-4604-88e5-824261f67900",
   "metadata": {},
   "source": [
    "'navigate::profile'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
