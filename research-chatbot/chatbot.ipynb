{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df84a72-bc03-443c-aefe-c3a4fe157de4",
   "metadata": {},
   "source": [
    "# Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f189d-c846-4ba9-908b-b45ff2c86391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from joblib import dump, load\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from preprocess_data import raw_to_json, unzip_entities, split_entities, tags_patterns_mix, get_responses, remove_fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b90c024-20fd-4ef3-823a-55b262662265",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d975a9a4-4964-4269-aa38-15fe6883c00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/Training - Training.csv')\n",
    "df_test = pd.read_csv('data/Training - Test.csv')\n",
    "intents = raw_to_json(df_train)\n",
    "parent_tags = ['navigate', 'find', 'action']\n",
    "data = unzip_entities(intents, parent_tags)\n",
    "responses = get_responses(data)\n",
    "data = remove_fallback(data)\n",
    "tags_patterns = tags_patterns_mix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a297841-9e06-4776-bb0b-cfab40616603",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def lemmatizer(text):\n",
    "    doc = nlp(text)\n",
    "    return [d.lemma_ for d in doc]\n",
    "\n",
    "def train_pipeline(tags_patterns):\n",
    "    \n",
    "    word_list = []\n",
    "    tags = []\n",
    "    word_tag_data = []\n",
    "    \n",
    "    for i, row in tags_patterns.iterrows():\n",
    "        tag = row['tag']\n",
    "        pattern = row['pattern']\n",
    "        tags.append(tag)\n",
    "        word = lemmatizer(pattern)\n",
    "        word_list.extend(word)\n",
    "        word_tag_data.append((word, tag))\n",
    "        \n",
    "    return tags, word_list, word_tag_data\n",
    "\n",
    "def prepare_training_data(word_tag_data, word_list, tags):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for (pattern, tag) in word_tag_data:\n",
    "        bog = bag_of_words(pattern, word_list)\n",
    "        X.append(bog)\n",
    "        label = tags.index(tag)\n",
    "        y.append(label)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def bag_of_words(tokenized_sentence, words):\n",
    "\n",
    "    bog = np.zeros(len(words), dtype=np.float32)\n",
    "    for idx, word in enumerate(words):\n",
    "        if word in tokenized_sentence:\n",
    "            bog[idx] = 1\n",
    "    return bog\n",
    "\n",
    "def pipe_new_input(text):\n",
    "    if text == '': #otherwise error\n",
    "        text = ' '\n",
    "    text = lemmatizer(text)\n",
    "    bog = bag_of_words(text, word_list)\n",
    "    x = bog.reshape(1, bog.shape[0])\n",
    "    return x\n",
    "    \n",
    "def predict(text, model):\n",
    "    x = pipe_new_input(text)\n",
    "    result = model.predict_proba(x)\n",
    "    return result\n",
    "\n",
    "def get_tag_from_prediction(result, tags, threshold, fallback = 'fallback'):\n",
    "    \n",
    "    max_proba = np.max(result)\n",
    "    \n",
    "    if max_proba < threshold:\n",
    "        return fallback\n",
    "    \n",
    "    predicted_tag = tags[np.argmax(result)]\n",
    "    \n",
    "    return predicted_tag\n",
    "    \n",
    "def test(df, model, tags, threshold = 0.4, col_name = 'Sentence', col_tag = 'Tag'):\n",
    "    predicted_tags = []\n",
    "    matches = []\n",
    "    probas = []\n",
    "    predicted_tags_if_not_fallback = []\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        sentence = row[col_name]\n",
    "        tag = row[col_tag]\n",
    "        \n",
    "        result = predict(sentence, model)\n",
    "        max_proba = np.max(result)\n",
    "        \n",
    "        predicted_tag = get_tag_from_prediction(result, tags, threshold)\n",
    "        \n",
    "        predicted_tag_except_fallback = get_tag_from_prediction(result, tags, 0.0)\n",
    "        \n",
    "        predicted_tags_if_not_fallback.append(predicted_tag_except_fallback)\n",
    "        probas.append(max_proba)\n",
    "        predicted_tags.append(predicted_tag)\n",
    "        matches.append(predicted_tag == tag)\n",
    "        \n",
    "    df = df.assign(predicted_tags = predicted_tags, matches = matches, probas = probas, predicted_tags_if_not_fallback = predicted_tags_if_not_fallback)\n",
    "    \n",
    "    acc = df['matches'].sum() / len(df)\n",
    "    output = f'Accuracy: {acc}'\n",
    "    \n",
    "    return df, output\n",
    "\n",
    "def get_random_response_from_tag(tag, responses):\n",
    "    return np.random.choice(responses[tag])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab86f4e-4852-4528-a5cd-f8b9b974ab57",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd9931-800f-4847-b3f0-727422457c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags, word_list, word_tag_data = train_pipeline(tags_patterns)\n",
    "IGNORE = ['?', '!', '.', ',']\n",
    "word_list = [word for word in word_list if word not in IGNORE]\n",
    "word_list = sorted(set(word_list))\n",
    "tags = sorted(set(tags))\n",
    "X, y = prepare_training_data(word_tag_data, word_list, tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a910bc4-2c8c-4a3c-b604-35ea775a766a",
   "metadata": {},
   "source": [
    "### Model training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0900cd-ce30-4b5c-857f-b55d20936eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(random_state=1, activation = 'logistic', max_iter=50000, hidden_layer_sizes = (16)).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015bef1d-e83a-41e2-a916-913d9724ab70",
   "metadata": {},
   "source": [
    "### Testing\n",
    "- calculates the accuracy of the model on test data\n",
    "- plots the dataframe with all misclassified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87838ac4-4191-42a1-b6a1-64754955fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_result, acc = test(df_test, clf, tags, col_name = 'Sentence', col_tag = 'Tag', threshold = 0.25)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ff263c-4b9d-4c09-a243-50cd48ab6943",
   "metadata": {},
   "source": [
    "Accuracy: 0.9333333333333333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce481051-8d4f-4c53-9c5e-9e22967bc80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_result[(df_test_result['matches'] == False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee27557-94c0-4261-a1f1-f27ccb2aaf9e",
   "metadata": {},
   "source": [
    "|    | Sentence                                 | Tag                  | Tag_parent   | predicted_tags       | matches   |   probas | predicted_tags_if_not_fallback   |\n",
    "|---:|:-----------------------------------------|:---------------------|:-------------|:---------------------|:----------|---------:|:---------------------------------|\n",
    "| 17 | Expose the page where I can make a post. | navigate_create_post | navigate     | find_create_trade    | False     | 0.945566 | find_create_trade                |\n",
    "| 19 | I would like to create a new post.       | action_create_post   | action       | navigate_create_post | False     | 0.736224 | navigate_create_post             |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e753da8c-4b15-4933-aeaa-15e3b27ceee4",
   "metadata": {},
   "source": [
    "### Saving the model & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901dab41-80fa-4bae-99c8-e1ff6c6fb2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(clf, 'utils/classifier.model');\n",
    "dump(responses, 'utils/responses.data');\n",
    "dump(tags, 'utils/tags.data');\n",
    "dump(word_list, 'utils/word_list.data');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20b8192-4e14-413b-a4e0-2fd50ed98abe",
   "metadata": {},
   "source": [
    "### Testing the model with own input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3f5088-83b6-4d1a-8e39-1d832fc3d5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = 'Does this chatbot work better than Alexa?'\n",
    "r = predict(txt, clf)\n",
    "pred = get_tag_from_prediction(r, tags, 0.20)\n",
    "get_random_response_from_tag(pred, responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6300dd3b-12dd-4067-8ab5-2b9b8ad25040",
   "metadata": {},
   "source": [
    "# Production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8abb3cd-efe7-478c-a9c0-742040257162",
   "metadata": {},
   "source": [
    "### Production class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99399b7f-e0c7-4c05-92aa-8d6f22415714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import spacy\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from joblib import load\n",
    "\n",
    "class Chatbot():\n",
    "    \n",
    "    path_classifier = 'utils/classifier.model'\n",
    "    path_responses = 'utils/responses.data'\n",
    "    path_tags = 'utils/tags.data'\n",
    "    path_word_list = 'utils/word_list.data'\n",
    "    \n",
    "    classifier = None\n",
    "    responses = None\n",
    "    tags = None\n",
    "    \n",
    "     \n",
    "    def __init__(self, threshold = 0.2, fallback = 'fallback', greeting = 'greeting'):\n",
    "        \n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "        self.classifier = load(self.path_classifier)\n",
    "        self.responses = load(self.path_responses)\n",
    "        self.tags = load(self.path_tags)\n",
    "        self.word_list = load(self.path_word_list)\n",
    "        \n",
    "        self.threshold = threshold #when below threshold chatbot returns a fallback answer because of the lacking confidence\n",
    "        self.fallback = fallback #name of fallback tag\n",
    "        self.greeting = greeting\n",
    "    \n",
    "    def lemmatizer(self, text):\n",
    "        doc = self.nlp(text)\n",
    "        return [d.lemma_ for d in doc]\n",
    "        \n",
    "    def get_tag_from_prediction(self, result, threshold):\n",
    "        max_proba = np.max(result)\n",
    "        if max_proba < threshold:\n",
    "            return self.fallback\n",
    "        predicted_tag = self.tags[np.argmax(result)]\n",
    "        return predicted_tag\n",
    "            \n",
    "        \n",
    "    def log_predictions(self, input_text, prediction_tag, probability, prediction_tag_if_not_fallback, response):\n",
    "        logging.basicConfig(filename='logs/chatbot_predictions.log', encoding='utf-8')#, level=logging.DEBUG)\n",
    "        s = f'{input_text}, {prediction_tag}, {probability}, {prediction_tag_if_not_fallback}, {response}'\n",
    "        logging.debug(s)\n",
    "    \n",
    "    def bag_of_words(self, sentence):\n",
    "        bog = np.zeros(len(self.word_list), dtype=np.float32)\n",
    "        for idx, word in enumerate(self.word_list):\n",
    "            if word in sentence:\n",
    "                bog[idx] = 1\n",
    "        return bog\n",
    "    \n",
    "    def pipe_new_input(self, text):\n",
    "        if text == '': #otherwise error\n",
    "            logging.info('Empty input')\n",
    "            text = ' '\n",
    "        text = self.lemmatizer(text)\n",
    "        bog = self.bag_of_words(text)\n",
    "        x = bog.reshape(1, bog.shape[0])\n",
    "        return x\n",
    "    \n",
    "    def get_greeting(self):\n",
    "        return self.get_random_response_from_tag(self.greeting)\n",
    "    \n",
    "    def get_random_response_from_tag(self, tag):\n",
    "        \n",
    "        return np.random.choice(self.responses[tag])\n",
    "    \n",
    "    def predict(self, input_text, log_status = True):\n",
    "        x = self.pipe_new_input(input_text)\n",
    "        \n",
    "        result = self.classifier.predict_proba(x)\n",
    "        max_proba = np.max(result)\n",
    "        \n",
    "        predicted_tag = self.get_tag_from_prediction(result, self.threshold)\n",
    "        predicted_tag_except_fallback = self.get_tag_from_prediction(result, 0.0)\n",
    "        \n",
    "        response = self.get_random_response_from_tag(predicted_tag)\n",
    "        \n",
    "        if log_status:\n",
    "            self.log_predictions(input_text,\n",
    "                                    predicted_tag,\n",
    "                                    max_proba,\n",
    "                                    predicted_tag_except_fallback,\n",
    "                                    response)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e0cb03-bfea-463f-be7f-bf02e1537788",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = Chatbot(threshold = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a961342f-434a-47a3-ba69-07758560966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb.predict('Create a post for me', False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
